{
    "docs": [
        {
            "location": "/",
            "text": "These are notes I've taken on technologies that I have used or would like to use. I used to keep them in a private mediawiki, but because they would be useful for other people, and because I want to have them immediately available during outages, I've moved this into public view.\n\n\n\n\nhttp://danielhoherd.github.io/tech-notes/\n\n\nhttp://github.com/danielhoherd/tech-notes",
            "title": "Home"
        },
        {
            "location": "/3d_printing/",
            "text": "https://www.makerbot.com\n\n\nhttp://www.meshlab.net\n\n\nhttps://www.thingiverse.com",
            "title": "3d printing"
        },
        {
            "location": "/3ds/",
            "text": "https://yls8.mtheall.com/3dsbrowserhax.php\n\n\nhttp://www.3dbrew.org/wiki/Homebrew_Applications\n\n\n\n\nLego + 3DS notes\n\n\n\n\n3DSXL screen is ~ 9x11 Lego units\n\n\n3DSXL outside is 20x12 Lego units\n\n\n\n\nEmulation\n\n\n\n\nCitra 3DS emulator\n\n\nDumping cartridges",
            "title": "3ds"
        },
        {
            "location": "/3ds/#lego-3ds-notes",
            "text": "3DSXL screen is ~ 9x11 Lego units  3DSXL outside is 20x12 Lego units",
            "title": "Lego + 3DS notes"
        },
        {
            "location": "/3ds/#emulation",
            "text": "Citra 3DS emulator  Dumping cartridges",
            "title": "Emulation"
        },
        {
            "location": "/airport/",
            "text": "Apple Airport, discontinued as of November 2016.\n\n\nUsing old Airport Utility apps with new versions of OS X\n\n\n\n\nhttps://zcs.zyniker.org/airport-utility-v5-6-1\n\n\nhttps://support.apple.com/kb/DL1536\n\n\n\n\nOr use the 5.6.1 Utility in Windows? Not sure if this works.\n\n\n\n\nhttps://support.apple.com/kb/dl1547",
            "title": "Airport"
        },
        {
            "location": "/airport/#using-old-airport-utility-apps-with-new-versions-of-os-x",
            "text": "https://zcs.zyniker.org/airport-utility-v5-6-1  https://support.apple.com/kb/DL1536   Or use the 5.6.1 Utility in Windows? Not sure if this works.   https://support.apple.com/kb/dl1547",
            "title": "Using old Airport Utility apps with new versions of OS X"
        },
        {
            "location": "/amazon-ec2/",
            "text": "\"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is designed to make web-scale cloud computing easier for developers.\" - \nhttps://aws.amazon.com/ec2/\n\n\nTechniques\n\n\nDetermine if you are on an EC2 instance\n\n\ngrep -i '^ec2' /sys/hypervisor/uuid\n\n\n\n\nSee Also\n\n\n\n\nAmazon",
            "title": "Amazon ec2"
        },
        {
            "location": "/amazon-ec2/#techniques",
            "text": "",
            "title": "Techniques"
        },
        {
            "location": "/amazon-ec2/#determine-if-you-are-on-an-ec2-instance",
            "text": "grep -i '^ec2' /sys/hypervisor/uuid",
            "title": "Determine if you are on an EC2 instance"
        },
        {
            "location": "/amazon-ec2/#see-also",
            "text": "Amazon",
            "title": "See Also"
        },
        {
            "location": "/amazon/",
            "text": "Links\n\n\n\n\nAmazon service availability by region\n\n\nAmazon EC2 Instance Types\n\n\nEC2Instances.info - Easy Amazon EC2 Instance Comparison\n\n\nAWS Console\n\n\nAWS in plain english\n\n\nGithub - Troposphere\n\n\ns3toosl\n - Command Line S3 Client and Backup\n\n\nawless - awless is a powerful, innovative and small surface command line interface (CLI) to manage Amazon Web Services.\n\n\n\n\nTips\n\n\nReformat accessKeys.csv into .aws/credentials format\n\n\nawk -F, 'BEGIN { print \"[temp_name]\" ; } !/Access/ {print \"aws_access_key_id = \"$1\"\\naws_secret_access_key = \"$2}' ~/Downloads/accessKeys.csv\n\n\n\n\nSee Also\n\n\n\n\naws cli\n\n\nCloudFormation\n\n\n\n\nTerms and Acronyms\n\n\n\n\n\n\n\n\nTerm\n\n\nDefinition\n\n\n\n\n\n\n\n\n\n\nAMI\n\n\nAmazon Machine Images\n\n\n\n\n\n\nASG\n\n\nAuto-Scaling Group. Auto Scaling can automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs.\n\n\n\n\n\n\nAWS\n\n\nAmazon Web Services\n\n\n\n\n\n\nAZ\n\n\nData centers. Amazon Availability Zones.\n\n\n\n\n\n\nEBS\n\n\nElastic Block Storage. Provides persistent block-level storage volumes for EC2.\n\n\n\n\n\n\nEC2\n\n\nElastic Compute Cloud\n\n\n\n\n\n\nELB\n\n\nElastic Load Balancing\n\n\n\n\n\n\nEMR\n\n\nElastic MapReduce. Allows easily and cheap processing of vast amounts of data\n\n\n\n\n\n\nETS\n\n\nElastic Transcoder. Provides video transcoding of S3 hosted videos\n\n\n\n\n\n\nFPS\n\n\nFlexible Payments Service. Provides an interface for micro payments.\n\n\n\n\n\n\nHSM\n\n\nHardware Security Module\n\n\n\n\n\n\nIAM\n\n\nIdentity and Access Management enables you to securely control access to AWS services and resources for your users. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.\n\n\n\n\n\n\nKMS\n\n\nKey Management Service\n\n\n\n\n\n\nMFA\n\n\nAmazon Web Services Multi-Factor Authentication is a simple best practice that adds an extra layer of protection on top of your user name and password.\n\n\n\n\n\n\nRDS\n\n\nRelational Database Service\n\n\n\n\n\n\nRI\n\n\nReserved Instance. EC2 instances for which there is a 1 or 3 year contract with AWS to achieve lower hourly run costs.\n\n\n\n\n\n\nRoute 53\n\n\nA highly available and scalable cloud Domain Name System (DNS) web service.\n\n\n\n\n\n\nS3\n\n\nSimple Storage Service\n\n\n\n\n\n\nSES\n\n\nSimple Email Service. Provides bulk and transactional email sending.\n\n\n\n\n\n\nSG\n\n\nSecurity Group. Security Groups in AWS are akin to firewalls.\n\n\n\n\n\n\nSNS\n\n\nSimple Notification Service. Provides a hosted multiprotocol \"push\" messaging for applications.\n\n\n\n\n\n\nSQS\n\n\nSimple Queue Service. Provides a hosted message queue for web applications.\n\n\n\n\n\n\nSWF\n\n\nSimple Workflow. Workflow service for building scalable, resilient applications.\n\n\n\n\n\n\nVPC\n\n\nVirtual Private Cloud",
            "title": "Links"
        },
        {
            "location": "/amazon/#links",
            "text": "Amazon service availability by region  Amazon EC2 Instance Types  EC2Instances.info - Easy Amazon EC2 Instance Comparison  AWS Console  AWS in plain english  Github - Troposphere  s3toosl  - Command Line S3 Client and Backup  awless - awless is a powerful, innovative and small surface command line interface (CLI) to manage Amazon Web Services.",
            "title": "Links"
        },
        {
            "location": "/amazon/#tips",
            "text": "",
            "title": "Tips"
        },
        {
            "location": "/amazon/#reformat-accesskeyscsv-into-awscredentials-format",
            "text": "awk -F, 'BEGIN { print \"[temp_name]\" ; } !/Access/ {print \"aws_access_key_id = \"$1\"\\naws_secret_access_key = \"$2}' ~/Downloads/accessKeys.csv",
            "title": "Reformat accessKeys.csv into .aws/credentials format"
        },
        {
            "location": "/amazon/#see-also",
            "text": "aws cli  CloudFormation",
            "title": "See Also"
        },
        {
            "location": "/amazon/#terms-and-acronyms",
            "text": "Term  Definition      AMI  Amazon Machine Images    ASG  Auto-Scaling Group. Auto Scaling can automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs.    AWS  Amazon Web Services    AZ  Data centers. Amazon Availability Zones.    EBS  Elastic Block Storage. Provides persistent block-level storage volumes for EC2.    EC2  Elastic Compute Cloud    ELB  Elastic Load Balancing    EMR  Elastic MapReduce. Allows easily and cheap processing of vast amounts of data    ETS  Elastic Transcoder. Provides video transcoding of S3 hosted videos    FPS  Flexible Payments Service. Provides an interface for micro payments.    HSM  Hardware Security Module    IAM  Identity and Access Management enables you to securely control access to AWS services and resources for your users. Using IAM, you can create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.    KMS  Key Management Service    MFA  Amazon Web Services Multi-Factor Authentication is a simple best practice that adds an extra layer of protection on top of your user name and password.    RDS  Relational Database Service    RI  Reserved Instance. EC2 instances for which there is a 1 or 3 year contract with AWS to achieve lower hourly run costs.    Route 53  A highly available and scalable cloud Domain Name System (DNS) web service.    S3  Simple Storage Service    SES  Simple Email Service. Provides bulk and transactional email sending.    SG  Security Group. Security Groups in AWS are akin to firewalls.    SNS  Simple Notification Service. Provides a hosted multiprotocol \"push\" messaging for applications.    SQS  Simple Queue Service. Provides a hosted message queue for web applications.    SWF  Simple Workflow. Workflow service for building scalable, resilient applications.    VPC  Virtual Private Cloud",
            "title": "Terms and Acronyms"
        },
        {
            "location": "/amiibo/",
            "text": "Amiibo are NFC figurines that enable in-game features on Nintendo 3DS, Wii U and Switch platforms.\n\n\nInfo\n\n\n\n\nUses NTAG215 RFID chips.\n\n\n\n\nLinks\n\n\n\n\nHow to Mimic Any Amiibo\n\n\nhttps://www.codejunkies.com/powersaves-for-amiibo/\n\n\nhttp://amiibo.wikia.com/wiki/Amiibo_Wiki\n\n\nhttp://nintendo.wikia.com/wiki/List_of_Amiibo_compatible_Games\n\n\nhttps://www.nintendo.com/amiibo/games\n\n\nhttps://nfc-bank.com\n\n\nhttps://github.com/HiddenRamblings/TagMo\n - TagMo is an Android app which allows for cloning Amiibos using blank NTAG215 NFC tags.",
            "title": "Amiibo"
        },
        {
            "location": "/amiibo/#info",
            "text": "Uses NTAG215 RFID chips.",
            "title": "Info"
        },
        {
            "location": "/amiibo/#links",
            "text": "How to Mimic Any Amiibo  https://www.codejunkies.com/powersaves-for-amiibo/  http://amiibo.wikia.com/wiki/Amiibo_Wiki  http://nintendo.wikia.com/wiki/List_of_Amiibo_compatible_Games  https://www.nintendo.com/amiibo/games  https://nfc-bank.com  https://github.com/HiddenRamblings/TagMo  - TagMo is an Android app which allows for cloning Amiibos using blank NTAG215 NFC tags.",
            "title": "Links"
        },
        {
            "location": "/ansible/",
            "text": "https://docs.ansible.com/playbooks_best_practices.html\n\n\nhttps://docs.ansible.com/intro_inventory.html\n\n\nhttp://docs.ansible.com/ansible/latest/list_of_all_modules.html\n\n\nhttps://galaxy.ansible.com\n\n\nhttp://www.azavea.com/blogs/labs/2014/10/creating-ansible-roles-from-scratch-part-1\n\n\nhttp://ryandlane.com/blog/2014/08/04/moving-away-from-puppet-saltstack-or-ansible/",
            "title": "Ansible"
        },
        {
            "location": "/apfs/",
            "text": "Notes here are current as of macOS 10.13, and don't apply specifically to any other devices that run APFS.\n\n\nUsage\n\n\n$ diskutil apfs\n2017-11-04 18:23:55-0700\nUsage:  diskutil [quiet] ap[fs] <verb> <options>\n        where <verb> is as follows:\n\n     list                (Show status of all current APFS Containers)\n     convert             (Nondestructively convert from HFS to APFS)\n     create              (Create a new APFS Container with one APFS Volume)\n     createContainer     (Create a new empty APFS Container)\n     deleteContainer     (Delete an APFS Container and reformat disks to HFS)\n     resizeContainer     (Resize an APFS Container and its disk space usage)\n     addVolume           (Export a new APFS Volume from an APFS Container)\n     deleteVolume        (Remove an APFS Volume from its APFS Container)\n     eraseVolume         (Erase contents of, but keep, an APFS Volume)\n     changeVolumeRole    (Change the Role metadata bits of an APFS Volume)\n     unlockVolume        (Unlock an encrypted APFS Volume which is locked)\n     lockVolume          (Lock an encrypted APFS Volume (diskutil unmount))\n     listCryptoUsers     (List cryptographic users of encrypted APFS Volume)\n     changePassphrase    (Change the passphrase of a cryptographic user)\n     setPassphraseHint   (Set or clear passphrase hint of a cryptographic user)\n     encryptVolume       (Start async encryption of an unencrypted APFS Volume)\n     decryptVolume       (Start async decryption of an encrypted APFS Volume)\n     updatePreboot       (Update the APFS Volume's related APFS Preboot Volume)\n\ndiskutil apfs <verb> with no options will provide help on that verb\n\n\n\n\nFile clones\n\n\nAPFS supports deduplicated file copies, which it calls clonefiles. Copying a file by option-dragging it in Finder creates a clonefile. To create a clonefile on the CLI use \ncp -c src dst\n. Creating clonefiless of any size file is instantaneous because no file data is actually being copied. This differs from hard links because if you modify the clone, only the new blocks will be written to disk, and the source of the cloned file will not be modified.\n\n\nSnapshots\n\n\nSnapshots appear to be tied pretty directly to Time Machine, and do not appear to be general purpose. There appear to be many limitations in how they can be used, and what information you can get about them.\n\n\nThere was previously a tool called \napfs_snapshot\n but it was removed before macOS 10.13 was released.\n\n\nCreate a snapshot\n\n\nYou cannot choose a name for your snapshot, it is tied to the date the snapshot was taken in the form of YYYY-MM-DD-HHMMSS.\n\n\n$ sudo tmutil localsnapshot\nCreated local snapshot with date: 2017-11-04-183728\n\n\n\n\nShow snapshots\n\n\n$ sudo tmutil listlocalsnapshots /\ncom.apple.TimeMachine.2017-11-01-161748\ncom.apple.TimeMachine.2017-11-02-100755\ncom.apple.TimeMachine.2017-11-03-084837\ncom.apple.TimeMachine.2017-11-04-182813\n\n\n\n\nMount a snapshot\n\n\n$ mkdir snap_test\n$ sudo mount_apfs -s com.apple.TimeMachine.2017-11-04-192829 / \"${PWD}/snap_test\"\n\n\n\n\nDelete a snapshot\n\n\nYou can only delete snapshots based off of their date.\n\n\n$ sudo tmutil deletelocalsnapshots 2017-11-04-183813\nDeleted local snapshot '2017-11-04-183813'\n\n\n\n\nDelete all snapshots\n\n\n/usr/bin/tmutil listlocalsnapshots / | while read -r X ; do\n  tmutil deletelocalsnapshots \"${X##*.}\"\ndone\n\n\n\n\nThin out snapshots\n\n\nOn the given drive, reclaim the given space by thinning out snapshots. As of tmutil 4.0.0, you cannot use any data unit other than bytes. (EG: 1G or 1GB will not work)\n\n\n$ sudo tmutil thinlocalsnapshots / 250000000\nThinned local snapshots:\n2017-11-04-184425\n2017-11-04-184433\n2017-11-04-184440\n\n\n\n\nSee also\n\n\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs.util\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs_invert\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs_preflight_converter\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs_stats\n\n\n\n\nLinks\n\n\n\n\nApple File System\n\n\nRich Trouton - Storing our digital lives - Mac filesystems from MFS to APFS\n\n\nApple File System Guide\n\n\nRuss Bishop - Apple File System",
            "title": "Apfs"
        },
        {
            "location": "/apfs/#usage",
            "text": "$ diskutil apfs\n2017-11-04 18:23:55-0700\nUsage:  diskutil [quiet] ap[fs] <verb> <options>\n        where <verb> is as follows:\n\n     list                (Show status of all current APFS Containers)\n     convert             (Nondestructively convert from HFS to APFS)\n     create              (Create a new APFS Container with one APFS Volume)\n     createContainer     (Create a new empty APFS Container)\n     deleteContainer     (Delete an APFS Container and reformat disks to HFS)\n     resizeContainer     (Resize an APFS Container and its disk space usage)\n     addVolume           (Export a new APFS Volume from an APFS Container)\n     deleteVolume        (Remove an APFS Volume from its APFS Container)\n     eraseVolume         (Erase contents of, but keep, an APFS Volume)\n     changeVolumeRole    (Change the Role metadata bits of an APFS Volume)\n     unlockVolume        (Unlock an encrypted APFS Volume which is locked)\n     lockVolume          (Lock an encrypted APFS Volume (diskutil unmount))\n     listCryptoUsers     (List cryptographic users of encrypted APFS Volume)\n     changePassphrase    (Change the passphrase of a cryptographic user)\n     setPassphraseHint   (Set or clear passphrase hint of a cryptographic user)\n     encryptVolume       (Start async encryption of an unencrypted APFS Volume)\n     decryptVolume       (Start async decryption of an encrypted APFS Volume)\n     updatePreboot       (Update the APFS Volume's related APFS Preboot Volume)\n\ndiskutil apfs <verb> with no options will provide help on that verb",
            "title": "Usage"
        },
        {
            "location": "/apfs/#file-clones",
            "text": "APFS supports deduplicated file copies, which it calls clonefiles. Copying a file by option-dragging it in Finder creates a clonefile. To create a clonefile on the CLI use  cp -c src dst . Creating clonefiless of any size file is instantaneous because no file data is actually being copied. This differs from hard links because if you modify the clone, only the new blocks will be written to disk, and the source of the cloned file will not be modified.",
            "title": "File clones"
        },
        {
            "location": "/apfs/#snapshots",
            "text": "Snapshots appear to be tied pretty directly to Time Machine, and do not appear to be general purpose. There appear to be many limitations in how they can be used, and what information you can get about them.  There was previously a tool called  apfs_snapshot  but it was removed before macOS 10.13 was released.",
            "title": "Snapshots"
        },
        {
            "location": "/apfs/#create-a-snapshot",
            "text": "You cannot choose a name for your snapshot, it is tied to the date the snapshot was taken in the form of YYYY-MM-DD-HHMMSS.  $ sudo tmutil localsnapshot\nCreated local snapshot with date: 2017-11-04-183728",
            "title": "Create a snapshot"
        },
        {
            "location": "/apfs/#show-snapshots",
            "text": "$ sudo tmutil listlocalsnapshots /\ncom.apple.TimeMachine.2017-11-01-161748\ncom.apple.TimeMachine.2017-11-02-100755\ncom.apple.TimeMachine.2017-11-03-084837\ncom.apple.TimeMachine.2017-11-04-182813",
            "title": "Show snapshots"
        },
        {
            "location": "/apfs/#mount-a-snapshot",
            "text": "$ mkdir snap_test\n$ sudo mount_apfs -s com.apple.TimeMachine.2017-11-04-192829 / \"${PWD}/snap_test\"",
            "title": "Mount a snapshot"
        },
        {
            "location": "/apfs/#delete-a-snapshot",
            "text": "You can only delete snapshots based off of their date.  $ sudo tmutil deletelocalsnapshots 2017-11-04-183813\nDeleted local snapshot '2017-11-04-183813'",
            "title": "Delete a snapshot"
        },
        {
            "location": "/apfs/#delete-all-snapshots",
            "text": "/usr/bin/tmutil listlocalsnapshots / | while read -r X ; do\n  tmutil deletelocalsnapshots \"${X##*.}\"\ndone",
            "title": "Delete all snapshots"
        },
        {
            "location": "/apfs/#thin-out-snapshots",
            "text": "On the given drive, reclaim the given space by thinning out snapshots. As of tmutil 4.0.0, you cannot use any data unit other than bytes. (EG: 1G or 1GB will not work)  $ sudo tmutil thinlocalsnapshots / 250000000\nThinned local snapshots:\n2017-11-04-184425\n2017-11-04-184433\n2017-11-04-184440",
            "title": "Thin out snapshots"
        },
        {
            "location": "/apfs/#see-also",
            "text": "/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs.util\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs_invert\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs_preflight_converter\n/System/Library/Filesystems/apfs.fs/Contents/Resources/apfs_stats",
            "title": "See also"
        },
        {
            "location": "/apfs/#links",
            "text": "Apple File System  Rich Trouton - Storing our digital lives - Mac filesystems from MFS to APFS  Apple File System Guide  Russ Bishop - Apple File System",
            "title": "Links"
        },
        {
            "location": "/aptly/",
            "text": "\"Aptly is a swiss army knife for Debian repository management.\"\n\n\nhttps://github.com/sepulworld/aptly-vagrant",
            "title": "Aptly"
        },
        {
            "location": "/atomicparsley/",
            "text": "AtomicParsley\n\n\nAtomicParsley\n is a lightweight command line program for reading, parsing and setting metadata into MPEG-4 files. This is a functional mp4 equivalent of what \ni3dv2\n is for mp3 files.\n\n\nExamples\n\n\nSet metadata on multiple files\n\n\nUnfortunately the syntax of this tool requires you to edit one file at a time, so you have to iterate each item of an album using shell loops or \nxargs\n or whatever you prefer.\n\n\nfor file in *.m4a ; do\n  AtomicParsley \"${file}\" --artist \"Various Artists\" ;\ndone ;\n\n\n\n\nRemove Personally Identifiable Information (pii) from files\n\n\nUseful if you want to remove your personal info from iTunes Match files.\n\n\nfor file in *.m4a ; do\n  AtomicParsley \\\n    \"$file\" \\\n    --DeepScan \\\n    --manualAtomRemove \"moov.trak.mdia.minf.stbl.mp4a.pinf\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.----.name:[iTunMOVI]\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.apID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.atID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.cnID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.cprt\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.flvr\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.geID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.plID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.purd\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.rtng\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.sfID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.soal\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.stik\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.xid\" \\\ndone",
            "title": "AtomicParsley"
        },
        {
            "location": "/atomicparsley/#atomicparsley",
            "text": "AtomicParsley  is a lightweight command line program for reading, parsing and setting metadata into MPEG-4 files. This is a functional mp4 equivalent of what  i3dv2  is for mp3 files.",
            "title": "AtomicParsley"
        },
        {
            "location": "/atomicparsley/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/atomicparsley/#set-metadata-on-multiple-files",
            "text": "Unfortunately the syntax of this tool requires you to edit one file at a time, so you have to iterate each item of an album using shell loops or  xargs  or whatever you prefer.  for file in *.m4a ; do\n  AtomicParsley \"${file}\" --artist \"Various Artists\" ;\ndone ;",
            "title": "Set metadata on multiple files"
        },
        {
            "location": "/atomicparsley/#remove-personally-identifiable-information-pii-from-files",
            "text": "Useful if you want to remove your personal info from iTunes Match files.  for file in *.m4a ; do\n  AtomicParsley \\\n    \"$file\" \\\n    --DeepScan \\\n    --manualAtomRemove \"moov.trak.mdia.minf.stbl.mp4a.pinf\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.----.name:[iTunMOVI]\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.apID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.atID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.cnID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.cprt\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.flvr\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.geID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.plID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.purd\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.rtng\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.sfID\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.soal\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.stik\" \\\n    --manualAtomRemove \"moov.udta.meta.ilst.xid\" \\\ndone",
            "title": "Remove Personally Identifiable Information (pii) from files"
        },
        {
            "location": "/atop/",
            "text": "\"Atop is an ASCII full-screen performance monitor for Linux that is capable of reporting the activity of all processes (even if processes have finished during the interval), daily logging of system and process activity for long-term analysis, highlighting overloaded system resources by using colors, etc.\" - \nhttps://www.atoptool.nl/\n\n\nThe feature that sets atop apart from other process \ntop\n tools is that it catches short-lived processes that would be left out of period sampling that other tools use.\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Atop"
        },
        {
            "location": "/atop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/avahi/",
            "text": "The Avahi \nmDNS/DNS-SD\n daemon implements Apple's Zeroconf architecture (also known as \"Rendezvous\" or \"Bonjour\").\n\n\nTips\n\n\nAfter installing avahi-daemon it may not start. To fix this you may need to run \nservice messagebus start\n\n\nService types\n are defined in \n/usr/share/avahi/service-types\n\n\nService configs\n\n\nCorrectly formatted and named files in \n/etc/avahi/services/whatever.service\n are loaded on the fly, no need to restart \navahi-daemon\n. If your service doesn't immediately show up, check syslog for errors.\n\n\n<?xml version=\"1.0\" standalone='no'?><!--*-nxml-*-->\n<!DOCTYPE service-group SYSTEM \"avahi-service.dtd\">\n<service-group>\n  <name replace-wildcards=\"yes\">%h</name>\n  <service>\n    <type>_ssh._tcp</type>\n    <port>22</port>\n  </service>\n  <service>\n    <type>_http._tcp</type>\n    <port>80</port>\n  </service>\n</service-group>",
            "title": "Avahi"
        },
        {
            "location": "/avahi/#tips",
            "text": "After installing avahi-daemon it may not start. To fix this you may need to run  service messagebus start  Service types  are defined in  /usr/share/avahi/service-types",
            "title": "Tips"
        },
        {
            "location": "/avahi/#service-configs",
            "text": "Correctly formatted and named files in  /etc/avahi/services/whatever.service  are loaded on the fly, no need to restart  avahi-daemon . If your service doesn't immediately show up, check syslog for errors.  <?xml version=\"1.0\" standalone='no'?><!--*-nxml-*-->\n<!DOCTYPE service-group SYSTEM \"avahi-service.dtd\">\n<service-group>\n  <name replace-wildcards=\"yes\">%h</name>\n  <service>\n    <type>_ssh._tcp</type>\n    <port>22</port>\n  </service>\n  <service>\n    <type>_http._tcp</type>\n    <port>80</port>\n  </service>\n</service-group>",
            "title": "Service configs"
        },
        {
            "location": "/awk/",
            "text": "\"pattern-directed scanning and processing language\" - \nman awk\n\n\nExamples\n\n\nSome of these require GNU awk.\n\n\nPrint the first column of a file\n\n\nawk '${print $1}' filename.txt\n\n\n\n\nPrint column 2 if column 1 matches a string\n\n\nps aux | awk '$1 == \"root\" {print $2}'\n\n\n\n\nSort a file by line lengths\n\n\nawk\u00a0'{print\u00a0length,\u00a0$0}' testfile.txt\u00a0|\u00a0sort\u00a0-n\n\n\n\n\nTDL to CSV\n\n\nawk '{gsub(\"\\t\",\"\\\",\\\"\",$0); print;}' | sed 's#^#\"#;s#$#\"#;'\n\n\n\n\nPrint the first column of every other line\n\n\n% is the modulus operator, which finds the remainder after an integer\ndivide.\n\n\nawk\u00a0'NR\u00a0%\u00a02\u00a0==\u00a00\u00a0{\u00a0print\u00a0$1\u00a0}'\n\n\n\n\nPrint only even numbered lines\n\n\nls\u00a0|\u00a0awk\u00a0'NR\u00a0%\u00a02\u00a0==\u00a00\u00a0{\u00a0print\u00a0$0\u00a0}'\n\n\n\n\nPrint only odd numbered lines\n\n\nls\u00a0|\u00a0awk\u00a0'NR\u00a0%\u00a02\u00a0!=\u00a00\u00a0{\u00a0print\u00a0$0\u00a0}'\n\n\n\n\nPrint even numbered lines on the same line before odd numbered lines\n\n\nawk\u00a0'{if\u00a0(NR%2==0)\u00a0{\u00a0print\u00a0$0\u00a0\"\u00a0\"\u00a0prev\u00a0}\u00a0else\u00a0{\u00a0prev=$0\u00a0}}'\n\n\n\n\nSum all the first columns of each line in a file\n\n\nawk\u00a0'{sum\u00a0+=\u00a0$1}\u00a0END\u00a0{print\u00a0sum}'\u00a0filename\n\n\n\n\nSplit file by recurring string\n\n\nThis will create a new file every time the string \"SERVER\" is found, essentially splitting the file by that string. Concatenating all of the output files would create the original file (potentially adding an extra newline).\n\n\nawk '/SERVER/{n++}{print >\"out\" sprintf(\"%02d\", n) \".txt\" }' example.txt\n\n\n\n\nShow count of syslog messages per minute\n\n\nawk\u00a0-F:\u00a0{'print\u00a0$1\u00a0`\u201c`:`\u201d`\u00a0$2'}\u00a0/var/log/messages\u00a0|uniq\u00a0-c\n\n\n\n\nShow count of root logins per minute\n\n\nawk -F: '/root/{print $1 \":\" $2}' /var/log/auth.log |uniq -c\n\n\n\n\nPrint lines in ls where UID is numeric\n\n\nls\u00a0-la\u00a0|\u00a0awk\u00a0'$3\u00a0~/[0-9]/{print}'\n\n\n\n\nShow only zfs snapshots whose size is zero\n\n\nzfs\u00a0list\u00a0-t\u00a0snapshot\u00a0|\u00a0awk\u00a0'$2\u00a0==\u00a00'\n\n\n\n\nPrint a line if the third field does not match a regex\n\n\ntcpdump\u00a0-r\u00a0ops1prod-syn.cap\u00a0|\u00a0sort\u00a0-k2\u00a0|\u00a0awk\u00a0'$3\u00a0!~\u00a0/ztmis.prod/\u00a0{\u00a0print\u00a0}'\n\n\n\n\nShow 500 errors in a standard apache access log\n\n\nawk\u00a0'$9\u00a0~\u00a0/5[0-9][0-9]/'\u00a0www_zoosk_access.log\n\n\n\n\nShow total rss and vsz count for all cronolog processes\n\n\nps\u00a0aux\u00a0|\n  grep\u00a0-i\u00a0cronolo[g]\u00a0|\n  awk\u00a0'{vsz\u00a0+=\u00a0$5;\u00a0rss\u00a0+=\u00a0$6}\u00a0END\u00a0{print\u00a0\"vsz\u00a0total\u00a0=\u00a0\"vsz\u00a0;\u00a0print\u00a0\"rss\u00a0total\u00a0=\u00a0\"rss}'\n\n\n\n\nGet IPv4 address on BSD/OSX\n\n\nifconfig | awk '$1 == \"inet\" && $2 != \"127.0.0.1\" {print $2}'\n\n\n\n\nGet IPv6 address on BSD/OSX\n\n\nifconfig | awk '$1 == \"inet6\" && $2 !~ \"::1|.*lo\" {print $2}'\n\n\n\n\nPrint the last element\n\n\nls\u00a0-la\u00a0|\u00a0awk\u00a0-F\"\u00a0\"\u00a0'{print\u00a0$NF}'\n\n\n\n\nPrint 2nd to last element\n\n\nls\u00a0-la\u00a0|\u00a0awk\u00a0-F\"\u00a0\"\u00a0'{print\u00a0$(NF\u00a0-\u00a01)}'\n\n\n\n\nPrint the previous line on string match\n\n\nThis works by storing the previous line. If the current line matches the regex, the previous line is printed from the stored value.\n\n\n$ awk '/32 host/ { print previous_line } {previous_line=$0}' /proc/net/fib_trie | column -t | sort -u\n|--  10.134.243.137\n|--  127.0.0.1\n|--  169.50.9.172\n\n\n\n\nSee Also\n\n\n\n\nhttp://www.grymoire.com/Unix/Awk.html",
            "title": "Awk"
        },
        {
            "location": "/awk/#examples",
            "text": "Some of these require GNU awk.",
            "title": "Examples"
        },
        {
            "location": "/awk/#print-the-first-column-of-a-file",
            "text": "awk '${print $1}' filename.txt",
            "title": "Print the first column of a file"
        },
        {
            "location": "/awk/#print-column-2-if-column-1-matches-a-string",
            "text": "ps aux | awk '$1 == \"root\" {print $2}'",
            "title": "Print column 2 if column 1 matches a string"
        },
        {
            "location": "/awk/#sort-a-file-by-line-lengths",
            "text": "awk\u00a0'{print\u00a0length,\u00a0$0}' testfile.txt\u00a0|\u00a0sort\u00a0-n",
            "title": "Sort a file by line lengths"
        },
        {
            "location": "/awk/#tdl-to-csv",
            "text": "awk '{gsub(\"\\t\",\"\\\",\\\"\",$0); print;}' | sed 's#^#\"#;s#$#\"#;'",
            "title": "TDL to CSV"
        },
        {
            "location": "/awk/#print-the-first-column-of-every-other-line",
            "text": "% is the modulus operator, which finds the remainder after an integer\ndivide.  awk\u00a0'NR\u00a0%\u00a02\u00a0==\u00a00\u00a0{\u00a0print\u00a0$1\u00a0}'",
            "title": "Print the first column of every other line"
        },
        {
            "location": "/awk/#print-only-even-numbered-lines",
            "text": "ls\u00a0|\u00a0awk\u00a0'NR\u00a0%\u00a02\u00a0==\u00a00\u00a0{\u00a0print\u00a0$0\u00a0}'",
            "title": "Print only even numbered lines"
        },
        {
            "location": "/awk/#print-only-odd-numbered-lines",
            "text": "ls\u00a0|\u00a0awk\u00a0'NR\u00a0%\u00a02\u00a0!=\u00a00\u00a0{\u00a0print\u00a0$0\u00a0}'",
            "title": "Print only odd numbered lines"
        },
        {
            "location": "/awk/#print-even-numbered-lines-on-the-same-line-before-odd-numbered-lines",
            "text": "awk\u00a0'{if\u00a0(NR%2==0)\u00a0{\u00a0print\u00a0$0\u00a0\"\u00a0\"\u00a0prev\u00a0}\u00a0else\u00a0{\u00a0prev=$0\u00a0}}'",
            "title": "Print even numbered lines on the same line before odd numbered lines"
        },
        {
            "location": "/awk/#sum-all-the-first-columns-of-each-line-in-a-file",
            "text": "awk\u00a0'{sum\u00a0+=\u00a0$1}\u00a0END\u00a0{print\u00a0sum}'\u00a0filename",
            "title": "Sum all the first columns of each line in a file"
        },
        {
            "location": "/awk/#split-file-by-recurring-string",
            "text": "This will create a new file every time the string \"SERVER\" is found, essentially splitting the file by that string. Concatenating all of the output files would create the original file (potentially adding an extra newline).  awk '/SERVER/{n++}{print >\"out\" sprintf(\"%02d\", n) \".txt\" }' example.txt",
            "title": "Split file by recurring string"
        },
        {
            "location": "/awk/#show-count-of-syslog-messages-per-minute",
            "text": "awk\u00a0-F:\u00a0{'print\u00a0$1\u00a0`\u201c`:`\u201d`\u00a0$2'}\u00a0/var/log/messages\u00a0|uniq\u00a0-c",
            "title": "Show count of syslog messages per minute"
        },
        {
            "location": "/awk/#show-count-of-root-logins-per-minute",
            "text": "awk -F: '/root/{print $1 \":\" $2}' /var/log/auth.log |uniq -c",
            "title": "Show count of root logins per minute"
        },
        {
            "location": "/awk/#print-lines-in-ls-where-uid-is-numeric",
            "text": "ls\u00a0-la\u00a0|\u00a0awk\u00a0'$3\u00a0~/[0-9]/{print}'",
            "title": "Print lines in ls where UID is numeric"
        },
        {
            "location": "/awk/#show-only-zfs-snapshots-whose-size-is-zero",
            "text": "zfs\u00a0list\u00a0-t\u00a0snapshot\u00a0|\u00a0awk\u00a0'$2\u00a0==\u00a00'",
            "title": "Show only zfs snapshots whose size is zero"
        },
        {
            "location": "/awk/#print-a-line-if-the-third-field-does-not-match-a-regex",
            "text": "tcpdump\u00a0-r\u00a0ops1prod-syn.cap\u00a0|\u00a0sort\u00a0-k2\u00a0|\u00a0awk\u00a0'$3\u00a0!~\u00a0/ztmis.prod/\u00a0{\u00a0print\u00a0}'",
            "title": "Print a line if the third field does not match a regex"
        },
        {
            "location": "/awk/#show-500-errors-in-a-standard-apache-access-log",
            "text": "awk\u00a0'$9\u00a0~\u00a0/5[0-9][0-9]/'\u00a0www_zoosk_access.log",
            "title": "Show 500 errors in a standard apache access log"
        },
        {
            "location": "/awk/#show-total-rss-and-vsz-count-for-all-cronolog-processes",
            "text": "ps\u00a0aux\u00a0|\n  grep\u00a0-i\u00a0cronolo[g]\u00a0|\n  awk\u00a0'{vsz\u00a0+=\u00a0$5;\u00a0rss\u00a0+=\u00a0$6}\u00a0END\u00a0{print\u00a0\"vsz\u00a0total\u00a0=\u00a0\"vsz\u00a0;\u00a0print\u00a0\"rss\u00a0total\u00a0=\u00a0\"rss}'",
            "title": "Show total rss and vsz count for all cronolog processes"
        },
        {
            "location": "/awk/#get-ipv4-address-on-bsdosx",
            "text": "ifconfig | awk '$1 == \"inet\" && $2 != \"127.0.0.1\" {print $2}'",
            "title": "Get IPv4 address on BSD/OSX"
        },
        {
            "location": "/awk/#get-ipv6-address-on-bsdosx",
            "text": "ifconfig | awk '$1 == \"inet6\" && $2 !~ \"::1|.*lo\" {print $2}'",
            "title": "Get IPv6 address on BSD/OSX"
        },
        {
            "location": "/awk/#print-the-last-element",
            "text": "ls\u00a0-la\u00a0|\u00a0awk\u00a0-F\"\u00a0\"\u00a0'{print\u00a0$NF}'",
            "title": "Print the last element"
        },
        {
            "location": "/awk/#print-2nd-to-last-element",
            "text": "ls\u00a0-la\u00a0|\u00a0awk\u00a0-F\"\u00a0\"\u00a0'{print\u00a0$(NF\u00a0-\u00a01)}'",
            "title": "Print 2nd to last element"
        },
        {
            "location": "/awk/#print-the-previous-line-on-string-match",
            "text": "This works by storing the previous line. If the current line matches the regex, the previous line is printed from the stored value.  $ awk '/32 host/ { print previous_line } {previous_line=$0}' /proc/net/fib_trie | column -t | sort -u\n|--  10.134.243.137\n|--  127.0.0.1\n|--  169.50.9.172",
            "title": "Print the previous line on string match"
        },
        {
            "location": "/awk/#see-also",
            "text": "http://www.grymoire.com/Unix/Awk.html",
            "title": "See Also"
        },
        {
            "location": "/awless/",
            "text": "\"A Mighty CLI for AWS\" - \nhttps://github.com/wallix/awless\n\n\nExamples\n\n\n\n\nExample templates - \nhttps://github.com/wallix/awless-templates\n\n\n\n\nA lot of these syntax examples can be found by issuing the command, verb and entity but no parameters. Such as \nawless create stack\n, which will drop you into a prompt series to complete the necessary and optional parameters.\n\n\nList ec2 instances sorted by uptime\n\n\n$ awless list instances --sort=uptime\n|         ID          |    ZONE    |           NAME          |  STATE  |    TYPE    | PUBLIC IP |   PRIVATE IP  | UPTIME \u25b2 | KEYPAIR |\n|---------------------|------------|-------------------------|---------|------------|-----------|---------------|----------|---------|\n| i-050ad501b33c6ad07 | us-west-1a | faruko-nal              | running | m4.xlarge  |           | 172.19.15.172 | 85 mins  | foo-ops |\n| i-5b381e9b          | us-west-1b | planted-collector11.foo | running | m4.xlarge  |           | 172.27.26.159 | 6 days   | foo-ops |\n| i-04ced9880586c009b | us-west-1a | hadoop07.foo            | running | m4.4xlarge |           | 172.27.37.100 | 8 days   | foo-ops |\n| i-0e583dcd3bc2444d8 | us-west-1a | db-na-historical06.foo  | running | m2.4xlarge |           | 172.19.48.79  | 12 days  | foo-ops |\n\n\n\n\nSum the amount of unattached disks in your environment\n\n\nawless list volumes \\\n    --filter state=available \\\n    --format json |\n  jq .[].Size |\n  awk '{sum += $1 ; count += 1 ;} END {print sum \"G in \" count \" volumes\"}'\n\n\n\n\nSwitch to a different AWS profile\n\n\nThis uses the ~/.aws/credentials file for its profiles\n\n\nShort way:\n\n\nawless switch prod\n\n\n\n\nLong way:\n\n\nawless config set aws.profile prod\n\n\n\n\nCustomize output columns\n\n\nawless list instances --columns name,type,launched\n\n\n\n\nAdd a user to a group\n\n\nawless --aws-profile govcloud --aws-region us-gov-west-1 attach user group=SystemAdministrators name=SpaceGhost\n\n\n\n\nCreate an access key for a user\n\n\nThis creates an access key and saves it in \n~/.aws/credentials\n\n\nawless --aws-profile govcloud --aws-region us-gov-west-1 create accesskey user=SpaceGhost save=true\n\n\n\n\nCreate a tag\n\n\nawless create tag key=test_tag resource=i-9ba90158 value=true\n\n\n\n\nDelete a tag\n\n\nawless delete tag key=test_tag_dhoherd resource=i-9ba90158\n\n\n\n\nCreate an instance\n\n\nawless create instance count=1 image=ami-5ab82fa8 keypair=ops name=new-hostname securitygroup=[sg-c4321fd1,sg-c4321cb0] subnet=subnet-c4321c33 type=t2.medium",
            "title": "Awless"
        },
        {
            "location": "/awless/#examples",
            "text": "Example templates -  https://github.com/wallix/awless-templates   A lot of these syntax examples can be found by issuing the command, verb and entity but no parameters. Such as  awless create stack , which will drop you into a prompt series to complete the necessary and optional parameters.",
            "title": "Examples"
        },
        {
            "location": "/awless/#list-ec2-instances-sorted-by-uptime",
            "text": "$ awless list instances --sort=uptime\n|         ID          |    ZONE    |           NAME          |  STATE  |    TYPE    | PUBLIC IP |   PRIVATE IP  | UPTIME \u25b2 | KEYPAIR |\n|---------------------|------------|-------------------------|---------|------------|-----------|---------------|----------|---------|\n| i-050ad501b33c6ad07 | us-west-1a | faruko-nal              | running | m4.xlarge  |           | 172.19.15.172 | 85 mins  | foo-ops |\n| i-5b381e9b          | us-west-1b | planted-collector11.foo | running | m4.xlarge  |           | 172.27.26.159 | 6 days   | foo-ops |\n| i-04ced9880586c009b | us-west-1a | hadoop07.foo            | running | m4.4xlarge |           | 172.27.37.100 | 8 days   | foo-ops |\n| i-0e583dcd3bc2444d8 | us-west-1a | db-na-historical06.foo  | running | m2.4xlarge |           | 172.19.48.79  | 12 days  | foo-ops |",
            "title": "List ec2 instances sorted by uptime"
        },
        {
            "location": "/awless/#sum-the-amount-of-unattached-disks-in-your-environment",
            "text": "awless list volumes \\\n    --filter state=available \\\n    --format json |\n  jq .[].Size |\n  awk '{sum += $1 ; count += 1 ;} END {print sum \"G in \" count \" volumes\"}'",
            "title": "Sum the amount of unattached disks in your environment"
        },
        {
            "location": "/awless/#switch-to-a-different-aws-profile",
            "text": "This uses the ~/.aws/credentials file for its profiles  Short way:  awless switch prod  Long way:  awless config set aws.profile prod",
            "title": "Switch to a different AWS profile"
        },
        {
            "location": "/awless/#customize-output-columns",
            "text": "awless list instances --columns name,type,launched",
            "title": "Customize output columns"
        },
        {
            "location": "/awless/#add-a-user-to-a-group",
            "text": "awless --aws-profile govcloud --aws-region us-gov-west-1 attach user group=SystemAdministrators name=SpaceGhost",
            "title": "Add a user to a group"
        },
        {
            "location": "/awless/#create-an-access-key-for-a-user",
            "text": "This creates an access key and saves it in  ~/.aws/credentials  awless --aws-profile govcloud --aws-region us-gov-west-1 create accesskey user=SpaceGhost save=true",
            "title": "Create an access key for a user"
        },
        {
            "location": "/awless/#create-a-tag",
            "text": "awless create tag key=test_tag resource=i-9ba90158 value=true",
            "title": "Create a tag"
        },
        {
            "location": "/awless/#delete-a-tag",
            "text": "awless delete tag key=test_tag_dhoherd resource=i-9ba90158",
            "title": "Delete a tag"
        },
        {
            "location": "/awless/#create-an-instance",
            "text": "awless create instance count=1 image=ami-5ab82fa8 keypair=ops name=new-hostname securitygroup=[sg-c4321fd1,sg-c4321cb0] subnet=subnet-c4321c33 type=t2.medium",
            "title": "Create an instance"
        },
        {
            "location": "/aws-cloudformation/",
            "text": "\"AWS CloudFormation is a service that helps you model and set up your Amazon Web Services resources so that you can spend less time managing those resources and more time focusing on your applications that run in AWS.\" - \nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html\n\n\nLinks\n\n\n\n\nhttp://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.html\n\n\nCloudFormer\n - CloudFormer is a template creation beta tool that creates an AWS CloudFormation template from existing AWS resources in your account. You select any supported AWS resources that are running in your account, and CloudFormer creates a template in an Amazon S3 bucket.\n\n\nSceptre\n - Sceptre is a tool to drive Cloudformation. Sceptre manages the creating, updating and deletion of stacks, and provides meta commands to allow users to get information about their stacks.",
            "title": "Aws cloudformation"
        },
        {
            "location": "/aws-cloudformation/#links",
            "text": "http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/best-practices.html  CloudFormer  - CloudFormer is a template creation beta tool that creates an AWS CloudFormation template from existing AWS resources in your account. You select any supported AWS resources that are running in your account, and CloudFormer creates a template in an Amazon S3 bucket.  Sceptre  - Sceptre is a tool to drive Cloudformation. Sceptre manages the creating, updating and deletion of stacks, and provides meta commands to allow users to get information about their stacks.",
            "title": "Links"
        },
        {
            "location": "/awscli/",
            "text": "Official Amazon AWS command-line interface - \nhttps://aws.amazon.com/cli\n\n\nExample usage\n\n\nShow subnets for a particular region and account\n\n\naws --profile=dev --region=us-west-2 ec2 describe-subnets\n\n\n\n\nSee Also\n\n\n\n\nAmazon",
            "title": "Awscli"
        },
        {
            "location": "/awscli/#example-usage",
            "text": "",
            "title": "Example usage"
        },
        {
            "location": "/awscli/#show-subnets-for-a-particular-region-and-account",
            "text": "aws --profile=dev --region=us-west-2 ec2 describe-subnets",
            "title": "Show subnets for a particular region and account"
        },
        {
            "location": "/awscli/#see-also",
            "text": "Amazon",
            "title": "See Also"
        },
        {
            "location": "/backups/",
            "text": "Data backup notes.\n\n\nLinks\n\n\n\n\nhttp://duplicity.nongnu.org\n\n\nhttps://www.nixtutor.com/linux/off-site-encrypted-backups-using-rsync-and-aes\n\n\nhttp://www.nongnu.org/rdiff-backup",
            "title": "Backups"
        },
        {
            "location": "/backups/#links",
            "text": "http://duplicity.nongnu.org  https://www.nixtutor.com/linux/off-site-encrypted-backups-using-rsync-and-aes  http://www.nongnu.org/rdiff-backup",
            "title": "Links"
        },
        {
            "location": "/badblocks/",
            "text": "badblocks is a program to test storage devices for bad blocks. - \nhttps://wiki.archlinux.org/index.php/badblocks\n\n\nExamples\n\n\nDestroy all data on a disk while logging bad blocks\n\n\n# -v verbose output writes error info to stderr\n# -s show scan progress, including percent complete, time elapsed, and error count\n# -w destructive write test, vs -n (nondestructive read/write test)\n# -b 4096 byte blocks\n# -t random test pattern\n# -o output file containing list of bad blocks, which can be passed back to badblocks, fsck or mke2fs\nbadblocks -v -s -w -b 4096 -t random -o ~/sdc.txt /dev/sdc\n\n\n\n\nSee also\n\n\n\n\ndcfldd\n\n\ndd\n\n\nddrescue\n\n\npv",
            "title": "Badblocks"
        },
        {
            "location": "/badblocks/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/badblocks/#destroy-all-data-on-a-disk-while-logging-bad-blocks",
            "text": "# -v verbose output writes error info to stderr\n# -s show scan progress, including percent complete, time elapsed, and error count\n# -w destructive write test, vs -n (nondestructive read/write test)\n# -b 4096 byte blocks\n# -t random test pattern\n# -o output file containing list of bad blocks, which can be passed back to badblocks, fsck or mke2fs\nbadblocks -v -s -w -b 4096 -t random -o ~/sdc.txt /dev/sdc",
            "title": "Destroy all data on a disk while logging bad blocks"
        },
        {
            "location": "/badblocks/#see-also",
            "text": "dcfldd  dd  ddrescue  pv",
            "title": "See also"
        },
        {
            "location": "/bash/",
            "text": "This doc has been automatically converted and still needs some cleanup.\n\n\nBash is the most common mainstream *nix shell.\n\n\nTricks and Usage\n\n\nNavigating on the command line\n\n\nThe following can be seen by running: \nstty -a\n\n\n\n\nctrl-a - move cursor to the beginning of the line\n\n\nctrl-e - move cursor to the end of the line\n\n\nctrl-l - do a \"clear\" on the terminal window\n\n\nctrl-r - reverse history command search\n\n\nctrl-t - get status of foreground process\n\n\nctrl-w - delete previous word\n\n\n\n\nView a list of all commands, etc..\n\n\n\n\ncompgen -b\n will list all the built-ins you could run.\n\n\ncompgen -a\n will list all the aliases you could run.\n\n\ncompgen -c\n will list all the commands you could run.\n\n\ncompgen -k\n will list all the keywords you could run.\n\n\ncompgen -A\n function will list all the functions you could run.\n\n\ncompgen -back\n will list all the above in one go.\n\n\n\n\nRemove leading zeroes\n\n\nfor X in 00{1..20..2} ; do\n  echo \"$X == $((10#${X}))\" ;\ndone ;\n\n\n\n\nOr...\n\n\nfor X in {1..50..5} ; do\n  Y=00${X} ;\n  echo \"${X} with zeroes is ${Y} and removed with bc is $(echo ${Y} | bc)\" ;\ndone ;\n\n\n\n\nConvert base 36 to decimal\n\n\nThis converts the base 36 number z to a decimal value\n\n\necho $((36#z))\n\n\nRun a command for 5 seconds, then kill it\n\n\nping -f & sleep 5 ; kill %1\n\n\nAlternatively, use the timeout command if it's available. In macOS this can be installed through \nhomebrew install coreutils\n and accessed with \ngtimeout\n.\n\n\ntimeout 300 cmd\n\n\nTest if a variable is empty\n\n\nif [[ -z \"$var\" ]]\n\n\nDate\n\n\nFor date stuff, see date, because it's different depending on platform.\n\n\nShow RANDOM statistics\n\n\nfor X in {0..9999} ; do\n  echo $(($RANDOM % 5)) ;\ndone |\nsort |\nuniq -c\n\n\n\n\nnamed pipes\n\n\nmkfifo baz ; ps aux > baz\n then in another terminal \ncat baz\n\n\nalternate redirection outputs\n\n\nexec 3> /tmp/baz ; ps aux >&3 # sends the output of ps aux to /tmp/baz\n\n\nRedirect all output of a script into a file\n\n\nThis is not bash specific, but works in bash.\n\n\n#!/usr/bin/env bash\n\nexec >> /tmp/$0.log\nexec 2>&1\n\ndate \"+%F %T%z $0 This is stdout\"\ndate \"+%F %T%z $0 This is stderr\" >&2\n\n\n\n\nShow size of each user's home folder\n\n\ngetent passwd |\nwhile IFS=: read -r user _ uid _ _ home _ ; do\n  if [[ $uid -ge 500 ]] ; then\n    printf \"$user \" ;\n    sudo du -sh $home ;\n  fi ;\ndone\n\n\n\n\nPrevious command's args\n\n\nmkdir temp ; cd !!:*\n\n\nBe aware of the location of the tokens. eg: \nmkdir -p {foo,bar}/{a,b,c} ; stat !!:*\n creates a problem because you can't \nstat -p\n so you must \nstat -p !!:2*\n\n\nDebug a script\n\n\nThis will show everything bash is executing\n\n\nbash -x scriptname.sh\n\n\nOr debug with a function:\n\n\nfunction debug { if [ ${debug:-0} -gt 0 ] ; then echo $@ 2>&1 ; fi ; }\n\n\nFind where all the inodes are\n\n\nfind ~/ -type d -print0 |\nxargs -I %% -0 bash -c \"echo -n %% ; ls -a '%%' | wc -l\" >> ~/inodes.txt\n\n\n\n\nBuild and print an array\n\n\narray=(\"one is the first element\");\narray+=(\"two is the second element\" \"three is the third\");\necho \"${array[@]}\"\n\n\n\n\nThis is useful for building command line strings. For example, \ngpsbabel\n requires each input file to be prepended with \n-f\n. The following script takes a list of files and uses a bash array to create a command line in the form of \ngpsbabel -i gpx -f input_file_1.gpx -f input_file_2.gpx -o gpx -F output.gpx\n\n\n#!/usr/bin/env bash\n\n# Check for at least one argument, print usage if fail\nif [ $# -lt 2 ] ; then\n    echo \"This script merges gpx files and requires at least two gpx files passed as arguments. Output is output.gpx\";\n    echo \"Usage:    $0 <gpx file> <gpx file> [...<gpx file>]\";\n    exit 1;\nfi\n\n# Create an array of arguments to pass to gpsbabel\nargs=();\nfor item in \"$@\" ; do\n    if [ -f \"$item\" ] || [ -h \"$item\" ] ; then\n        args+=( \"-f\" \"$item\" );\n    else\n        echo \"Skipping $item, it's not a file or symlink.\"\n    fi\ndone;\n\n### Verify we have at least two files to work with\nif [ \"${#args[@]}\" -lt 4 ] ; then\n    echo \"We don't have enough actual files to work with. Exiting.\"\n    exit 1\nfi\n\ngpsbabel -i gpx \"${args[@]}\" -o gpx -F output.gpx\n\n\n\n\nBuild and print an associative array (dict, hash)\n\n\ndeclare -A animals=(\n  [\"cow\"]=\"moo\"\n  [\"dog\"]=\"woof woof\"\n  [\"cat\"]=\"meow\"\n) ;\nfor animal in \"${!animals[@]}\" ; do\n  echo \"The $animal says '${animals[$animal]}'\" ;\ndone ;\n\n\n\n\nShow permissions in rwx and octal format\n\n\n\n\nLinux: \nstat -c '%A %a %n' filename\n\n\nOSX: \nstat -f '%A %N' filename\n\n\n\n\nFind the length of a variable\n\n\necho ${#SHELL}\n\n\nPrint all variables that start with the substring \nSH\n\n\necho ${!SH*}\n\n\n\n\nTertiary type variables\n\n\n${V:-D} # means \"return the value of the environment variable V or the string D if V isn't set.\n\n\nDo a command, and if it returns false, so some more stuff\n\n\nwhile ! command_that_will_fail ; do something_else ; done ;\n\n\nPrint two digit months\n\n\necho {1..12}\n may not work. If not, use \necho $(seq -w 1 12)\n\n\nGet filename, extension or path\n\n\nTaken from \nhttp://mywiki.wooledge.org/BashFAQ/073\n\n\nRename files to a sequence and change their extension at the same time\n\n\nls | while read -r line ; do\n  stub=${line%.*} ;\n  (( i += 1 )) ;\n  mv \"${line}\" \"${i}-${stub}.txt3\" ;\ndone ;\n\n\n\n\nFullPath=/path/to/name4afile-00809.ext   # result:   #   /path/to/name4afile-00809.ext\nFilename=${FullPath##*/}                             #   name4afile-00809.ext\nPathPref=${FullPath%\"$Filename\"}                     #   /path/to/\nFileStub=${Filename%.*}                              #   name4afile-00809\nFileExt=${Filename#\"$FileStub\"}                      #   .ext\n\n\n\n\nSort a line by spaces\n\n\ns=( whiskey tango foxtrot );\nsorted=$(printf \"%s\\n\"` `${s[@]}|sort);\necho $sorted\n\n\n\n\nCalculate the difference between two dates\n\n\necho $(( $(gdate +%s -d 20120203) - $(gdate +%s -d 20120115) ))\n\n\n\n\nsubstring replace a variable\n\n\nThis is not regex, just a simple string replacement.\n\n\n# ${VAR/search/replace} does only the first\n# ${VAR//search/replace} does all replacements\necho \"Paths in your path: ${PATH//:/ }\"\n\n\n\n\nSubtract two from a MAC address\n\n\n# printf -v defines a variable instead of printing to stdout\nprintf -v dec \"%d\" 0x$(echo 00:25:9c:52:1c:2a | sed 's/://g') ;\nlet dec=${dec}-2 ;\nprintf \"%012X\" ${dec} \\\n| sed -E 's/(..)(..)(..)(..)(..)(..)/\\1:\\2:\\3:\\4:\\5:\\6/g'\n\n\n\n\nPrint the last for chars of a variable\n\n\n\n\necho ${foo:$((${#foo}-4))}\n\n\necho ${foo: -4}\n The space is necessary to prevent it from\n\n\ndoing a completely different thing. See the next example...\n\n\n\n\nPrint something else if a variable doesn't exist\n\n\n\n\necho ${foo:-foo isn't assigned}\n\n\necho ${foo:-${bar}}\n\n\n\n\nThis can even be recursively done...\n\n\n\n\necho ${foo:-${bar:-foo and bar are not assigned}}\n\n\n\n\nPrint every third number starting with 1 and ending with 30\n\n\necho {1..30..3}\n\n\nPrint every 5th letter of the alphabet\n\n\necho {a..z..5}\n\n\nProcess all lines, but print out status about what line we are on every Nth line\n\n\nSometimes during a series of long-running jobs you want to see the status of where you are at, or at least some indicator that things have not paused. when \nctrl-t\n is not available (and even when it is) this pattern can help you monitor that things are still moving a long.\n\n\nN=0\nfind \"/usr/bin\" -type f |\nwhile read -r X ; do\n  N=$((N + 1))\n  [[ \"$((N % 50))\" -eq 0 ]] && date \"+%F %T file number $N $X\" >&2\n  shasum -a 512 \"${X}\" >> ~/usr_bin_shasums.txt\ndone\n\n\n\n\nExample terminal output from the above command, while all \nshasum\n output goes into \n~/usr_bin_shasums.txt\n:\n\n\n$ find \"/usr/bin\" -type f |\n> while read -r X ; do\n>   N=$((N + 1))\n>   [[ \"$((N % 50))\" -eq 0 ]] && date \"+%F %T file number $N $X\" >&2\n>   shasum -a 512 \"${X}\" >> ~/usr_bin_shasums.txt\n> done\n2018-02-24 15:30:29 file number 50 /usr/bin/toe\n2018-02-24 15:30:30 file number 100 /usr/bin/db_hotbackup\n2018-02-24 15:30:32 file number 150 /usr/bin/host\n2018-02-24 15:30:33 file number 200 /usr/bin/groffer\n2018-02-24 15:30:35 file number 250 /usr/bin/mail\n2018-02-24 15:30:36 file number 300 /usr/bin/dbicadmin\n2018-02-24 15:30:38 file number 350 /usr/bin/fwkpfv\n2018-02-24 15:30:39 file number 400 /usr/bin/tab2space\n\n\n\n\nMake a directory structure of every combination of /adjective/noun\n\n\nmkdir -p {red,green,blue}/{fish,bird,flower}\n\n\nGenerate a zero padded random 2 byte hex number\n\n\nprintf \"%02X\\n\" $((RANDOM % 256))\n\n\ngrep many log files and sort output by date\n\n\nsudo grep cron /var/log/* \\\n| sed 's/:/ /' \\\n| while read file month day hour line ; do\n  date -d \"$month $day $hour\" \"+%F %T%z ${file} ${line}\" ;\ndone \\\n| sort\n\n\n\n\nGet command line switches\n\n\nwhile getopts p:l:t: opt; do\n  case $opt in\n    p) pages=$OPTARG ;;\n    l) length=$OPTARG ;;\n    t) time=$OPTARG ;;\n  esac\ndone\n\nshift $((OPTIND - 1))\necho \"pages is ${pages}\"\necho \"length is ${length}\"\necho \"time is ${time}\"\necho \"\\$1 is $1\"\necho \"\\$2 is $2\"\n\n\n\n\nCall this script as \n./foo.sh -p \"this is p\" -l llll -t this\\ is\\ t foo bar\n\n\nFiles\n\n\nThese files can change the behavior of bash.\n\n\n.bash_profile\n\n\n~/.bash_profile\n is executed every time you log into the system or initiate a login shell. Inclusion of things that write to stdout is allowed here.\n\n\nIf you want to write scripts that change your interactive shell environment, such as changing your CWD, define functions here instead of using stand-alone scripts.\n\n\nExample .bash_profile\n\n\nThe \n~/.bash_profile\n file can be quite long and complicated. The following example is an incomplete sample:\n\n\nexport EDITOR=/usr/bin/vim\nexport GZIP='-9'\nexport HISTSIZE=5000\nexport HISTTIMEFORMAT='%F %T%z '\nexport PS1=\"\\u@\\h:\\w$ \"\nexport TERM=xterm-256color\nexport TMOUT=\"1800\"  # log out after this many seconds of shell inactivity\n\nalias ll='ls -la'\nalias temp='tempdate=$(date +%F) ; mkdir -p ~/temp/$tempdate 2>/dev/null ; cd ~/temp/$tempdate'\n\nsprunge() { curl -F 'sprunge=<-' http://sprunge.us < \"${1:-/dev/stdin}\"; } # usage: sprunge FILE # or some_command | sprunge\n\n# Don't record some commands\nexport HISTIGNORE=\"&:[ ]*:exit:ls:bg:fg:history:clear\"\n\n# Avoid duplicate entries\nHISTCONTROL=\"erasedups:ignoreboth\"\n\n# Perform file completion in a case insensitive fashion\nbind \"set completion-ignore-case on\"\n\n\n\n\n.bashrc\n\n\n~/.bashrc\n is executed every time you open a sub-shell. It \nshould not\n output any text, otherwise certain things (eg: scp) will fail.\n\n\n~/.inputrc\n\n\nThis file defines some bash behaviors. It also affects some other tools.\n\n\n# Ignore case while completing\nset completion-ignore-case on\n\n\n\n\nLinks\n\n\n\n\nCommand Line Quicksheet: \nhttp://www.pixelbeat.org/cmdline.html\n\n\nTons of BASH examples: \nhttp://mywiki.wooledge.org/BashFAQ\n\n\nBash Manual: Bash Variables\n\n\nBash pitfalls: \nhttp://mywiki.wooledge.org/BashPitfalls\n\n\nBash prompt howto, including colors: \nhttp://www.tldp.org/HOWTO/Bash-Prompt-HOWTO/x329.html\n\n\nBash Automated Test System",
            "title": "Bash"
        },
        {
            "location": "/bash/#tricks-and-usage",
            "text": "",
            "title": "Tricks and Usage"
        },
        {
            "location": "/bash/#navigating-on-the-command-line",
            "text": "The following can be seen by running:  stty -a   ctrl-a - move cursor to the beginning of the line  ctrl-e - move cursor to the end of the line  ctrl-l - do a \"clear\" on the terminal window  ctrl-r - reverse history command search  ctrl-t - get status of foreground process  ctrl-w - delete previous word",
            "title": "Navigating on the command line"
        },
        {
            "location": "/bash/#view-a-list-of-all-commands-etc",
            "text": "compgen -b  will list all the built-ins you could run.  compgen -a  will list all the aliases you could run.  compgen -c  will list all the commands you could run.  compgen -k  will list all the keywords you could run.  compgen -A  function will list all the functions you could run.  compgen -back  will list all the above in one go.",
            "title": "View a list of all commands, etc.."
        },
        {
            "location": "/bash/#remove-leading-zeroes",
            "text": "for X in 00{1..20..2} ; do\n  echo \"$X == $((10#${X}))\" ;\ndone ;  Or...  for X in {1..50..5} ; do\n  Y=00${X} ;\n  echo \"${X} with zeroes is ${Y} and removed with bc is $(echo ${Y} | bc)\" ;\ndone ;",
            "title": "Remove leading zeroes"
        },
        {
            "location": "/bash/#convert-base-36-to-decimal",
            "text": "This converts the base 36 number z to a decimal value  echo $((36#z))",
            "title": "Convert base 36 to decimal"
        },
        {
            "location": "/bash/#run-a-command-for-5-seconds-then-kill-it",
            "text": "ping -f & sleep 5 ; kill %1  Alternatively, use the timeout command if it's available. In macOS this can be installed through  homebrew install coreutils  and accessed with  gtimeout .  timeout 300 cmd",
            "title": "Run a command for 5 seconds, then kill it"
        },
        {
            "location": "/bash/#test-if-a-variable-is-empty",
            "text": "if [[ -z \"$var\" ]]",
            "title": "Test if a variable is empty"
        },
        {
            "location": "/bash/#date",
            "text": "For date stuff, see date, because it's different depending on platform.",
            "title": "Date"
        },
        {
            "location": "/bash/#show-random-statistics",
            "text": "for X in {0..9999} ; do\n  echo $(($RANDOM % 5)) ;\ndone |\nsort |\nuniq -c",
            "title": "Show RANDOM statistics"
        },
        {
            "location": "/bash/#named-pipes",
            "text": "mkfifo baz ; ps aux > baz  then in another terminal  cat baz",
            "title": "named pipes"
        },
        {
            "location": "/bash/#alternate-redirection-outputs",
            "text": "exec 3> /tmp/baz ; ps aux >&3 # sends the output of ps aux to /tmp/baz",
            "title": "alternate redirection outputs"
        },
        {
            "location": "/bash/#redirect-all-output-of-a-script-into-a-file",
            "text": "This is not bash specific, but works in bash.  #!/usr/bin/env bash\n\nexec >> /tmp/$0.log\nexec 2>&1\n\ndate \"+%F %T%z $0 This is stdout\"\ndate \"+%F %T%z $0 This is stderr\" >&2",
            "title": "Redirect all output of a script into a file"
        },
        {
            "location": "/bash/#show-size-of-each-users-home-folder",
            "text": "getent passwd |\nwhile IFS=: read -r user _ uid _ _ home _ ; do\n  if [[ $uid -ge 500 ]] ; then\n    printf \"$user \" ;\n    sudo du -sh $home ;\n  fi ;\ndone",
            "title": "Show size of each user's home folder"
        },
        {
            "location": "/bash/#previous-commands-args",
            "text": "mkdir temp ; cd !!:*  Be aware of the location of the tokens. eg:  mkdir -p {foo,bar}/{a,b,c} ; stat !!:*  creates a problem because you can't  stat -p  so you must  stat -p !!:2*",
            "title": "Previous command's args"
        },
        {
            "location": "/bash/#debug-a-script",
            "text": "This will show everything bash is executing  bash -x scriptname.sh  Or debug with a function:  function debug { if [ ${debug:-0} -gt 0 ] ; then echo $@ 2>&1 ; fi ; }",
            "title": "Debug a script"
        },
        {
            "location": "/bash/#find-where-all-the-inodes-are",
            "text": "find ~/ -type d -print0 |\nxargs -I %% -0 bash -c \"echo -n %% ; ls -a '%%' | wc -l\" >> ~/inodes.txt",
            "title": "Find where all the inodes are"
        },
        {
            "location": "/bash/#build-and-print-an-array",
            "text": "array=(\"one is the first element\");\narray+=(\"two is the second element\" \"three is the third\");\necho \"${array[@]}\"  This is useful for building command line strings. For example,  gpsbabel  requires each input file to be prepended with  -f . The following script takes a list of files and uses a bash array to create a command line in the form of  gpsbabel -i gpx -f input_file_1.gpx -f input_file_2.gpx -o gpx -F output.gpx  #!/usr/bin/env bash\n\n# Check for at least one argument, print usage if fail\nif [ $# -lt 2 ] ; then\n    echo \"This script merges gpx files and requires at least two gpx files passed as arguments. Output is output.gpx\";\n    echo \"Usage:    $0 <gpx file> <gpx file> [...<gpx file>]\";\n    exit 1;\nfi\n\n# Create an array of arguments to pass to gpsbabel\nargs=();\nfor item in \"$@\" ; do\n    if [ -f \"$item\" ] || [ -h \"$item\" ] ; then\n        args+=( \"-f\" \"$item\" );\n    else\n        echo \"Skipping $item, it's not a file or symlink.\"\n    fi\ndone;\n\n### Verify we have at least two files to work with\nif [ \"${#args[@]}\" -lt 4 ] ; then\n    echo \"We don't have enough actual files to work with. Exiting.\"\n    exit 1\nfi\n\ngpsbabel -i gpx \"${args[@]}\" -o gpx -F output.gpx",
            "title": "Build and print an array"
        },
        {
            "location": "/bash/#build-and-print-an-associative-array-dict-hash",
            "text": "declare -A animals=(\n  [\"cow\"]=\"moo\"\n  [\"dog\"]=\"woof woof\"\n  [\"cat\"]=\"meow\"\n) ;\nfor animal in \"${!animals[@]}\" ; do\n  echo \"The $animal says '${animals[$animal]}'\" ;\ndone ;",
            "title": "Build and print an associative array (dict, hash)"
        },
        {
            "location": "/bash/#show-permissions-in-rwx-and-octal-format",
            "text": "Linux:  stat -c '%A %a %n' filename  OSX:  stat -f '%A %N' filename",
            "title": "Show permissions in rwx and octal format"
        },
        {
            "location": "/bash/#find-the-length-of-a-variable",
            "text": "echo ${#SHELL}",
            "title": "Find the length of a variable"
        },
        {
            "location": "/bash/#print-all-variables-that-start-with-the-substring-sh",
            "text": "echo ${!SH*}",
            "title": "Print all variables that start with the substring SH"
        },
        {
            "location": "/bash/#tertiary-type-variables",
            "text": "${V:-D} # means \"return the value of the environment variable V or the string D if V isn't set.",
            "title": "Tertiary type variables"
        },
        {
            "location": "/bash/#do-a-command-and-if-it-returns-false-so-some-more-stuff",
            "text": "while ! command_that_will_fail ; do something_else ; done ;",
            "title": "Do a command, and if it returns false, so some more stuff"
        },
        {
            "location": "/bash/#print-two-digit-months",
            "text": "echo {1..12}  may not work. If not, use  echo $(seq -w 1 12)",
            "title": "Print two digit months"
        },
        {
            "location": "/bash/#get-filename-extension-or-path",
            "text": "Taken from  http://mywiki.wooledge.org/BashFAQ/073",
            "title": "Get filename, extension or path"
        },
        {
            "location": "/bash/#rename-files-to-a-sequence-and-change-their-extension-at-the-same-time",
            "text": "ls | while read -r line ; do\n  stub=${line%.*} ;\n  (( i += 1 )) ;\n  mv \"${line}\" \"${i}-${stub}.txt3\" ;\ndone ;  FullPath=/path/to/name4afile-00809.ext   # result:   #   /path/to/name4afile-00809.ext\nFilename=${FullPath##*/}                             #   name4afile-00809.ext\nPathPref=${FullPath%\"$Filename\"}                     #   /path/to/\nFileStub=${Filename%.*}                              #   name4afile-00809\nFileExt=${Filename#\"$FileStub\"}                      #   .ext",
            "title": "Rename files to a sequence and change their extension at the same time"
        },
        {
            "location": "/bash/#sort-a-line-by-spaces",
            "text": "s=( whiskey tango foxtrot );\nsorted=$(printf \"%s\\n\"` `${s[@]}|sort);\necho $sorted",
            "title": "Sort a line by spaces"
        },
        {
            "location": "/bash/#calculate-the-difference-between-two-dates",
            "text": "echo $(( $(gdate +%s -d 20120203) - $(gdate +%s -d 20120115) ))",
            "title": "Calculate the difference between two dates"
        },
        {
            "location": "/bash/#substring-replace-a-variable",
            "text": "This is not regex, just a simple string replacement.  # ${VAR/search/replace} does only the first\n# ${VAR//search/replace} does all replacements\necho \"Paths in your path: ${PATH//:/ }\"",
            "title": "substring replace a variable"
        },
        {
            "location": "/bash/#subtract-two-from-a-mac-address",
            "text": "# printf -v defines a variable instead of printing to stdout\nprintf -v dec \"%d\" 0x$(echo 00:25:9c:52:1c:2a | sed 's/://g') ;\nlet dec=${dec}-2 ;\nprintf \"%012X\" ${dec} \\\n| sed -E 's/(..)(..)(..)(..)(..)(..)/\\1:\\2:\\3:\\4:\\5:\\6/g'",
            "title": "Subtract two from a MAC address"
        },
        {
            "location": "/bash/#print-the-last-for-chars-of-a-variable",
            "text": "echo ${foo:$((${#foo}-4))}  echo ${foo: -4}  The space is necessary to prevent it from  doing a completely different thing. See the next example...",
            "title": "Print the last for chars of a variable"
        },
        {
            "location": "/bash/#print-something-else-if-a-variable-doesnt-exist",
            "text": "echo ${foo:-foo isn't assigned}  echo ${foo:-${bar}}   This can even be recursively done...   echo ${foo:-${bar:-foo and bar are not assigned}}",
            "title": "Print something else if a variable doesn't exist"
        },
        {
            "location": "/bash/#print-every-third-number-starting-with-1-and-ending-with-30",
            "text": "echo {1..30..3}",
            "title": "Print every third number starting with 1 and ending with 30"
        },
        {
            "location": "/bash/#print-every-5th-letter-of-the-alphabet",
            "text": "echo {a..z..5}",
            "title": "Print every 5th letter of the alphabet"
        },
        {
            "location": "/bash/#process-all-lines-but-print-out-status-about-what-line-we-are-on-every-nth-line",
            "text": "Sometimes during a series of long-running jobs you want to see the status of where you are at, or at least some indicator that things have not paused. when  ctrl-t  is not available (and even when it is) this pattern can help you monitor that things are still moving a long.  N=0\nfind \"/usr/bin\" -type f |\nwhile read -r X ; do\n  N=$((N + 1))\n  [[ \"$((N % 50))\" -eq 0 ]] && date \"+%F %T file number $N $X\" >&2\n  shasum -a 512 \"${X}\" >> ~/usr_bin_shasums.txt\ndone  Example terminal output from the above command, while all  shasum  output goes into  ~/usr_bin_shasums.txt :  $ find \"/usr/bin\" -type f |\n> while read -r X ; do\n>   N=$((N + 1))\n>   [[ \"$((N % 50))\" -eq 0 ]] && date \"+%F %T file number $N $X\" >&2\n>   shasum -a 512 \"${X}\" >> ~/usr_bin_shasums.txt\n> done\n2018-02-24 15:30:29 file number 50 /usr/bin/toe\n2018-02-24 15:30:30 file number 100 /usr/bin/db_hotbackup\n2018-02-24 15:30:32 file number 150 /usr/bin/host\n2018-02-24 15:30:33 file number 200 /usr/bin/groffer\n2018-02-24 15:30:35 file number 250 /usr/bin/mail\n2018-02-24 15:30:36 file number 300 /usr/bin/dbicadmin\n2018-02-24 15:30:38 file number 350 /usr/bin/fwkpfv\n2018-02-24 15:30:39 file number 400 /usr/bin/tab2space",
            "title": "Process all lines, but print out status about what line we are on every Nth line"
        },
        {
            "location": "/bash/#make-a-directory-structure-of-every-combination-of-adjectivenoun",
            "text": "mkdir -p {red,green,blue}/{fish,bird,flower}",
            "title": "Make a directory structure of every combination of /adjective/noun"
        },
        {
            "location": "/bash/#generate-a-zero-padded-random-2-byte-hex-number",
            "text": "printf \"%02X\\n\" $((RANDOM % 256))",
            "title": "Generate a zero padded random 2 byte hex number"
        },
        {
            "location": "/bash/#grep-many-log-files-and-sort-output-by-date",
            "text": "sudo grep cron /var/log/* \\\n| sed 's/:/ /' \\\n| while read file month day hour line ; do\n  date -d \"$month $day $hour\" \"+%F %T%z ${file} ${line}\" ;\ndone \\\n| sort",
            "title": "grep many log files and sort output by date"
        },
        {
            "location": "/bash/#get-command-line-switches",
            "text": "while getopts p:l:t: opt; do\n  case $opt in\n    p) pages=$OPTARG ;;\n    l) length=$OPTARG ;;\n    t) time=$OPTARG ;;\n  esac\ndone\n\nshift $((OPTIND - 1))\necho \"pages is ${pages}\"\necho \"length is ${length}\"\necho \"time is ${time}\"\necho \"\\$1 is $1\"\necho \"\\$2 is $2\"  Call this script as  ./foo.sh -p \"this is p\" -l llll -t this\\ is\\ t foo bar",
            "title": "Get command line switches"
        },
        {
            "location": "/bash/#files",
            "text": "These files can change the behavior of bash.",
            "title": "Files"
        },
        {
            "location": "/bash/#bash_profile",
            "text": "~/.bash_profile  is executed every time you log into the system or initiate a login shell. Inclusion of things that write to stdout is allowed here.  If you want to write scripts that change your interactive shell environment, such as changing your CWD, define functions here instead of using stand-alone scripts.",
            "title": ".bash_profile"
        },
        {
            "location": "/bash/#example-bash_profile",
            "text": "The  ~/.bash_profile  file can be quite long and complicated. The following example is an incomplete sample:  export EDITOR=/usr/bin/vim\nexport GZIP='-9'\nexport HISTSIZE=5000\nexport HISTTIMEFORMAT='%F %T%z '\nexport PS1=\"\\u@\\h:\\w$ \"\nexport TERM=xterm-256color\nexport TMOUT=\"1800\"  # log out after this many seconds of shell inactivity\n\nalias ll='ls -la'\nalias temp='tempdate=$(date +%F) ; mkdir -p ~/temp/$tempdate 2>/dev/null ; cd ~/temp/$tempdate'\n\nsprunge() { curl -F 'sprunge=<-' http://sprunge.us < \"${1:-/dev/stdin}\"; } # usage: sprunge FILE # or some_command | sprunge\n\n# Don't record some commands\nexport HISTIGNORE=\"&:[ ]*:exit:ls:bg:fg:history:clear\"\n\n# Avoid duplicate entries\nHISTCONTROL=\"erasedups:ignoreboth\"\n\n# Perform file completion in a case insensitive fashion\nbind \"set completion-ignore-case on\"",
            "title": "Example .bash_profile"
        },
        {
            "location": "/bash/#bashrc",
            "text": "~/.bashrc  is executed every time you open a sub-shell. It  should not  output any text, otherwise certain things (eg: scp) will fail.",
            "title": ".bashrc"
        },
        {
            "location": "/bash/#inputrc",
            "text": "This file defines some bash behaviors. It also affects some other tools.  # Ignore case while completing\nset completion-ignore-case on",
            "title": "~/.inputrc"
        },
        {
            "location": "/bash/#links",
            "text": "Command Line Quicksheet:  http://www.pixelbeat.org/cmdline.html  Tons of BASH examples:  http://mywiki.wooledge.org/BashFAQ  Bash Manual: Bash Variables  Bash pitfalls:  http://mywiki.wooledge.org/BashPitfalls  Bash prompt howto, including colors:  http://www.tldp.org/HOWTO/Bash-Prompt-HOWTO/x329.html  Bash Automated Test System",
            "title": "Links"
        },
        {
            "location": "/bc/",
            "text": "bc\n is a tool that does math on the CLI.\n\n\nExamples\n\n\nDivide one number into another and show two decimal places\n\n\nThe \nscale\n variable sets the number of significant digits.\n\n\necho \"scale=2 ; 7 / 3\" | bc\n\n\nConvert decimal to hexadecimal\n\n\necho \"obase=16 ; 10\" | bc\n\n\nConvert hexadecimal to binary\n\n\necho \"ibase=16 ; obase=2 ; AF\" | bc\n\n\nSubtract two from the last octet of a MAC address\n\n\necho 24:b6:fd:ff:ba:31 |\nwhile read -r X ; do\n  echo ${X%??}$(\n    echo \"obase=16 ; $(( 0x${X#*:??:??:??:??:} )) - 2\" |\n      bc |\n      sed 's/^\\(.\\)$/0\\1/' |\n      tr A-Z a-z\n  ) ;\ndone ;",
            "title": "Bc"
        },
        {
            "location": "/bc/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/bc/#divide-one-number-into-another-and-show-two-decimal-places",
            "text": "The  scale  variable sets the number of significant digits.  echo \"scale=2 ; 7 / 3\" | bc",
            "title": "Divide one number into another and show two decimal places"
        },
        {
            "location": "/bc/#convert-decimal-to-hexadecimal",
            "text": "echo \"obase=16 ; 10\" | bc",
            "title": "Convert decimal to hexadecimal"
        },
        {
            "location": "/bc/#convert-hexadecimal-to-binary",
            "text": "echo \"ibase=16 ; obase=2 ; AF\" | bc",
            "title": "Convert hexadecimal to binary"
        },
        {
            "location": "/bc/#subtract-two-from-the-last-octet-of-a-mac-address",
            "text": "echo 24:b6:fd:ff:ba:31 |\nwhile read -r X ; do\n  echo ${X%??}$(\n    echo \"obase=16 ; $(( 0x${X#*:??:??:??:??:} )) - 2\" |\n      bc |\n      sed 's/^\\(.\\)$/0\\1/' |\n      tr A-Z a-z\n  ) ;\ndone ;",
            "title": "Subtract two from the last octet of a MAC address"
        },
        {
            "location": "/bind/",
            "text": "Bind\n\n\nBIND, or named, is the most widely used Domain Name System (DNS) software on the Internet.\n\n\n\n\nhttps://www.isc.org/downloads/bind/doc/\n\n\nhttps://en.wikipedia.org/wiki/BIND\n\n\n\n\nFlush records\n\n\nFlush a single record\n\n\nrndc flushname github.com\n\n\n\n\nFlush all records\n\n\nrndc flush",
            "title": "Bind"
        },
        {
            "location": "/bind/#bind",
            "text": "BIND, or named, is the most widely used Domain Name System (DNS) software on the Internet.   https://www.isc.org/downloads/bind/doc/  https://en.wikipedia.org/wiki/BIND",
            "title": "Bind"
        },
        {
            "location": "/bind/#flush-records",
            "text": "",
            "title": "Flush records"
        },
        {
            "location": "/bind/#flush-a-single-record",
            "text": "rndc flushname github.com",
            "title": "Flush a single record"
        },
        {
            "location": "/bind/#flush-all-records",
            "text": "rndc flush",
            "title": "Flush all records"
        },
        {
            "location": "/blkid/",
            "text": "\"The blkid program is the command-line interface to working with the libblkid(3) library. It can determine the type of content (e.g. filesystem or swap) that a block device holds, and also attributes (tokens, NAME=value pairs) from the content metadata (e.g. LABEL or UUID fields). blkid has two main forms of operation: either searching for a device with a specific NAME=value pair, or displaying NAME=value pairs for one or more specified devices.\" - \nman blkid\n\n\nExamples\n\n\nSimple usage\n\n\nHere is the output of \nblkid\n on an \nUbuntu\n 16.04 \nVagrant\n box:\n\n\n$ blkid\n/dev/sda1: LABEL=\"cloudimg-rootfs\" UUID=\"743b1402-d445-494c-af0b-749040bb33e4\" TYPE=\"ext4\" PARTUUID=\"95a4c157-01\"\n/dev/sdb: UUID=\"2017-12-12-14-38-00-00\" LABEL=\"cidata\" TYPE=\"iso9660\"\n\n\n\n\nSee Also\n\n\n\n\nfindmnt\n\n\nlsblk",
            "title": "Blkid"
        },
        {
            "location": "/blkid/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/blkid/#simple-usage",
            "text": "Here is the output of  blkid  on an  Ubuntu  16.04  Vagrant  box:  $ blkid\n/dev/sda1: LABEL=\"cloudimg-rootfs\" UUID=\"743b1402-d445-494c-af0b-749040bb33e4\" TYPE=\"ext4\" PARTUUID=\"95a4c157-01\"\n/dev/sdb: UUID=\"2017-12-12-14-38-00-00\" LABEL=\"cidata\" TYPE=\"iso9660\"",
            "title": "Simple usage"
        },
        {
            "location": "/blkid/#see-also",
            "text": "findmnt  lsblk",
            "title": "See Also"
        },
        {
            "location": "/bosh/",
            "text": "\"BOSH is an open source tool for release engineering, deployment, lifecycle management, and monitoring of distributed systems.\" - \nhttps://bosh.io/",
            "title": "Bosh"
        },
        {
            "location": "/bpf/",
            "text": "\"Linux Socket Filtering (LSF) is derived from the Berkeley Packet Filter. Though there are some distinct differences between the BSD and Linux Kernel filtering, but when we speak of BPF or LSF in Linux context, we mean the very same mechanism of filtering in the Linux kernel.\"\n\n\n\n\nhttps://www.kernel.org/doc/Documentation/networking/filter.txt\n\n\nhttps://lwn.net/Articles/599755/\n\n\nhttps://www.facebook.com/atscaleevents/videos/1693888610884236/\n\n\nhttp://iovisor.github.io/bcc/\n\n\nhttp://www.brendangregg.com/blog/2015-05-15/ebpf-one-small-step.html\n\n\nhttps://github.com/sharklinux/shark",
            "title": "Bpf"
        },
        {
            "location": "/centos/",
            "text": "CentOS 7\n\n\n\n\nReleased 2014-07-07\n\n\n\n\nNew things in CentOS 7\n\n\n\n\nfirewalld\n\u00a0manages\u00a0the\u00a0firewall\n\n\nhostnamectl\n changes\u00a0the\u00a0hostname\u00a0and\u00a0applies\u00a0the\u00a0setting\u00a0immediately\n\n\njournalctl\n shows log files of services launched by systemd\n\n\nsystemctl\n\u00a0manages systemd services\n\n\n\n\nInitial setup\n\n\nSet up some base parameters on a fresh instance\n\n\nyum\u00a0install\u00a0-y\u00a0bash-completion\u00a0bc\u00a0curl\u00a0git\u00a0lsof\u00a0mlocate\u00a0mutt\u00a0net-snmp\u00a0ntpd\u00a0smartmontools\u00a0strace\u00a0sysstat\u00a0vim\u00a0wget  \nln\u00a0-sf\u00a0/usr/share/zoneinfo/America/Los_Angeles\u00a0/etc/localtime  \nntpdate\u00a0{0..3}.pool.ntp.org  \nsystemctl\u00a0start\u00a0ntpd\n\n\n\n\nCentOS 6\n\n\n\n\nReleased 2011-07-10\n\n\n\n\nCentOS 6 Initial Setup\n\n\n\n\nyum\u00a0install\u00a0-y\u00a0ntp  \nchkconfig\u00a0--levels\u00a0345\u00a0ntpd\u00a0on\u00a0&&\u00a0ntpdate\u00a0time.apple.com\u00a0&&\u00a0service\u00a0ntpd\u00a0start  \nyum\u00a0upgrade\u00a0-y  \nyum\u00a0install\u00a0-y\u00a0arping\u00a0avahi\u00a0avahi-tools\u00a0bc\u00a0bind-utils\u00a0curl\u00a0elinks\u00a0fping\u00a0lsof\u00a0net-snmp\u00a0man\u00a0mlocate\u00a0mutt\u00a0openssh\u00a0openssh-clients\u00a0openssh-server\u00a0perl-Crypt-SSLeay\u00a0perl-libwww-perl\u00a0rsync\u00a0strace\u00a0vim\u00a0wget\u00a0yum-cron \nln\u00a0-sf\u00a0/usr/share/zoneinfo/America/Los_Angeles\u00a0/etc/localtime  \nchkconfig\u00a0--levels\u00a0345\u00a0yum-cron\u00a0on\u00a0&&\u00a0service\u00a0yum-cron\u00a0start  \nyum\u00a0install\u00a0-y\u00a0dcfldd\u00a0nfs-utils\u00a0smartmontools\u00a0dmidecode\u00a0lshw\u00a0dstat\u00a0htop\u00a0iotop  \nchkconfig\u00a0--levels\u00a0345\u00a0smartd\u00a0on\u00a0&&\u00a0service\u00a0smartd\u00a0start\n\n\n\n\nTweaks and Tricks\n\n\nGet past protected lib problems\n\n\nyum\u00a0update\u00a0--setopt=protected_multilib=false\u00a0--skip-broken\n\n\nEnable DHCP Hostname for DNS resolution\n\n\nadd \u201c\nDHCP_HOSTNAME=whatever\n\u201d to\n/etc/sysconfig/network-scripts/ifcfg-eth0\n\n\nInstall OS from USB\n\n\n\n\nFrom Windows: \nhttp://iso2usb.sourceforge.net/\n\n\nFrom Linux: \nhttps://fedoraproject.org/wiki/Livecd-iso-to-disk\n\n\n\n\nShow installed repository keys\n\n\nrpm\u00a0-q\u00a0gpg-pubkey\u00a0--qf\u00a0'%{name}-%{version}-%{release}\u00a0-->\u00a0%{summary}\\n'\n\n\nDHCP with DDNS hostname\n\n\nModel your /etc/sysconfig/network-scripts/ifcfg-eth0 like this:\n\n\nTYPE=Ethernet\nDEVICE=eth0\nONBOOT=yes\nBOOTPROTO=dhcp\n# Without the following line, dhclient will not update /etc/resolv.conf and may not get an IP address at all\nDHCP_HOSTNAME=some_hostname\n\n\n\n\n\n\nTo configure your hostname, edit /etc/sysconfig/network and add HOSTNAME=\n\n\nYou also may need to delete these files:\n\n\n\n\nrm -f /etc/dhclient-eth?.conf /var/lib/dhclient/dhclient-eth?.leases /etc/udev/rules.d/70-persistent-net.rules /etc/sysconfig/network-scripts/ifcfg-eth1\n\n\n\n\nConfiguration to auth against \nMicrosoft\n AD\n\n\n\n\nhttp://www.uncompiled.com/using-winbind-in-centos-6-for-active-director\n worked perfectly with \nsamba\n and \nwinbind\n\n\n\n\nBond Configs\n\n\n$\u00a0cat\u00a0/etc/modprobe.d/bond0.conf\u00a0  \nalias\u00a0bond0\u00a0bonding  \noptions\u00a0bond0\u00a0max_bonds=1\u00a0fail_over_mac=2\u00a0mode=1\u00a0num_grat_arp=2\u00a0primary=em1\u00a0primary_reselect=1\u00a0arp_validate=1\u00a0arp_interval=100\u00a0arp_ip_target=10.1.5.15,10.1.1.1\n\n\n\n\nSee Also\n\n\n\n\nchkconfig\n\n\nrpm\n\n\nselinux\n - \nhttp://wiki.centos.org/HowTos/SELinux\n\n\nyum",
            "title": "CentOS 7"
        },
        {
            "location": "/centos/#centos-7",
            "text": "Released 2014-07-07",
            "title": "CentOS 7"
        },
        {
            "location": "/centos/#new-things-in-centos-7",
            "text": "firewalld \u00a0manages\u00a0the\u00a0firewall  hostnamectl  changes\u00a0the\u00a0hostname\u00a0and\u00a0applies\u00a0the\u00a0setting\u00a0immediately  journalctl  shows log files of services launched by systemd  systemctl \u00a0manages systemd services",
            "title": "New things in CentOS 7"
        },
        {
            "location": "/centos/#initial-setup",
            "text": "Set up some base parameters on a fresh instance  yum\u00a0install\u00a0-y\u00a0bash-completion\u00a0bc\u00a0curl\u00a0git\u00a0lsof\u00a0mlocate\u00a0mutt\u00a0net-snmp\u00a0ntpd\u00a0smartmontools\u00a0strace\u00a0sysstat\u00a0vim\u00a0wget  \nln\u00a0-sf\u00a0/usr/share/zoneinfo/America/Los_Angeles\u00a0/etc/localtime  \nntpdate\u00a0{0..3}.pool.ntp.org  \nsystemctl\u00a0start\u00a0ntpd",
            "title": "Initial setup"
        },
        {
            "location": "/centos/#centos-6",
            "text": "Released 2011-07-10",
            "title": "CentOS 6"
        },
        {
            "location": "/centos/#centos-6-initial-setup",
            "text": "yum\u00a0install\u00a0-y\u00a0ntp  \nchkconfig\u00a0--levels\u00a0345\u00a0ntpd\u00a0on\u00a0&&\u00a0ntpdate\u00a0time.apple.com\u00a0&&\u00a0service\u00a0ntpd\u00a0start  \nyum\u00a0upgrade\u00a0-y  \nyum\u00a0install\u00a0-y\u00a0arping\u00a0avahi\u00a0avahi-tools\u00a0bc\u00a0bind-utils\u00a0curl\u00a0elinks\u00a0fping\u00a0lsof\u00a0net-snmp\u00a0man\u00a0mlocate\u00a0mutt\u00a0openssh\u00a0openssh-clients\u00a0openssh-server\u00a0perl-Crypt-SSLeay\u00a0perl-libwww-perl\u00a0rsync\u00a0strace\u00a0vim\u00a0wget\u00a0yum-cron \nln\u00a0-sf\u00a0/usr/share/zoneinfo/America/Los_Angeles\u00a0/etc/localtime  \nchkconfig\u00a0--levels\u00a0345\u00a0yum-cron\u00a0on\u00a0&&\u00a0service\u00a0yum-cron\u00a0start  \nyum\u00a0install\u00a0-y\u00a0dcfldd\u00a0nfs-utils\u00a0smartmontools\u00a0dmidecode\u00a0lshw\u00a0dstat\u00a0htop\u00a0iotop  \nchkconfig\u00a0--levels\u00a0345\u00a0smartd\u00a0on\u00a0&&\u00a0service\u00a0smartd\u00a0start",
            "title": "CentOS 6 Initial Setup"
        },
        {
            "location": "/centos/#tweaks-and-tricks",
            "text": "",
            "title": "Tweaks and Tricks"
        },
        {
            "location": "/centos/#get-past-protected-lib-problems",
            "text": "yum\u00a0update\u00a0--setopt=protected_multilib=false\u00a0--skip-broken",
            "title": "Get past protected lib problems"
        },
        {
            "location": "/centos/#enable-dhcp-hostname-for-dns-resolution",
            "text": "add \u201c DHCP_HOSTNAME=whatever \u201d to\n/etc/sysconfig/network-scripts/ifcfg-eth0",
            "title": "Enable DHCP Hostname for DNS resolution"
        },
        {
            "location": "/centos/#install-os-from-usb",
            "text": "From Windows:  http://iso2usb.sourceforge.net/  From Linux:  https://fedoraproject.org/wiki/Livecd-iso-to-disk",
            "title": "Install OS from USB"
        },
        {
            "location": "/centos/#show-installed-repository-keys",
            "text": "rpm\u00a0-q\u00a0gpg-pubkey\u00a0--qf\u00a0'%{name}-%{version}-%{release}\u00a0-->\u00a0%{summary}\\n'",
            "title": "Show installed repository keys"
        },
        {
            "location": "/centos/#dhcp-with-ddns-hostname",
            "text": "Model your /etc/sysconfig/network-scripts/ifcfg-eth0 like this:  TYPE=Ethernet\nDEVICE=eth0\nONBOOT=yes\nBOOTPROTO=dhcp\n# Without the following line, dhclient will not update /etc/resolv.conf and may not get an IP address at all\nDHCP_HOSTNAME=some_hostname   To configure your hostname, edit /etc/sysconfig/network and add HOSTNAME=  You also may need to delete these files:   rm -f /etc/dhclient-eth?.conf /var/lib/dhclient/dhclient-eth?.leases /etc/udev/rules.d/70-persistent-net.rules /etc/sysconfig/network-scripts/ifcfg-eth1",
            "title": "DHCP with DDNS hostname"
        },
        {
            "location": "/centos/#configuration-to-auth-against-microsoft-ad",
            "text": "http://www.uncompiled.com/using-winbind-in-centos-6-for-active-director  worked perfectly with  samba  and  winbind",
            "title": "Configuration to auth against Microsoft AD"
        },
        {
            "location": "/centos/#bond-configs",
            "text": "$\u00a0cat\u00a0/etc/modprobe.d/bond0.conf\u00a0  \nalias\u00a0bond0\u00a0bonding  \noptions\u00a0bond0\u00a0max_bonds=1\u00a0fail_over_mac=2\u00a0mode=1\u00a0num_grat_arp=2\u00a0primary=em1\u00a0primary_reselect=1\u00a0arp_validate=1\u00a0arp_interval=100\u00a0arp_ip_target=10.1.5.15,10.1.1.1",
            "title": "Bond Configs"
        },
        {
            "location": "/centos/#see-also",
            "text": "chkconfig  rpm  selinux  -  http://wiki.centos.org/HowTos/SELinux  yum",
            "title": "See Also"
        },
        {
            "location": "/ceph/",
            "text": "\"Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability.\" - \nhttps://ceph.com\n\n\nExamples\n\n\nsudo ceph-disk activate-all\n\n\nLinks\n\n\n\n\nCeph Intro & Architectural Overview - \nhttps://youtu.be/7I9uxoEhUdY",
            "title": "Ceph"
        },
        {
            "location": "/ceph/#examples",
            "text": "sudo ceph-disk activate-all",
            "title": "Examples"
        },
        {
            "location": "/ceph/#links",
            "text": "Ceph Intro & Architectural Overview -  https://youtu.be/7I9uxoEhUdY",
            "title": "Links"
        },
        {
            "location": "/chkconfig/",
            "text": "chkconfig is a tool to interact with sys-v init scripts on centos/rhel hosts.\n\n\nExamples\n\n\nList services and their runlevels\n\n\nchkconfig\u00a0--list\n\n\nTurn on mysql at runlevels 3 and 5\n\n\nchkconfig\u00a0--level\u00a035\u00a0mysql\u00a0on\n\n\nSee Also\n\n\n\n\nupdate-rc.d\n - similar feature for ubuntu sysvinit",
            "title": "Chkconfig"
        },
        {
            "location": "/chkconfig/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/chkconfig/#list-services-and-their-runlevels",
            "text": "chkconfig\u00a0--list",
            "title": "List services and their runlevels"
        },
        {
            "location": "/chkconfig/#turn-on-mysql-at-runlevels-3-and-5",
            "text": "chkconfig\u00a0--level\u00a035\u00a0mysql\u00a0on",
            "title": "Turn on mysql at runlevels 3 and 5"
        },
        {
            "location": "/chkconfig/#see-also",
            "text": "update-rc.d  - similar feature for ubuntu sysvinit",
            "title": "See Also"
        },
        {
            "location": "/chocolatey/",
            "text": "\"The package manager for WIndows\" - \nhttps://chocolatey.org\n\n\nExamples\n\n\nchoco\n has to be run from an admin shell.\n\n\nSearch for a package\n\n\nchoco search xencenter\n\n\n\n\nInstall software and all its requirements\n\n\nchoco install xencenter -y",
            "title": "Chocolatey"
        },
        {
            "location": "/chocolatey/#examples",
            "text": "choco  has to be run from an admin shell.",
            "title": "Examples"
        },
        {
            "location": "/chocolatey/#search-for-a-package",
            "text": "choco search xencenter",
            "title": "Search for a package"
        },
        {
            "location": "/chocolatey/#install-software-and-all-its-requirements",
            "text": "choco install xencenter -y",
            "title": "Install software and all its requirements"
        },
        {
            "location": "/chronos/",
            "text": "\"Chronos is a replacement for cron. It is a distributed and fault-tolerant scheduler that runs on top of Apache Mesos that can be used for job orchestration.\" - \nhttps://mesos.github.io/chronos/\n\n\n\n\nUses \nISO 8601 Repeating Interval notation\n, but the P is required so you can only use the syntax \nRn/<datespec>/PT4H\n - see \nhttp://mesos.github.io/chronos/docs/api.html#adding-a-scheduled-job",
            "title": "Chronos"
        },
        {
            "location": "/circleci/",
            "text": "\"CircleCI's continuous integration and delivery platform makes it easy for teams of all sizes to rapidly build and release quality software at scale. Build for Linux, macOS, and Android, in the cloud or behind your firewall.\" - \nhttps://circleci.com/\n\n\nLinks\n\n\n\n\nhttps://circleci.com/docs/2.0/configuration-reference/\n\n\nhttps://circleci.com/docs/2.0/sample-config/\n\n\nhttps://circleci.com/docs/2.0/circleci-images/\n\n\nhttps://circleci.com/docs/2.0/workflows/",
            "title": "Circleci"
        },
        {
            "location": "/circleci/#links",
            "text": "https://circleci.com/docs/2.0/configuration-reference/  https://circleci.com/docs/2.0/sample-config/  https://circleci.com/docs/2.0/circleci-images/  https://circleci.com/docs/2.0/workflows/",
            "title": "Links"
        },
        {
            "location": "/cncf/",
            "text": "\"CNCF serves as the vendor-neutral home for many of the fastest-growing projects on GitHub, including Kubernetes, Prometheus and Envoy, fostering collaboration between the industry\u2019s top developers, end users, and vendors.\" - \nhttps://www.cncf.io",
            "title": "Cncf"
        },
        {
            "location": "/cobbler/",
            "text": "\"Cobbler is a Linux installation server that allows for rapid setup of network installation environments.\" -- \nhttp://cobbler.github.io\n\n\nNotes\n\n\n\n\nVersions prior to 2.6.9 can no longer auto-download loaders\n\n\n\n\nLinks\n\n\n\n\nhttps://cobbler.github.io/\n\n\nhttps://cobbler.github.io/manuals/quickstart/\n\n\nhttps://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/CentOS_CentOS-6/noarch/\n - Newer than epel CentOS 6 rpms\n\n\nhttps://github.com/rhinstaller/pykickstart",
            "title": "Cobbler"
        },
        {
            "location": "/cobbler/#notes",
            "text": "Versions prior to 2.6.9 can no longer auto-download loaders",
            "title": "Notes"
        },
        {
            "location": "/cobbler/#links",
            "text": "https://cobbler.github.io/  https://cobbler.github.io/manuals/quickstart/  https://download.opensuse.org/repositories/home:/libertas-ict:/cobbler26/CentOS_CentOS-6/noarch/  - Newer than epel CentOS 6 rpms  https://github.com/rhinstaller/pykickstart",
            "title": "Links"
        },
        {
            "location": "/conjure-up/",
            "text": "\"Get started with big software, fast\" - \nhttps://conjure-up.io/\n\n\nLinks\n\n\n\n\nDeploying The Canonical Distribution Of Kubernetes onto AWS",
            "title": "Conjure up"
        },
        {
            "location": "/conjure-up/#links",
            "text": "Deploying The Canonical Distribution Of Kubernetes onto AWS",
            "title": "Links"
        },
        {
            "location": "/consul/",
            "text": "\"Service Discovery and Configuration Made Easy\" - \nhttps://www.consul.io/\n\n\nLinks\n\n\n\n\nhttps://www.consul.io/docs/internals/architecture.html",
            "title": "Consul"
        },
        {
            "location": "/consul/#links",
            "text": "https://www.consul.io/docs/internals/architecture.html",
            "title": "Links"
        },
        {
            "location": "/cowsay/",
            "text": "In Linux etc., print a cow that is saying something. Also works as \ncowthink\n, and a variety of other animals and artwork are available.\n\n\nExamples\n\n\nGet a list of things that can talk\n\n\n$ cowthink -l\nCow files in /usr/share/cowsay/cows:\napt beavis.zen bong bud-frogs bunny calvin cheese cock cower daemon default\ndragon dragon-and-cow duck elephant elephant-in-snake eyes flaming-sheep\nghostbusters gnu head-in hellokitty kiss kitty koala kosh luke-koala\nmech-and-cow meow milk moofasa moose mutilated pony pony-smaller ren sheep\nskeleton snowman sodomized-sheep stegosaurus stimpy suse three-eyes turkey\nturtle tux unipony unipony-smaller vader vader-koala www\n\n\n\n\ncowsay\n\n\n$ cowsay \"Hello world!\"\n ______________\n< Hello world! >\n --------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||\n\n\n\n\ncowthink\n\n\n$ cowthink -f dragon \"On the internet, nobody knows you're a dragon!\"\n ________________________________________\n( On the internet, nobody knows you're a )\n( dragon!                                )\n ----------------------------------------\n      o                    / \\  //\\\n       o    |\\___/|      /   \\//  \\\\\n            /0  0  \\__  /    //  | \\ \\\n           /     /  \\/_/    //   |  \\  \\\n           @_^_@'/   \\/_   //    |   \\   \\\n           //_^_/     \\/_ //     |    \\    \\\n        ( //) |        \\///      |     \\     \\\n      ( / /) _|_ /   )  //       |      \\     _\\\n    ( // /) '/,_ _ _/  ( ; -.    |    _ _\\.-~        .-~~~^-.\n  (( / / )) ,-{        _      `-.|.-~-.           .~         `.\n (( // / ))  '/\\      /                 ~-. _ .-~      .-~^-.  \\\n (( /// ))      `.   {            }                   /      \\  \\\n  (( / ))     .----~-.\\        \\-'                 .~         \\  `. \\^-.\n             ///.----..>        \\             _ -~             `.  ^-`  ^-_\n               ///-._ _ _ _ _ _ _}^ - - - - ~                     ~-- ,.-~\n                                                                  /.-~",
            "title": "Cowsay"
        },
        {
            "location": "/cowsay/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/cowsay/#get-a-list-of-things-that-can-talk",
            "text": "$ cowthink -l\nCow files in /usr/share/cowsay/cows:\napt beavis.zen bong bud-frogs bunny calvin cheese cock cower daemon default\ndragon dragon-and-cow duck elephant elephant-in-snake eyes flaming-sheep\nghostbusters gnu head-in hellokitty kiss kitty koala kosh luke-koala\nmech-and-cow meow milk moofasa moose mutilated pony pony-smaller ren sheep\nskeleton snowman sodomized-sheep stegosaurus stimpy suse three-eyes turkey\nturtle tux unipony unipony-smaller vader vader-koala www",
            "title": "Get a list of things that can talk"
        },
        {
            "location": "/cowsay/#cowsay",
            "text": "$ cowsay \"Hello world!\"\n ______________\n< Hello world! >\n --------------\n        \\   ^__^\n         \\  (oo)\\_______\n            (__)\\       )\\/\\\n                ||----w |\n                ||     ||",
            "title": "cowsay"
        },
        {
            "location": "/cowsay/#cowthink",
            "text": "$ cowthink -f dragon \"On the internet, nobody knows you're a dragon!\"\n ________________________________________\n( On the internet, nobody knows you're a )\n( dragon!                                )\n ----------------------------------------\n      o                    / \\  //\\\n       o    |\\___/|      /   \\//  \\\\\n            /0  0  \\__  /    //  | \\ \\\n           /     /  \\/_/    //   |  \\  \\\n           @_^_@'/   \\/_   //    |   \\   \\\n           //_^_/     \\/_ //     |    \\    \\\n        ( //) |        \\///      |     \\     \\\n      ( / /) _|_ /   )  //       |      \\     _\\\n    ( // /) '/,_ _ _/  ( ; -.    |    _ _\\.-~        .-~~~^-.\n  (( / / )) ,-{        _      `-.|.-~-.           .~         `.\n (( // / ))  '/\\      /                 ~-. _ .-~      .-~^-.  \\\n (( /// ))      `.   {            }                   /      \\  \\\n  (( / ))     .----~-.\\        \\-'                 .~         \\  `. \\^-.\n             ///.----..>        \\             _ -~             `.  ^-`  ^-_\n               ///-._ _ _ _ _ _ _}^ - - - - ~                     ~-- ,.-~\n                                                                  /.-~",
            "title": "cowthink"
        },
        {
            "location": "/cron/",
            "text": "Per-user and system-wide scheduled tasks, handled by the cron daemon.\n\n\nLocations\n\n\nCron scripts and entries can run from several locations.  By using /etc/crontab.d/scriptname you can set different MAILTO and ENV variables and isolate your scheduled jobs. User jobs can be edited via \ncrontab -e\n.\n\n\nDST\n\n\nSome cron daemons don't handle DST correctly.  Because of this, do not schedule jobs within the our of 1am.  During DST changes this hour happens twice or is skipped altogether.\n\n\nCronie says it handled DST gracefully, running jobs that should have run but haven't yet due to time changes, or no running jobs twice when time goes back.\n\n\nSyntax quirks\n\n\nSome systems have problems with #/# syntax.  (eg: \n15 2/6 * * * /usr/bin/whatever\n)\n\n\nDefault Editor\n\n\nIn some systems, the default editor is found by the symlink located at /etc/defaults/editor.  To override this, export your EDITOR shell variable. (eg: \nexport EDITOR=/usr/bin/vim\n)\n\n\nExamples\n\n\nQuick and dirty realignment\n\n\nThis will definitely fail in some circumstances.\n\n\nalias crontab-align='crontab -l | while read -r a b c d e f ; do\n  if [[ \"$a\" =~ ^## ]] ; then\n    echo \"$a $b $c $d $e $f\" ;\n  else\n    printf \"% -20s %s\\n\" \"$a $b $c $d $e\" \"$f\" ;\n  fi ;\ndone'\n\ncrontab-align | crontab -\n\n\n\n\nAdd a random delay\n\n\nThis example sleeps for a random number of seconds lower than 1800, including 0.  The \n%\n symbol has to be escaped in crontabs.\n\n\n0 * * * *   sleep $((RANDOM \\% 1800)) ; /usr/local/bin/do-a-thing.sh ;\n\n\n\n\nProgrammatic editing of the crontab\n\n\nThis is potentially dangerous because you can wipe out a user's crontab.\n\n\ncrontab -l | sed -e '/downtime/s/^\\#//' | crontab -\necho \"* * * * * /usr/local/bin/every_minute.sh\" | crontab -\n\n\n\n\nSee if and when parts are running\n\n\nPut this in /etc/cron.*/01-cron-log :\n\n\nlogger -t cron Running `basename $PWD`\n\n\n\n\nOS X Alarm Clock\n\n\n## Alarm Clock\n55 5 * * 1-5    /usr/bin/osascript -e 'tell application \"iTunes\"' -e 'set the sound volume to 100' -e 'end tell'\n00 6 * * 1-5    /usr/bin/osascript -e 'tell application \"iTunes\"' -e 'play playlist \"Old Podcasts\"' -e 'end tell'\n15 8 * * 1-5    /usr/bin/osascript -e 'tell application \"iTunes\" to stop'\n\n\n\n\nCurl every other hour\n\n\n0 */2 * * *    curl -fs \"http://bighugelabs.com/flickr/profilewidget/randomint/000000/ffffff/94246031@N00.jpg\" > /dev/null\n\n\n\n\nTroubleshooting\n\n\nHaving junk files like temp vim files in /var/cron/tabs can make cron go to 100% cpu usage.  Remove all non crontab files and kill cron to fix it.",
            "title": "Cron"
        },
        {
            "location": "/cron/#locations",
            "text": "Cron scripts and entries can run from several locations.  By using /etc/crontab.d/scriptname you can set different MAILTO and ENV variables and isolate your scheduled jobs. User jobs can be edited via  crontab -e .",
            "title": "Locations"
        },
        {
            "location": "/cron/#dst",
            "text": "Some cron daemons don't handle DST correctly.  Because of this, do not schedule jobs within the our of 1am.  During DST changes this hour happens twice or is skipped altogether.  Cronie says it handled DST gracefully, running jobs that should have run but haven't yet due to time changes, or no running jobs twice when time goes back.",
            "title": "DST"
        },
        {
            "location": "/cron/#syntax-quirks",
            "text": "Some systems have problems with #/# syntax.  (eg:  15 2/6 * * * /usr/bin/whatever )",
            "title": "Syntax quirks"
        },
        {
            "location": "/cron/#default-editor",
            "text": "In some systems, the default editor is found by the symlink located at /etc/defaults/editor.  To override this, export your EDITOR shell variable. (eg:  export EDITOR=/usr/bin/vim )",
            "title": "Default Editor"
        },
        {
            "location": "/cron/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/cron/#quick-and-dirty-realignment",
            "text": "This will definitely fail in some circumstances.  alias crontab-align='crontab -l | while read -r a b c d e f ; do\n  if [[ \"$a\" =~ ^## ]] ; then\n    echo \"$a $b $c $d $e $f\" ;\n  else\n    printf \"% -20s %s\\n\" \"$a $b $c $d $e\" \"$f\" ;\n  fi ;\ndone'\n\ncrontab-align | crontab -",
            "title": "Quick and dirty realignment"
        },
        {
            "location": "/cron/#add-a-random-delay",
            "text": "This example sleeps for a random number of seconds lower than 1800, including 0.  The  %  symbol has to be escaped in crontabs.  0 * * * *   sleep $((RANDOM \\% 1800)) ; /usr/local/bin/do-a-thing.sh ;",
            "title": "Add a random delay"
        },
        {
            "location": "/cron/#programmatic-editing-of-the-crontab",
            "text": "This is potentially dangerous because you can wipe out a user's crontab.  crontab -l | sed -e '/downtime/s/^\\#//' | crontab -\necho \"* * * * * /usr/local/bin/every_minute.sh\" | crontab -",
            "title": "Programmatic editing of the crontab"
        },
        {
            "location": "/cron/#see-if-and-when-parts-are-running",
            "text": "Put this in /etc/cron.*/01-cron-log :  logger -t cron Running `basename $PWD`",
            "title": "See if and when parts are running"
        },
        {
            "location": "/cron/#os-x-alarm-clock",
            "text": "## Alarm Clock\n55 5 * * 1-5    /usr/bin/osascript -e 'tell application \"iTunes\"' -e 'set the sound volume to 100' -e 'end tell'\n00 6 * * 1-5    /usr/bin/osascript -e 'tell application \"iTunes\"' -e 'play playlist \"Old Podcasts\"' -e 'end tell'\n15 8 * * 1-5    /usr/bin/osascript -e 'tell application \"iTunes\" to stop'",
            "title": "OS X Alarm Clock"
        },
        {
            "location": "/cron/#curl-every-other-hour",
            "text": "0 */2 * * *    curl -fs \"http://bighugelabs.com/flickr/profilewidget/randomint/000000/ffffff/94246031@N00.jpg\" > /dev/null",
            "title": "Curl every other hour"
        },
        {
            "location": "/cron/#troubleshooting",
            "text": "Having junk files like temp vim files in /var/cron/tabs can make cron go to 100% cpu usage.  Remove all non crontab files and kill cron to fix it.",
            "title": "Troubleshooting"
        },
        {
            "location": "/cryptsetup/",
            "text": "\"Cryptsetup is utility used to conveniently setup disk encryption based\non DMCrypt kernel module.\" - \nhttps://gitlab.com/cryptsetup/cryptsetup/blob/master/README.md\n\n\n\"LUKS is the standard for Linux hard disk encryption. By providing a standard on-disk-format, it does not\nonly facilitate compatibility among distributions, but also provides secure management of multiple user passwords.\" - \nhttps://gitlab.com/cryptsetup/cryptsetup/blob/master/README.md",
            "title": "Cryptsetup"
        },
        {
            "location": "/curl/",
            "text": "\"command line tool and library for transferring data with URLs\" - \nhttps://curl.haxx.se\n\n\ncurl is a tool to transfer data from or to a server, using one of the supported protocols (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMTP, SMTPS, TELNET and TFTP). The command is designed to work without user interaction.\n\n\nExamples\n\n\nFollow location redirects\n\n\ncurl -L http://whatever\n\n\n\n\nShow the HTTP code for a given request\n\n\nThis downloads 1 byte from the remote URI and shows the HTTP code, so it's a quick way to discover HTTP codes.\n\n\ncurl --max-filesize 1 -s -w \"%{http_code}\\n\" -o /dev/null http://www.example.com/\n\n\n\n\nRequest a specific vhost from a server\n\n\nThis is useful for testing production code on non-production multi-tennant name based virtual hosts.\n\n\ncurl -H 'Host: www.domain.com' http://example.com\n\n\n\n\nGet the length of the file to be downloaded\n\n\ncurl -qI  https://www.google.com/index.php 2>/dev/null | awk '/Length/ {print $2}'\n\n\n\n\nFetch only HTTP headers, not content\n\n\ncurl -I http://www.example.com/some_huge_file.iso\n\n\n\n\nSend POST variables\n\n\ncurl --data \"user=foo&pass=bar\" http://example.com/login.php\n\n\n\n\nScrape URLs from a page\n\n\nThis appears to have problems with some strings. For instance, this doesn't catch the full \nhttps://acounts.google.com\n string.  The regex is correct according to \nhttp://regexpal.com\n, but egrep is apparently not handling it correctly.\n\n\ncurl -s http://www.google.com | egrep -o '(((https?|ftp|gopher)://|(mailto|file|news):)[^\u2019 <>\\n\"]+|(www|web|w3)\\.[-a-z0-9.]+)[^\u2019 .,;<>\":]'\n\n\n\n\nLinks\n\n\n\n\nRelease Notes",
            "title": "Curl"
        },
        {
            "location": "/curl/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/curl/#follow-location-redirects",
            "text": "curl -L http://whatever",
            "title": "Follow location redirects"
        },
        {
            "location": "/curl/#show-the-http-code-for-a-given-request",
            "text": "This downloads 1 byte from the remote URI and shows the HTTP code, so it's a quick way to discover HTTP codes.  curl --max-filesize 1 -s -w \"%{http_code}\\n\" -o /dev/null http://www.example.com/",
            "title": "Show the HTTP code for a given request"
        },
        {
            "location": "/curl/#request-a-specific-vhost-from-a-server",
            "text": "This is useful for testing production code on non-production multi-tennant name based virtual hosts.  curl -H 'Host: www.domain.com' http://example.com",
            "title": "Request a specific vhost from a server"
        },
        {
            "location": "/curl/#get-the-length-of-the-file-to-be-downloaded",
            "text": "curl -qI  https://www.google.com/index.php 2>/dev/null | awk '/Length/ {print $2}'",
            "title": "Get the length of the file to be downloaded"
        },
        {
            "location": "/curl/#fetch-only-http-headers-not-content",
            "text": "curl -I http://www.example.com/some_huge_file.iso",
            "title": "Fetch only HTTP headers, not content"
        },
        {
            "location": "/curl/#send-post-variables",
            "text": "curl --data \"user=foo&pass=bar\" http://example.com/login.php",
            "title": "Send POST variables"
        },
        {
            "location": "/curl/#scrape-urls-from-a-page",
            "text": "This appears to have problems with some strings. For instance, this doesn't catch the full  https://acounts.google.com  string.  The regex is correct according to  http://regexpal.com , but egrep is apparently not handling it correctly.  curl -s http://www.google.com | egrep -o '(((https?|ftp|gopher)://|(mailto|file|news):)[^\u2019 <>\\n\"]+|(www|web|w3)\\.[-a-z0-9.]+)[^\u2019 .,;<>\":]'",
            "title": "Scrape URLs from a page"
        },
        {
            "location": "/curl/#links",
            "text": "Release Notes",
            "title": "Links"
        },
        {
            "location": "/date/",
            "text": "The \ndate\n shell command\n\n\ndate behaves differently between gnu and bsd. In OS X you can install gnu date by doing \nbrew install coreutils\n\n\nGNU date\n\n\nShow adjusted date/time\n\n\ndate -d -2month # two months ago\ndate -d +1hour # one hour in the future\ndate -d +15minute\ndate -d \"last week + 1 hour\"\ndate -d \"january 10 1978 + 5 years\" +%a\n\n\n\n\nConvert a string date to epoch seconds\n\n\ndate -d \"Fri Sep  7  2:00 2012\" +%s\n\n\n\n\nConvert epoch seconds to string date\n\n\ndate -d @1375899534\n\n\n\n\nOutput various RFC 3339 time formats\n\n\ndate --rfc-3339=date\ndate --rfc-3339=seconds\ndate --rfc-3339=ns\n\n\n\n\nShow and number all previous weeks from one year ago\n\n\nfor X in {1..53} ; do printf \"%02s \" ${X} ; date -d -49weeks-2days+${X}week \"+%b %d %Y\" ; done ;\n\n\n\n\nShow and number all weeks from the point I started working at Zoosk\n\n\nfor X in {1..90} ; do printf \"%02s \" ${X} ; date -d \"June 10 2013 - 1 week + ${X} week\" \"+%a %b %d %Y\" ; done ;\n\n\n\n\nShow how many seconds old I am\n\n\necho \"$(date +%s) - $(date -d \"January 10 1978 7:46pm\" +%s)\" | bc\n\n\n\n\nShow subsecond date, without going full nano\n\n\nfor X in {1..100} ; do date +%s.%N | cut -c1-15 ; done ;\n\n\n\n\nSleep until the next 5 minute 0 seconds mark\n\n\nwhile sleep $(date \"+60 - %S.%N\" | bc) 240 ; do date \"+%F %T.%N\" ; done ;\n\n\n\n\nBSD date\n\n\nShow adjusted date/time\n\n\ndate -v-2m # two months ago\ndate -v+1H # one hour in the future\n\n\n\n\nConvert epoch seconds to string date\n\n\ndate -r 1514308711",
            "title": "Date"
        },
        {
            "location": "/date/#gnu-date",
            "text": "",
            "title": "GNU date"
        },
        {
            "location": "/date/#show-adjusted-datetime",
            "text": "date -d -2month # two months ago\ndate -d +1hour # one hour in the future\ndate -d +15minute\ndate -d \"last week + 1 hour\"\ndate -d \"january 10 1978 + 5 years\" +%a",
            "title": "Show adjusted date/time"
        },
        {
            "location": "/date/#convert-a-string-date-to-epoch-seconds",
            "text": "date -d \"Fri Sep  7  2:00 2012\" +%s",
            "title": "Convert a string date to epoch seconds"
        },
        {
            "location": "/date/#convert-epoch-seconds-to-string-date",
            "text": "date -d @1375899534",
            "title": "Convert epoch seconds to string date"
        },
        {
            "location": "/date/#output-various-rfc-3339-time-formats",
            "text": "date --rfc-3339=date\ndate --rfc-3339=seconds\ndate --rfc-3339=ns",
            "title": "Output various RFC 3339 time formats"
        },
        {
            "location": "/date/#show-and-number-all-previous-weeks-from-one-year-ago",
            "text": "for X in {1..53} ; do printf \"%02s \" ${X} ; date -d -49weeks-2days+${X}week \"+%b %d %Y\" ; done ;",
            "title": "Show and number all previous weeks from one year ago"
        },
        {
            "location": "/date/#show-and-number-all-weeks-from-the-point-i-started-working-at-zoosk",
            "text": "for X in {1..90} ; do printf \"%02s \" ${X} ; date -d \"June 10 2013 - 1 week + ${X} week\" \"+%a %b %d %Y\" ; done ;",
            "title": "Show and number all weeks from the point I started working at Zoosk"
        },
        {
            "location": "/date/#show-how-many-seconds-old-i-am",
            "text": "echo \"$(date +%s) - $(date -d \"January 10 1978 7:46pm\" +%s)\" | bc",
            "title": "Show how many seconds old I am"
        },
        {
            "location": "/date/#show-subsecond-date-without-going-full-nano",
            "text": "for X in {1..100} ; do date +%s.%N | cut -c1-15 ; done ;",
            "title": "Show subsecond date, without going full nano"
        },
        {
            "location": "/date/#sleep-until-the-next-5-minute-0-seconds-mark",
            "text": "while sleep $(date \"+60 - %S.%N\" | bc) 240 ; do date \"+%F %T.%N\" ; done ;",
            "title": "Sleep until the next 5 minute 0 seconds mark"
        },
        {
            "location": "/date/#bsd-date",
            "text": "",
            "title": "BSD date"
        },
        {
            "location": "/date/#show-adjusted-datetime_1",
            "text": "date -v-2m # two months ago\ndate -v+1H # one hour in the future",
            "title": "Show adjusted date/time"
        },
        {
            "location": "/date/#convert-epoch-seconds-to-string-date_1",
            "text": "date -r 1514308711",
            "title": "Convert epoch seconds to string date"
        },
        {
            "location": "/dcfldd/",
            "text": "dcfldd\n is an advanced version of \ndd\n which is more useful than \npv\n in some situations.\n\n\nOne simple advantage \ndcfldd\n has over \ndd\n is a progress counter displayed by default, although even with \ndd\n you can see progress by pressing \nctrl-t\n. However, if all you need is a progress display, \npv\n is really your best bet.\n\n\nAnother useful advantage dcfldd has is the ability to specify hex and ascii patterns, as well as the output of a command as the source. You may also specify multiple outputs.\n\n\nExamples\n\n\nWipe a hard disk\n\n\nThis wipes hard disk /dev/rdisk9 with binary \n01010101\n pattern.\n\n\ndcfldd pattern=AAAA of=/dev/rdisk9\n\n\n\n\nResume wiping a hard disk\n\n\nYou can use \nseek\n to skip past the first N blocks on the destination disk. If you have to resume multiple times, perhaps the best option is to use bash's arithmetic expansion to add up the number of blocks written.\n\n\n$ dcfldd pattern=AAAA of=/dev/rdisk3\n3328 blocks (104Mb) written.^C\n3466+0 records in\n3465+0 records out\n$ dcfldd pattern=AAAA of=/dev/rdisk3 seek=3328\n2936064 blocks (91752Mb) written.^C\n2936132+0 records in\n2936131+0 records out\n$ dcfldd pattern=AAAA of=/dev/rdisk3 seek=$((3328+2936064))\n\n\n\n\nView progress with pv\n\n\npv\n is useful for seeing the transfer rate of the pipe, which can help diagnose continued success or lack thereof with failing hard disks.\n\n\nroot# dcfldd pattern=AAAA | pv | dcfldd of=/dev/rdisk3 seek=$((4192000+504000+10240000+2936064))\n512 blocks (16Mb) written.22.1MiB 0:00:07 [21.7MiB/s] [   <=>\n1280 blocks (40Mb) written.43.5MiB 0:00:08 [21.5MiB/s] [    <=>\n2304 blocks (72Mb) written.79.4MiB 0:00:09 [35.9MiB/s] [      <=>\n3584 blocks (112Mb) written. 114MiB 0:00:10 [35.2MiB/s] [       <=>",
            "title": "Dcfldd"
        },
        {
            "location": "/dcfldd/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/dcfldd/#wipe-a-hard-disk",
            "text": "This wipes hard disk /dev/rdisk9 with binary  01010101  pattern.  dcfldd pattern=AAAA of=/dev/rdisk9",
            "title": "Wipe a hard disk"
        },
        {
            "location": "/dcfldd/#resume-wiping-a-hard-disk",
            "text": "You can use  seek  to skip past the first N blocks on the destination disk. If you have to resume multiple times, perhaps the best option is to use bash's arithmetic expansion to add up the number of blocks written.  $ dcfldd pattern=AAAA of=/dev/rdisk3\n3328 blocks (104Mb) written.^C\n3466+0 records in\n3465+0 records out\n$ dcfldd pattern=AAAA of=/dev/rdisk3 seek=3328\n2936064 blocks (91752Mb) written.^C\n2936132+0 records in\n2936131+0 records out\n$ dcfldd pattern=AAAA of=/dev/rdisk3 seek=$((3328+2936064))",
            "title": "Resume wiping a hard disk"
        },
        {
            "location": "/dcfldd/#view-progress-with-pv",
            "text": "pv  is useful for seeing the transfer rate of the pipe, which can help diagnose continued success or lack thereof with failing hard disks.  root# dcfldd pattern=AAAA | pv | dcfldd of=/dev/rdisk3 seek=$((4192000+504000+10240000+2936064))\n512 blocks (16Mb) written.22.1MiB 0:00:07 [21.7MiB/s] [   <=>\n1280 blocks (40Mb) written.43.5MiB 0:00:08 [21.5MiB/s] [    <=>\n2304 blocks (72Mb) written.79.4MiB 0:00:09 [35.9MiB/s] [      <=>\n3584 blocks (112Mb) written. 114MiB 0:00:10 [35.2MiB/s] [       <=>",
            "title": "View progress with pv"
        },
        {
            "location": "/dd-wrt/",
            "text": "Netgear R7000\n\n\n\n\nhttps://www.myopenrouter.com/downloads/dd-wrt-r7000\n\n\nhttp://www.desipro.de/ddwrt/K3-AC-Arm/\n\n\n\n\nRestart script\n\n\nThis device with dd-wrt has caused me so much trouble I have to monitor it and reboot it when it fails. Here is a short script to do that. I have this set up in cron to run every 5 minutes. The router will not reboot unless it's been up for 10 minutes.\n\n\nfping -q google.com || {\n  date '+%F %T%z Router is locked up. Restarting it.' | tee -a \"${HOME}/router_reboot.log\"\n  ssh root@192.168.1.1 'set -x ; uptime ; awk \"int(\\$1) < 600 { exit 1 }\" /proc/uptime && reboot ;' | tee -a \"${HOME}/router_reboot.log\"\n}\n\n\n\n\nVersion notes\n\n\n2015-12-24 v3.0-r28598 kongac\n\n\n\n\nCannot edit DHCP reservations. Only can push and pop from the list, but cannot edit the added entries.\n\n\n\n\n2015-12-03 v3.0-r28600M kongac\n\n\n\n\nNo observed differences from v3.0-r28598\n\n\n\n\n2017-01-18 v3.0-r31160M kongac\n\n\n\n\nGeneral instability. Periodic lockups requiring power cycle to fix.\n\n\nPotential weirdness playing with other wifi access points, unable to roam from this to Airport AC as I used to.\n\n\n\n\n2017-03-10 v3.0-r31520M kongac\n\n\n\n\nhttp://www.dd-wrt.com/phpBB2/viewtopic.php?p=1071890\n\n\nInstalled 2017-03-20\n\n\nExperienced hard lock within 24 hours, had to power cycle to fix. Found posts in dd-wrt forum about other folks experiencing the same issue.\n\n\n\n\n2017-03-26 v3.0-r31575M kongac\n\n\n\n\nInstalled on 2017-03-21\n\n\nAppears to have fixed the hard lock-ups\n\n\n\n\n2017-03-26 v3.0-r31780M kongac\n\n\n\n\nInstalled on 2017-03-31 via \nddup --flash-latest\n. First attempt failed. Rebooted, and second attempt worked.\n\n\nNever had any problems with this\n\n\n\n\n2017-03-31 v3.0-r31800M kongac\n\n\n\n\nInstalled on 2017-04-01\n\n\n1 router lockup 3 days after installation\n\n\n2 router lockups on day 4\n\n\n\n\n2017-04-08 v3.0-r31830M kongac\n\n\n\n\nInstalled on 2017-04-07\n\n\nLocked up after 10 days\n\n\n\n\n2017-04-16 v3.0-r31870M kongac\n\n\n\n\nInstalled on 2017-04-17\n\n\nRouter locked up after 4 days\n\n\n\n\n2017-04-30 v3.0-r31920M kongac\n\n\n\n\nInstalled on 2017-05-02\n\n\nHad periodic lockups\n\n\n\n\n2017-05-11 v3.0-r31980M kongac\n\n\n\n\nInstalled on 2017-05-14\n\n\nExperienced wifi problem, dhcp problem, and routing problems within 24 hours\n\n\nExperienced the same problems within 12 hours after reboot\n\n\nUptime peak is 9 days\n\n\n\n\n2017-06-03 v3.0-r32170M kongac\n\n\n\n\nInstalled on 2017-06-08\n\n\nSometimes wireless clients are unable to connect to the network.\n\n\nSometimes the router becomes inaccessable to clients even though it is still up.\n\n\n\n\n2017-08-02 v3.0-r33000M kongac\n\n\n\n\nInstalled on 2017-08-05\n\n\nQuite stable\n\n\n\n\n2017-10-22 v3.0-r33575M kongac\n\n\n\n\nInstalled on 2017-10-22\n\n\nSeeing lock-ups and wifi unavailability after 24 hours\n\n\nSeeing more lock-ups and wifi unavailability hours after restart\n\n\n\n\n2017-11-03 v3.0-r33655M kongac\n\n\n\n\nInstalled on 2017-11-04\n\n\nWiFi instability observed within hours\n\n\n\n\n2017-11-03 v3.0-r33675M kongac\n\n\n\n\n2017-12-25: Discovered this firmware had been installed\n\n\n\n\n2018-01-03 v3.0-r34320M kongac\n\n\n\n\nInstalled on 2018-01-16\n\n\nDD-WRT v3.0-r34320M kongac (c) 2017 NewMedia-NET GmbH\n\n\nRelease: 01/03/18\n\n\nhttp://www.desipro.de/ddwrt/K3-AC-Arm/TEST/dd-wrt.v24-K3_AC_ARM_STD.bin\n\n\nFrequent lock-ups\n\n\n\n\n2018-02-11 v3.0-r34900M kongac\n\n\n\n\nInstalled on 2018-02-16\n\n\nDD-WRT v3.0-r34900M kongac (c) 2018 NewMedia-NET GmbH\n\n\nRelease: 02/11/18\n\n\nVery unstable wifi\n\n\n\n\n2018-02-19 v3.0-r35030M kongac\n\n\n\n\nInstalled on 2018-02-24 (?)\n\n\nDD-WRT v3.0-r35030M kongac (c) 2018 NewMedia-NET GmbH\n\n\nRelease: 02/19/18",
            "title": "Netgear R7000"
        },
        {
            "location": "/dd-wrt/#netgear-r7000",
            "text": "https://www.myopenrouter.com/downloads/dd-wrt-r7000  http://www.desipro.de/ddwrt/K3-AC-Arm/",
            "title": "Netgear R7000"
        },
        {
            "location": "/dd-wrt/#restart-script",
            "text": "This device with dd-wrt has caused me so much trouble I have to monitor it and reboot it when it fails. Here is a short script to do that. I have this set up in cron to run every 5 minutes. The router will not reboot unless it's been up for 10 minutes.  fping -q google.com || {\n  date '+%F %T%z Router is locked up. Restarting it.' | tee -a \"${HOME}/router_reboot.log\"\n  ssh root@192.168.1.1 'set -x ; uptime ; awk \"int(\\$1) < 600 { exit 1 }\" /proc/uptime && reboot ;' | tee -a \"${HOME}/router_reboot.log\"\n}",
            "title": "Restart script"
        },
        {
            "location": "/dd-wrt/#version-notes",
            "text": "",
            "title": "Version notes"
        },
        {
            "location": "/dd-wrt/#2015-12-24-v30-r28598-kongac",
            "text": "Cannot edit DHCP reservations. Only can push and pop from the list, but cannot edit the added entries.",
            "title": "2015-12-24 v3.0-r28598 kongac"
        },
        {
            "location": "/dd-wrt/#2015-12-03-v30-r28600m-kongac",
            "text": "No observed differences from v3.0-r28598",
            "title": "2015-12-03 v3.0-r28600M kongac"
        },
        {
            "location": "/dd-wrt/#2017-01-18-v30-r31160m-kongac",
            "text": "General instability. Periodic lockups requiring power cycle to fix.  Potential weirdness playing with other wifi access points, unable to roam from this to Airport AC as I used to.",
            "title": "2017-01-18 v3.0-r31160M kongac"
        },
        {
            "location": "/dd-wrt/#2017-03-10-v30-r31520m-kongac",
            "text": "http://www.dd-wrt.com/phpBB2/viewtopic.php?p=1071890  Installed 2017-03-20  Experienced hard lock within 24 hours, had to power cycle to fix. Found posts in dd-wrt forum about other folks experiencing the same issue.",
            "title": "2017-03-10 v3.0-r31520M kongac"
        },
        {
            "location": "/dd-wrt/#2017-03-26-v30-r31575m-kongac",
            "text": "Installed on 2017-03-21  Appears to have fixed the hard lock-ups",
            "title": "2017-03-26 v3.0-r31575M kongac"
        },
        {
            "location": "/dd-wrt/#2017-03-26-v30-r31780m-kongac",
            "text": "Installed on 2017-03-31 via  ddup --flash-latest . First attempt failed. Rebooted, and second attempt worked.  Never had any problems with this",
            "title": "2017-03-26 v3.0-r31780M kongac"
        },
        {
            "location": "/dd-wrt/#2017-03-31-v30-r31800m-kongac",
            "text": "Installed on 2017-04-01  1 router lockup 3 days after installation  2 router lockups on day 4",
            "title": "2017-03-31 v3.0-r31800M kongac"
        },
        {
            "location": "/dd-wrt/#2017-04-08-v30-r31830m-kongac",
            "text": "Installed on 2017-04-07  Locked up after 10 days",
            "title": "2017-04-08 v3.0-r31830M kongac"
        },
        {
            "location": "/dd-wrt/#2017-04-16-v30-r31870m-kongac",
            "text": "Installed on 2017-04-17  Router locked up after 4 days",
            "title": "2017-04-16 v3.0-r31870M kongac"
        },
        {
            "location": "/dd-wrt/#2017-04-30-v30-r31920m-kongac",
            "text": "Installed on 2017-05-02  Had periodic lockups",
            "title": "2017-04-30 v3.0-r31920M kongac"
        },
        {
            "location": "/dd-wrt/#2017-05-11-v30-r31980m-kongac",
            "text": "Installed on 2017-05-14  Experienced wifi problem, dhcp problem, and routing problems within 24 hours  Experienced the same problems within 12 hours after reboot  Uptime peak is 9 days",
            "title": "2017-05-11 v3.0-r31980M kongac"
        },
        {
            "location": "/dd-wrt/#2017-06-03-v30-r32170m-kongac",
            "text": "Installed on 2017-06-08  Sometimes wireless clients are unable to connect to the network.  Sometimes the router becomes inaccessable to clients even though it is still up.",
            "title": "2017-06-03 v3.0-r32170M kongac"
        },
        {
            "location": "/dd-wrt/#2017-08-02-v30-r33000m-kongac",
            "text": "Installed on 2017-08-05  Quite stable",
            "title": "2017-08-02 v3.0-r33000M kongac"
        },
        {
            "location": "/dd-wrt/#2017-10-22-v30-r33575m-kongac",
            "text": "Installed on 2017-10-22  Seeing lock-ups and wifi unavailability after 24 hours  Seeing more lock-ups and wifi unavailability hours after restart",
            "title": "2017-10-22 v3.0-r33575M kongac"
        },
        {
            "location": "/dd-wrt/#2017-11-03-v30-r33655m-kongac",
            "text": "Installed on 2017-11-04  WiFi instability observed within hours",
            "title": "2017-11-03 v3.0-r33655M kongac"
        },
        {
            "location": "/dd-wrt/#2017-11-03-v30-r33675m-kongac",
            "text": "2017-12-25: Discovered this firmware had been installed",
            "title": "2017-11-03 v3.0-r33675M kongac"
        },
        {
            "location": "/dd-wrt/#2018-01-03-v30-r34320m-kongac",
            "text": "Installed on 2018-01-16  DD-WRT v3.0-r34320M kongac (c) 2017 NewMedia-NET GmbH  Release: 01/03/18  http://www.desipro.de/ddwrt/K3-AC-Arm/TEST/dd-wrt.v24-K3_AC_ARM_STD.bin  Frequent lock-ups",
            "title": "2018-01-03 v3.0-r34320M kongac"
        },
        {
            "location": "/dd-wrt/#2018-02-11-v30-r34900m-kongac",
            "text": "Installed on 2018-02-16  DD-WRT v3.0-r34900M kongac (c) 2018 NewMedia-NET GmbH  Release: 02/11/18  Very unstable wifi",
            "title": "2018-02-11 v3.0-r34900M kongac"
        },
        {
            "location": "/dd-wrt/#2018-02-19-v30-r35030m-kongac",
            "text": "Installed on 2018-02-24 (?)  DD-WRT v3.0-r35030M kongac (c) 2018 NewMedia-NET GmbH  Release: 02/19/18",
            "title": "2018-02-19 v3.0-r35030M kongac"
        },
        {
            "location": "/ddrescue/",
            "text": "\"GNU ddrescue - Data recovery tool.  Copies data from one file or block device to another, trying to rescue the good parts first in case of read errors.\" \u2013 \nman ddrescue\n\n\nThere are actually two tools called ddrescue: dd_rescue and gddrescue.  gddrescue is the best.\n\n\n\n\nSoftware home page - \nhttp://www.gnu.org/software/ddrescue/\n\n\nInstruction Manual - \nhttp://www.gnu.org/software/ddrescue/manual/ddrescue_manual.html\n\n\n\n\nExamples\n\n\nAttempt to mirror an entire hard disk\n\n\nddrescue -f -n --min-read-rate=500000 /dev/source_disk /dev/target_disk ~/ddrescue.log\n\n\n\n\nAttempt to continue the mirror of a hard disk\n\n\nddrescue -f -n -A /dev/source_disk /dev/target_disk ~/ddrescue.log\n\n\n\n\nWipe the good sectors of a failing disk\n\n\nThis requires a valid rescue log file mapping out the good sectors that were recovered.\n\n\nddrescue --fill=+ --force /dev/zero /dev/bad_drive ~/bad_drive_wipe.log\n\n\n\n\nSee Also\n\n\n\n\ndcfldd\n\n\ndd\n\n\npv",
            "title": "Ddrescue"
        },
        {
            "location": "/ddrescue/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/ddrescue/#attempt-to-mirror-an-entire-hard-disk",
            "text": "ddrescue -f -n --min-read-rate=500000 /dev/source_disk /dev/target_disk ~/ddrescue.log",
            "title": "Attempt to mirror an entire hard disk"
        },
        {
            "location": "/ddrescue/#attempt-to-continue-the-mirror-of-a-hard-disk",
            "text": "ddrescue -f -n -A /dev/source_disk /dev/target_disk ~/ddrescue.log",
            "title": "Attempt to continue the mirror of a hard disk"
        },
        {
            "location": "/ddrescue/#wipe-the-good-sectors-of-a-failing-disk",
            "text": "This requires a valid rescue log file mapping out the good sectors that were recovered.  ddrescue --fill=+ --force /dev/zero /dev/bad_drive ~/bad_drive_wipe.log",
            "title": "Wipe the good sectors of a failing disk"
        },
        {
            "location": "/ddrescue/#see-also",
            "text": "dcfldd  dd  pv",
            "title": "See Also"
        },
        {
            "location": "/deb/",
            "text": "Notes and tips about working with the .deb package format\n\n\nExamples\n\n\nShow installed package versions\n\n\n# -V = sort by version (GNU sort only)\n/usr/bin/dpkg-query -W --showformat '${Package} ${Version} ${Status}\\n' | sort -k2 -V | column -t\n\n\n\n\nList files in packages that are available in configured repositories\n\n\napt-file list package_name\n\n\n\n\nFind a file available inside packages that are available in configured repositories\n\n\napt-file find libmysqlclient.so\n\n\n\n\nShow a list of packages that are installed or have left things on the filesystem\n\n\ndpkg --list\n\n\n\n\nShow which package a file came from\n\n\ndpkg -S /bin/bash\n\n\n\n\nList files in package that is installed\n\n\ndpkg-query -L klibc-utils\n\n\n\n\nList files in package that is not installed\n\n\ndpkg -c package.deb\n\n\n\n\nList packages available in the repository\n\n\napt-cache dumpavail\n\n\n\n\nShow information about a package\n\n\napt-cache show coreutils\n\n\n\n\nShow reverse dependencies of a package\n\n\napt-cache rdepends ec2-api-tools\n\n\n\n\nShow reverse dependencies of installed package\n\n\naptitude why openjdk-7-jre-headless\n\n\n\n\nRe-install many packages and validate that they were re-installed\n\n\nWhen \napt-get install --reinstall\n isn't good enough, this is the next option. This \nshould not\n be done unless you're willing to reload the system if it fails.\n\n\n# Generate a list of packages\ndpkg -l | grep 'python-' > dpkg-l-python ;\n\n# Remove and re-install each individual package one at a time\nawk '{print $2,$3}' dpkg-l-python |\n  while read -r p v ; do\n    echo \"Working on $p version $v\" ;\n    sudo dpkg --purge --force-depends \"$p\" ;\n    sudo apt-get install \"${p}=${v}\" ;\n  done ;\n\n# Validate that all packages are re-installed with the right version\nawk '{print $2,$3}' dpkg-l-python |\n  while read -r p v ; do\n    dpkg -l \"$p\" | grep \"$v\" || echo \"ERROR: Problem with $p $v\" ;\n  done ;\n\n\n\n\nLinks\n\n\n\n\nhttps://wiki.debian.org/RPM",
            "title": "Deb"
        },
        {
            "location": "/deb/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/deb/#show-installed-package-versions",
            "text": "# -V = sort by version (GNU sort only)\n/usr/bin/dpkg-query -W --showformat '${Package} ${Version} ${Status}\\n' | sort -k2 -V | column -t",
            "title": "Show installed package versions"
        },
        {
            "location": "/deb/#list-files-in-packages-that-are-available-in-configured-repositories",
            "text": "apt-file list package_name",
            "title": "List files in packages that are available in configured repositories"
        },
        {
            "location": "/deb/#find-a-file-available-inside-packages-that-are-available-in-configured-repositories",
            "text": "apt-file find libmysqlclient.so",
            "title": "Find a file available inside packages that are available in configured repositories"
        },
        {
            "location": "/deb/#show-a-list-of-packages-that-are-installed-or-have-left-things-on-the-filesystem",
            "text": "dpkg --list",
            "title": "Show a list of packages that are installed or have left things on the filesystem"
        },
        {
            "location": "/deb/#show-which-package-a-file-came-from",
            "text": "dpkg -S /bin/bash",
            "title": "Show which package a file came from"
        },
        {
            "location": "/deb/#list-files-in-package-that-is-installed",
            "text": "dpkg-query -L klibc-utils",
            "title": "List files in package that is installed"
        },
        {
            "location": "/deb/#list-files-in-package-that-is-not-installed",
            "text": "dpkg -c package.deb",
            "title": "List files in package that is not installed"
        },
        {
            "location": "/deb/#list-packages-available-in-the-repository",
            "text": "apt-cache dumpavail",
            "title": "List packages available in the repository"
        },
        {
            "location": "/deb/#show-information-about-a-package",
            "text": "apt-cache show coreutils",
            "title": "Show information about a package"
        },
        {
            "location": "/deb/#show-reverse-dependencies-of-a-package",
            "text": "apt-cache rdepends ec2-api-tools",
            "title": "Show reverse dependencies of a package"
        },
        {
            "location": "/deb/#show-reverse-dependencies-of-installed-package",
            "text": "aptitude why openjdk-7-jre-headless",
            "title": "Show reverse dependencies of installed package"
        },
        {
            "location": "/deb/#re-install-many-packages-and-validate-that-they-were-re-installed",
            "text": "When  apt-get install --reinstall  isn't good enough, this is the next option. This  should not  be done unless you're willing to reload the system if it fails.  # Generate a list of packages\ndpkg -l | grep 'python-' > dpkg-l-python ;\n\n# Remove and re-install each individual package one at a time\nawk '{print $2,$3}' dpkg-l-python |\n  while read -r p v ; do\n    echo \"Working on $p version $v\" ;\n    sudo dpkg --purge --force-depends \"$p\" ;\n    sudo apt-get install \"${p}=${v}\" ;\n  done ;\n\n# Validate that all packages are re-installed with the right version\nawk '{print $2,$3}' dpkg-l-python |\n  while read -r p v ; do\n    dpkg -l \"$p\" | grep \"$v\" || echo \"ERROR: Problem with $p $v\" ;\n  done ;",
            "title": "Re-install many packages and validate that they were re-installed"
        },
        {
            "location": "/deb/#links",
            "text": "https://wiki.debian.org/RPM",
            "title": "Links"
        },
        {
            "location": "/defaults/",
            "text": "defaults\n allows users to read, write, and delete Mac OS X user defaults from a command-line shell.\n\n\nExamples\n\n\nSet some boolean values\n\n\ndefaults write NSGlobalDomain     NSAutomaticQuoteSubstitutionEnabled -bool false\ndefaults write NSGlobalDomain     NSAutomaticDashSubstitutionEnabled  -bool false\ndefaults write com.apple.TextEdit SmartQuotes                         -bool false\ndefaults write com.apple.TextEdit SmartDashes                         -bool false\n\n\n\n\nAdd a value (an array) to a dict\n\n\nFILENAME=\"${HOME}/Library/Preferences/com.googlecode.iterm2.plist\"\ndefaults write \"${FILENAME}\" GlobalKeyMap -dict-add 0xf703-0x280000 '{ Action = 10; Text = f; }'\ndefaults write \"${FILENAME}\" GlobalKeyMap -dict-add 0xf702-0x280000 '{ Action = 10; Text = b; }'",
            "title": "Defaults"
        },
        {
            "location": "/defaults/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/defaults/#set-some-boolean-values",
            "text": "defaults write NSGlobalDomain     NSAutomaticQuoteSubstitutionEnabled -bool false\ndefaults write NSGlobalDomain     NSAutomaticDashSubstitutionEnabled  -bool false\ndefaults write com.apple.TextEdit SmartQuotes                         -bool false\ndefaults write com.apple.TextEdit SmartDashes                         -bool false",
            "title": "Set some boolean values"
        },
        {
            "location": "/defaults/#add-a-value-an-array-to-a-dict",
            "text": "FILENAME=\"${HOME}/Library/Preferences/com.googlecode.iterm2.plist\"\ndefaults write \"${FILENAME}\" GlobalKeyMap -dict-add 0xf703-0x280000 '{ Action = 10; Text = f; }'\ndefaults write \"${FILENAME}\" GlobalKeyMap -dict-add 0xf702-0x280000 '{ Action = 10; Text = b; }'",
            "title": "Add a value (an array) to a dict"
        },
        {
            "location": "/devops/",
            "text": "DevOps lifecycle\n\n\n\n\nPlan - Jira\n\n\nCode - Git, Eclipse, pycharm\n\n\nBuild - Ant, Maven, Gradle\n\n\nTest - Selenium, JUnit\n\n\nRelease - Jenkins, Bamboo\n\n\nDeploy - Puppet, Chef, Ansible, Saltstack\n\n\nOperate - Linux, Chrome, iOS\n\n\nMonitor - Sensu, Splunk, Nagios",
            "title": "DevOps lifecycle"
        },
        {
            "location": "/devops/#devops-lifecycle",
            "text": "Plan - Jira  Code - Git, Eclipse, pycharm  Build - Ant, Maven, Gradle  Test - Selenium, JUnit  Release - Jenkins, Bamboo  Deploy - Puppet, Chef, Ansible, Saltstack  Operate - Linux, Chrome, iOS  Monitor - Sensu, Splunk, Nagios",
            "title": "DevOps lifecycle"
        },
        {
            "location": "/dhcp/",
            "text": "Dynamic Host Configuration Protocol\n\n\nisc dhcpd\n\n\nhttps://www.isc.org/downloads/dhcp/\n\n\nTest configuration file\n\n\ndhcpd3 -t\n\n\n\n\nTest lease file\n\n\ndhcpd3 -T\n\n\n\n\nHandshake Process\n\n\nApr 21 15:33:00 ops1prod dhcpd: DHCPDISCOVER from 08:9e:01:8b:18:94 via eth0\nApr 21 15:33:01 ops1prod dhcpd: DHCPOFFER on 10.1.14.127 to 08:9e:01:8b:18:94 via eth0\nApr 21 15:33:01 ops1prod dhcpd: DHCPREQUEST for 10.1.225.43 from 00:1e:0b:bc:8a:c4 via eth1\nApr 21 15:33:01 ops1prod dhcpd: DHCPACK on 10.1.225.43 to 00:1e:0b:bc:8a:c4 via eth1",
            "title": "Dhcp"
        },
        {
            "location": "/dhcp/#isc-dhcpd",
            "text": "https://www.isc.org/downloads/dhcp/",
            "title": "isc dhcpd"
        },
        {
            "location": "/dhcp/#test-configuration-file",
            "text": "dhcpd3 -t",
            "title": "Test configuration file"
        },
        {
            "location": "/dhcp/#test-lease-file",
            "text": "dhcpd3 -T",
            "title": "Test lease file"
        },
        {
            "location": "/dhcp/#handshake-process",
            "text": "Apr 21 15:33:00 ops1prod dhcpd: DHCPDISCOVER from 08:9e:01:8b:18:94 via eth0\nApr 21 15:33:01 ops1prod dhcpd: DHCPOFFER on 10.1.14.127 to 08:9e:01:8b:18:94 via eth0\nApr 21 15:33:01 ops1prod dhcpd: DHCPREQUEST for 10.1.225.43 from 00:1e:0b:bc:8a:c4 via eth1\nApr 21 15:33:01 ops1prod dhcpd: DHCPACK on 10.1.225.43 to 00:1e:0b:bc:8a:c4 via eth1",
            "title": "Handshake Process"
        },
        {
            "location": "/dig/",
            "text": "dig (domain information groper) is a flexible tool for interrogating DNS name servers. The syntax for this tool is a bit cryptic and is not standard.\n\n\nUsage\n\n\nSimple usage\n\n\ndig yelp.com\n\n\n\n\nShow only the Answer section\n\n\ndig +noall +answer \"yelp.com\"\n\n\n\n\nTrace a query from the root servers\n\n\nThis is the most accurate way to get a DNS record as it will appear to anybody else on the internet who has not queried it before, and will show you all the DNS steps involved in the resolution.\n\n\ndig +trace yelp.com",
            "title": "Dig"
        },
        {
            "location": "/dig/#usage",
            "text": "",
            "title": "Usage"
        },
        {
            "location": "/dig/#simple-usage",
            "text": "dig yelp.com",
            "title": "Simple usage"
        },
        {
            "location": "/dig/#show-only-the-answer-section",
            "text": "dig +noall +answer \"yelp.com\"",
            "title": "Show only the Answer section"
        },
        {
            "location": "/dig/#trace-a-query-from-the-root-servers",
            "text": "This is the most accurate way to get a DNS record as it will appear to anybody else on the internet who has not queried it before, and will show you all the DNS steps involved in the resolution.  dig +trace yelp.com",
            "title": "Trace a query from the root servers"
        },
        {
            "location": "/dmidecode/",
            "text": "tool for listing hardware information and decoding it into human readable form. This tool decodes the DMI information.\n\n\nExamples\n\n\nShow system serial number\n\n\nsudo dmidecode -t system | grep Serial\nsudo dmidecode -s system-serial-number\n\n\n\n\nShow memory info including max installable\n\n\nsudo dmidecode -t memory\n\n\n\n\nShow bios version\n\n\nYou may need to grep for a different string, but even then it doesn't always show the info because not all machines support this.\n\n\nsudo dmidecode -t bios | grep -i revision\n\n\n\n\nShower power supply information\n\n\nThis doesn't always work. Some power supplies are not supported.\n\n\ndmidecode -t 39\n\n\n\n\nSee Also\n\n\nShow all keywords and their values:\n\n\n# -s without a keyword lists all keywords\n# -s with a keyword shows only the value of that keyword\ndmidecode -s |& grep '^  ' | while read -r X ; do echo $X: $(sudo dmidecode -s $X) ; done ;\n\n\n\n\n\n\nlshw\n - list hardware",
            "title": "Dmidecode"
        },
        {
            "location": "/dmidecode/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/dmidecode/#show-system-serial-number",
            "text": "sudo dmidecode -t system | grep Serial\nsudo dmidecode -s system-serial-number",
            "title": "Show system serial number"
        },
        {
            "location": "/dmidecode/#show-memory-info-including-max-installable",
            "text": "sudo dmidecode -t memory",
            "title": "Show memory info including max installable"
        },
        {
            "location": "/dmidecode/#show-bios-version",
            "text": "You may need to grep for a different string, but even then it doesn't always show the info because not all machines support this.  sudo dmidecode -t bios | grep -i revision",
            "title": "Show bios version"
        },
        {
            "location": "/dmidecode/#shower-power-supply-information",
            "text": "This doesn't always work. Some power supplies are not supported.  dmidecode -t 39",
            "title": "Shower power supply information"
        },
        {
            "location": "/dmidecode/#see-also",
            "text": "",
            "title": "See Also"
        },
        {
            "location": "/dmidecode/#show-all-keywords-and-their-values",
            "text": "# -s without a keyword lists all keywords\n# -s with a keyword shows only the value of that keyword\ndmidecode -s |& grep '^  ' | while read -r X ; do echo $X: $(sudo dmidecode -s $X) ; done ;   lshw  - list hardware",
            "title": "Show all keywords and their values:"
        },
        {
            "location": "/dns/",
            "text": "Domain Name System\n\n\n\"The Domain Name System (DNS) is a hierarchical decentralized naming system for computers, services, or any resource connected to the Internet or a private network.\"\n\n\n\n\nhttps://en.wikipedia.org/wiki/List_of_DNS_record_types\n\n\nhttps://en.wikipedia.org/wiki/Category:Application_layer_protocols",
            "title": "Dns"
        },
        {
            "location": "/docker/",
            "text": "\"An open source project to pack, ship and run any application as a lightweight container.\"\n\n\nExamples\n\n\nShow help on the run command\n\n\ndocker help run\n\n\n\n\nRun a docker image in an interactive shell\n\n\ndocker run -i -t node bash\n\n\n\n\n\n\n-i, --interactive\n\n\n-t, --tty\n\n\n\n\nhttps://docs.docker.com/reference/commandline/cli/#run\n\n\nGet a bash terminal on a running docker container\n\n\ndocker exec -i -t container_name bash\n\n\n\n\nRun a docker image and assign it a hostname, and a docker name\n\n\ndocker run --hostname=somehost1 --name=\"host1\" -ti centos:centos6 bash\n\n\n\n\nThe hostname shows up to the OS. The docker name can be used to interact with the container:\n\n\ndocker ps host1\n\n\n\n\nRun a container with a tcp port map\n\n\nThis maps port 18022 of the host to 22 of the guest.\n\n\ndocker run -ti -p 18022:22 centos bash\n\n\n\n\nRun a container with a shared directory\n\n\nWe are specifying :ro to make this a read-only mount. Default is rw.\n\n\ndocker run -d -v \"$HOME/www/:/var/www/html/:ro\" php:5.4.35-apache\n\n\n\n\nShow configuration parameters for a container\n\n\nThis shows more things that you can configure, like DNS, DNS search, etc..\n\n\ndocker inspect host1\n\n\n\n\nShow what has changed since a container was started\n\n\ndocker diff <container-id>\n\n\n\n\nhttps://docs.docker.com/reference/commandline/cli/#diff\n\n\nView the terminal scrollback of a a container\n\n\ndocker logs <container-id>\n\n\n\n\nList all containers, including ones that have been stopped\n\n\nThis allows you to restart previous instances of a container.\n\n\ndocker ps -a\n\n\n\n\nhttps://docs.docker.com/reference/commandline/cli/#ps\n\n\nStart a named container\n\n\nBy default containers don't restart when your system restarts, so you have to start them manually.\n\n\ndocker start ttrss\n\n\n\n\nStop a named container\n\n\ndocker stop ttrss\n\n\n\n\nUpdate the restart policy on a running container\n\n\ndocker update --restart=unless-stopped 3a898cb672ad\n\n\n\n\nGet a shell on a running container\n\n\ndocker exec -ti ttrss bash\n\n\n\n\nDelete old containers\n\n\nhttps://docs.docker.com/reference/commandline/cli/#rm\n\n\nRemove \n-r\n from \nxargs\n on non-GNU systems.\n\n\ndocker ps -a --format=\"{{.ID}} {{.Status}}\" | awk '$2 == \"Exited\" && $5 ~ /(days|weeks|months)/ {print $1}' | xargs -r docker rm\n\n\n\n\nA more systematic approach is to use \nDocker Custodian\n.\n\n\nDelete old images\n\n\nThis is safe to run as long as valuable containers are running, as it won't delete any images that are attached to running containers.\n\n\ndocker rmi $(docker images | grep '^<none>' | awk '{print $3}')\n\n\n\n\nhttps://docs.docker.com/reference/commandline/cli/#rmi\n\n\nA more systematic approach is to use \nDocker Custodian\n.\n\n\nShow processes running inside all docker containers\n\n\nOn hosts without cgroup integration, run:\n\n\npgrep docker | xargs -n1 pstree\n\n\n\n\nSee Also\n\n\n\n\nhttps://www.docker.io\n - Main page\n\n\nhttp://dockerfile.github.io\n - Trusted builds of FOSS software\n\n\nhttps://registry.hub.docker.com\n - Public docker images\n\n\nhttps://docs.docker.com/reference/builder/\n - How to build Dockerfiles",
            "title": "Docker"
        },
        {
            "location": "/docker/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/docker/#show-help-on-the-run-command",
            "text": "docker help run",
            "title": "Show help on the run command"
        },
        {
            "location": "/docker/#run-a-docker-image-in-an-interactive-shell",
            "text": "docker run -i -t node bash   -i, --interactive  -t, --tty   https://docs.docker.com/reference/commandline/cli/#run",
            "title": "Run a docker image in an interactive shell"
        },
        {
            "location": "/docker/#get-a-bash-terminal-on-a-running-docker-container",
            "text": "docker exec -i -t container_name bash",
            "title": "Get a bash terminal on a running docker container"
        },
        {
            "location": "/docker/#run-a-docker-image-and-assign-it-a-hostname-and-a-docker-name",
            "text": "docker run --hostname=somehost1 --name=\"host1\" -ti centos:centos6 bash  The hostname shows up to the OS. The docker name can be used to interact with the container:  docker ps host1",
            "title": "Run a docker image and assign it a hostname, and a docker name"
        },
        {
            "location": "/docker/#run-a-container-with-a-tcp-port-map",
            "text": "This maps port 18022 of the host to 22 of the guest.  docker run -ti -p 18022:22 centos bash",
            "title": "Run a container with a tcp port map"
        },
        {
            "location": "/docker/#run-a-container-with-a-shared-directory",
            "text": "We are specifying :ro to make this a read-only mount. Default is rw.  docker run -d -v \"$HOME/www/:/var/www/html/:ro\" php:5.4.35-apache",
            "title": "Run a container with a shared directory"
        },
        {
            "location": "/docker/#show-configuration-parameters-for-a-container",
            "text": "This shows more things that you can configure, like DNS, DNS search, etc..  docker inspect host1",
            "title": "Show configuration parameters for a container"
        },
        {
            "location": "/docker/#show-what-has-changed-since-a-container-was-started",
            "text": "docker diff <container-id>  https://docs.docker.com/reference/commandline/cli/#diff",
            "title": "Show what has changed since a container was started"
        },
        {
            "location": "/docker/#view-the-terminal-scrollback-of-a-a-container",
            "text": "docker logs <container-id>",
            "title": "View the terminal scrollback of a a container"
        },
        {
            "location": "/docker/#list-all-containers-including-ones-that-have-been-stopped",
            "text": "This allows you to restart previous instances of a container.  docker ps -a  https://docs.docker.com/reference/commandline/cli/#ps",
            "title": "List all containers, including ones that have been stopped"
        },
        {
            "location": "/docker/#start-a-named-container",
            "text": "By default containers don't restart when your system restarts, so you have to start them manually.  docker start ttrss",
            "title": "Start a named container"
        },
        {
            "location": "/docker/#stop-a-named-container",
            "text": "docker stop ttrss",
            "title": "Stop a named container"
        },
        {
            "location": "/docker/#update-the-restart-policy-on-a-running-container",
            "text": "docker update --restart=unless-stopped 3a898cb672ad",
            "title": "Update the restart policy on a running container"
        },
        {
            "location": "/docker/#get-a-shell-on-a-running-container",
            "text": "docker exec -ti ttrss bash",
            "title": "Get a shell on a running container"
        },
        {
            "location": "/docker/#delete-old-containers",
            "text": "https://docs.docker.com/reference/commandline/cli/#rm  Remove  -r  from  xargs  on non-GNU systems.  docker ps -a --format=\"{{.ID}} {{.Status}}\" | awk '$2 == \"Exited\" && $5 ~ /(days|weeks|months)/ {print $1}' | xargs -r docker rm  A more systematic approach is to use  Docker Custodian .",
            "title": "Delete old containers"
        },
        {
            "location": "/docker/#delete-old-images",
            "text": "This is safe to run as long as valuable containers are running, as it won't delete any images that are attached to running containers.  docker rmi $(docker images | grep '^<none>' | awk '{print $3}')  https://docs.docker.com/reference/commandline/cli/#rmi  A more systematic approach is to use  Docker Custodian .",
            "title": "Delete old images"
        },
        {
            "location": "/docker/#show-processes-running-inside-all-docker-containers",
            "text": "On hosts without cgroup integration, run:  pgrep docker | xargs -n1 pstree",
            "title": "Show processes running inside all docker containers"
        },
        {
            "location": "/docker/#see-also",
            "text": "https://www.docker.io  - Main page  http://dockerfile.github.io  - Trusted builds of FOSS software  https://registry.hub.docker.com  - Public docker images  https://docs.docker.com/reference/builder/  - How to build Dockerfiles",
            "title": "See Also"
        },
        {
            "location": "/dsrc/",
            "text": "\"Dedicated Short Range Communications is a two-way short-to-medium range wireless communications capability that permits very high data transmission critical in communications-based active safety applications\" - \nhttps://www.its.dot.gov/factsheets/dsrc_factsheet.htm\n\n\n\"Dedicated short-range communications are one-way or two-way short-range to medium-range wireless communication channels specifically designed for automotive use and a corresponding set of protocols and standards.\" - \nhttps://en.wikipedia.org/wiki/Dedicated_short-range_communications\n\n\nLinks\n\n\n\n\nhttps://www.its.dot.gov/factsheets/dsrc_factsheet.htm\n\n\nhttps://en.wikipedia.org/wiki/Dedicated_short-range_communications\n\n\nhttps://www.fcc.gov/wireless/bureau-divisions/mobility-division/dedicated-short-range-communications-dsrc-service",
            "title": "Dsrc"
        },
        {
            "location": "/dsrc/#links",
            "text": "https://www.its.dot.gov/factsheets/dsrc_factsheet.htm  https://en.wikipedia.org/wiki/Dedicated_short-range_communications  https://www.fcc.gov/wireless/bureau-divisions/mobility-division/dedicated-short-range-communications-dsrc-service",
            "title": "Links"
        },
        {
            "location": "/du/",
            "text": "\"estimate file space usage\" - \nman du\n\n\nExamples\n\n\nSummarize low level directory uage\n\n\nWhen a partition fills up this is a good place to begin looking. Some flags may not be available, such as \nsort -h\n\n\n# -x      --one-file-system\n# -d 3    --max-depth=3\n# -h      --human-readable\nsudo du -x -d 3 -h / | sort -h",
            "title": "Du"
        },
        {
            "location": "/du/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/du/#summarize-low-level-directory-uage",
            "text": "When a partition fills up this is a good place to begin looking. Some flags may not be available, such as  sort -h  # -x      --one-file-system\n# -d 3    --max-depth=3\n# -h      --human-readable\nsudo du -x -d 3 -h / | sort -h",
            "title": "Summarize low level directory uage"
        },
        {
            "location": "/duplicity/",
            "text": "Encrypted bandwidth-efficient backup using the rsync algorithm\n\n\n\n\nhttp://duplicity.nongnu.org/",
            "title": "Duplicity"
        },
        {
            "location": "/education/",
            "text": "https://www.coursera.org/\n\n\nhttps://www.edx.org/\n\n\nhttps://www.udemy.com/",
            "title": "Education"
        },
        {
            "location": "/eleduino/",
            "text": "Eleduino SpotPear touchscreen\n\n\nTaken from \nhttps://github.com/notro/rpi-firmware/issues/6#issuecomment-63180647\n, this is tested to work on Raspbian 7 (wheezy) and 8 (jessie).\n\n\nupdate the firmware to support FBTFT\n\n\nsudo apt-get install -y rpi-update\nsudo REPO_URI=https://github.com/notro/rpi-firmware BRANCH=builtin rpi-update\nsudo reboot\n\n\n\n\nModify boot args to enable the device\n\n\nsed -i \"s/$/ \\\nfbtft_device.custom \\\nfbtft_device.name=fb_ili9340 \\\nfbtft_device.gpios=dc:22,reset:27 \\\nfbtft_device.bgr=1 \\\nfbtft_device.speed=48000000/\" /boot/cmdline.txt\n\n\n\n\nEnable console on boot\n\n\nsed -i \"s/$/ \\\nfbcon=map:10 \\\nfbcon=font:ProFont6x11 \\\nlogo.nologo/\" /boot/cmdline.txt\n\n\n\n\nRotation etc..\n\n\nsed -i \"s/$/ \\\ndma.dmachans=0x7f35 \\\nconsole=tty1 \\\nconsoleblank=0 \\\nfbtft_device.fps=50 \\\nfbtft_device.rotate=270/\" /boot/cmdline.txt\n\n\n\n\nSort and unique /boot/cmdline.txt\n\n\ncat /boot/cmdline.txt | \\\ntee /root/cmdline.txt-$(date +%s) | \\\ntr \" \" \"\\n\" | \\\nsort -u | \\\ntr \"\\n\" \" \" > /boot/cmdline.txt",
            "title": "Eleduino SpotPear touchscreen"
        },
        {
            "location": "/eleduino/#eleduino-spotpear-touchscreen",
            "text": "Taken from  https://github.com/notro/rpi-firmware/issues/6#issuecomment-63180647 , this is tested to work on Raspbian 7 (wheezy) and 8 (jessie).",
            "title": "Eleduino SpotPear touchscreen"
        },
        {
            "location": "/eleduino/#update-the-firmware-to-support-fbtft",
            "text": "sudo apt-get install -y rpi-update\nsudo REPO_URI=https://github.com/notro/rpi-firmware BRANCH=builtin rpi-update\nsudo reboot",
            "title": "update the firmware to support FBTFT"
        },
        {
            "location": "/eleduino/#modify-boot-args-to-enable-the-device",
            "text": "sed -i \"s/$/ \\\nfbtft_device.custom \\\nfbtft_device.name=fb_ili9340 \\\nfbtft_device.gpios=dc:22,reset:27 \\\nfbtft_device.bgr=1 \\\nfbtft_device.speed=48000000/\" /boot/cmdline.txt",
            "title": "Modify boot args to enable the device"
        },
        {
            "location": "/eleduino/#enable-console-on-boot",
            "text": "sed -i \"s/$/ \\\nfbcon=map:10 \\\nfbcon=font:ProFont6x11 \\\nlogo.nologo/\" /boot/cmdline.txt",
            "title": "Enable console on boot"
        },
        {
            "location": "/eleduino/#rotation-etc",
            "text": "sed -i \"s/$/ \\\ndma.dmachans=0x7f35 \\\nconsole=tty1 \\\nconsoleblank=0 \\\nfbtft_device.fps=50 \\\nfbtft_device.rotate=270/\" /boot/cmdline.txt",
            "title": "Rotation etc.."
        },
        {
            "location": "/eleduino/#sort-and-unique-bootcmdlinetxt",
            "text": "cat /boot/cmdline.txt | \\\ntee /root/cmdline.txt-$(date +%s) | \\\ntr \" \" \"\\n\" | \\\nsort -u | \\\ntr \"\\n\" \" \" > /boot/cmdline.txt",
            "title": "Sort and unique /boot/cmdline.txt"
        },
        {
            "location": "/exiftool/",
            "text": "CLI Tool to read and write image metadata for many kinds of images.\n\n\n\n\nhttp://www.sno.phy.queensu.ca/~phil/exiftool/\n\n\n\n\nTricks\n\n\nStrip all tags\n\n\nexiftool -all= filename.jpg\n\n\n\n\nShow tags in a format that you can use to rewrite them\n\n\nexiftool -S filename.jpg\n\n\n\n\nExpanded basic usage\n\n\nexiftool -a -u -G:1:2 filename\n\n\n\n\nAdd missing lens data on Rokinon 85mm\n\n\nexiftool \\\n  -overwrite_original \\\n  -LensModel='Rokinon 85mm f/1.4' \\\n  -FocalLength='85' \\\n  -LongFocal='85' \\\n  -ShortFocal='85' \\\n  filename.dng\n\n\n\n\nCorrect EXIF time, for instance to sync with GPS time\n\n\n# exiftool -AllDates-='Y:M:D H:M:S'\nexiftool -AllDates+='0:0:0 0:1:56'\n\n\n\n\nSet all dates to something obviously wrong (useful for scanned images)\n\n\nexiftool -alldates='1900:01:01 01:01:01' *\n\n\n\n\nRename GPX files based on the capture time\n\n\nYou will end up with a filename like \n2013-09-30-23-35-40.gpx\n based off of the \nfirst\n trkpt timestamp.\n\n\nexiftool -d '%Y%m%d-%H-%M-%S' '-FileName<${GpxTrkTrksegTrkptTime;tr/ /-/;tr/:/-/;tr(/Z/)()d;}%-c.gpx' *.gpx\n\n\n\n\nRename files to their original date and time using a lower case file extension\n\n\nexiftool \"-FileName<CreateDate\" -d \"%Y%m%d-%H-%M-%S%%-c.%%le\" *.jpg\n\n\n\n\nRename files using a combination of tags\n\n\nThe '%-c' string here adds a '-1' if there are two of the same target filename, and increments if there are more, but is null for unique filenames.\n\n\nexiftool -d '%Y%m%d-%H-%M-%S' '-FileName<${CreateDate;}_${Headline;}%-c.%e'\n\n\n\n\nSet file modify time to image capture time\n\n\nexiftool \"-FileModifyDate<DateTimeOriginal\" *.jpg\n\n\n\n\nGenerate a table of Filename, Camera Model and File Size in bytes, sorted by bytes\n\n\nfind /src_dir/ -iname '*.dng' |\n  xargs  exiftool -p '$filename,$Model,$FileSize#' 2>/dev/null |\n  sort   -t, -k3 -n |\n  column -s, -t\n\n\n\n\nGenerate rsync commands for files matching a string\n\n\nexiftool -d \"%s\" -p 'rsync -aP $filename ~/Desktop/Stuff/ # $VideoFrameRate' 201411{2,3}* | grep -v '# 29\\.'\n\n\n\n\nRename files to their ShutterCount\n\n\nFilenames will not be changed if ShutterCount field is not populated.\n\n\nexiftool -P '-filename<${ShutterCount;}.%e' *.dng\n\n\n\n\nRename files based on a set of possible names\n\n\nExiftool will use the last parameter where all variables are present.\n\n\nexiftool -P -d '%F-%H-%M-%S' \\\n  '-filename<${DateTimeOriginal} - ${Make;}.%e' \\\n  '-filename<${CreateDate} - ${Make;}.%e' \\\n  '-filename<${DateTimeOriginal} - ${Make;} - ${Model;}.%e' \\\n  '-filename<${CreateDate} - ${Make;} - ${Model;}.%e' \\\n  '-filename<${DateTimeOriginal} - ${Make;} - ${Model;} - ${ShutterCount}.%e' \\\n  '-filename<${CreateDate} - ${Make;} - ${Model;} - ${ShutterCount}.%e' \\\n  *.dng\n\n\n\n\nUse TestName tag target to test what files would be renamed to\n\n\nThis block builds an array of possible tags to use as a filename, creates an exiftool argument string from that array, then tests what files would be named to. This is useful when dealing with files from various sources that don't all use the same tag to store the original media creation time. By using \nTestName\n instead of \nFileName\n as the target, we observe what would occur, essentially a dry-run, instead of actually renaming the files.\n\n\nThere is a funky behavior of %-c when you operate on a file that should ideally not be renamed. Exiftool will toggle back and forth each run appending and removing \n-1\n.\n\n\nThis assumes GNU xargs for the \n-r\n flag.\n\n\n#!/usr/bin/env bash\nset -x\n\n# The last valid variable from this list is used as the filename source\ncreate_date_sources=(\n  TrackCreateDate\n  RIFF:DateTimeOriginal\n  MediaCreateDate\n  FileModifyDate\n  DateTimeOriginal\n  CreateDate\n)\n\nfor opt in \"${create_date_sources[@]}\" ; do\n  args+=( \"-TestName<${opt}\" ) ;\ndone ;\n\nargs+=( '-d' './%Y/%m/%Y%m%d-%H-%M-%S%%-c.%%le' )\n\nfind . -maxdepth 1 -type f ! -name '*.sh' -print0 | xargs -0 -r exiftool \"${args[@]}\"\n\n\n\n\nRename music files in a directory\n\n\nThere is a big gotcha here, which is that slashes will create directories where they appear, which can cause serious problems. The \n${Tag;s/\\//_/}\n syntax replaces \n/\n with \n_\n, but there may be other characters that can cause unexpected results. This is a great place to use \n-TestName\n to inspect what would change before using \n-FileName\n to make the changes.\n\n\nexiftool \\\n  '-FileName<${Artist;s/\\//_/} - ${Title;s/\\//_/}.%e' \\\n  '-FileName<${Artist;s/\\//_/} - ${Album;s/\\//_/} - ${Title;s/\\//_/}.%e' \\\n  *.mp3 *.m4a\n\n\n\n\nMove short videos to one dir, long videos to another dir\n\n\nIn iOS, if you have Live Photo enabled it creates little movies each time you take a photo. While these can be very interesting context around photos, they can be quite irritating if you're playing through a collection of videos where these are mixed with videos of more moderate duration. The following code snip separates videos with a duration of more than 10 seconds from those with equal or lesser duration.\n\n\n# -TestName is used here so it does not destroy data. Replace this with FileName to make this actually work.\n# $Duration# has the # sign appended to make this tag machine readable so it can accurately be compared.\n# We must use perl's numeric comparisons (>, <=), not string comparisons (gt, le)\n# exiftool does not support if else syntax, so for the else condition you must run a second command.\n\nlong_args=(  \"-TestName<${opt}\" '-d' \"${working_path}/long/%Y/%m/%Y%m%d-%H-%M-%S%%-c.%%le\"  '-if' '${Duration#} >  10' )\nshort_args=( \"-TestName<${opt}\" '-d' \"${working_path}/short/%Y/%m/%Y%m%d-%H-%M-%S%%-c.%%le\" '-if' '${Duration#} <= 10' )\n\nfind \"${PWD}\" -maxdepth 1 -type f -print0 | xargs -0 -r exiftool \"${long_args[@]}\"\nfind \"${PWD}\" -maxdepth 1 -type f -print0 | xargs -0 -r exiftool \"${short_args[@]}\"\n\n\n\n\nSee Also\n\n\n\n\ngraphicsmagick\n\n\nimagemagick\n\n\njpeginfo\n\n\nsips",
            "title": "Exiftool"
        },
        {
            "location": "/exiftool/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/exiftool/#strip-all-tags",
            "text": "exiftool -all= filename.jpg",
            "title": "Strip all tags"
        },
        {
            "location": "/exiftool/#show-tags-in-a-format-that-you-can-use-to-rewrite-them",
            "text": "exiftool -S filename.jpg",
            "title": "Show tags in a format that you can use to rewrite them"
        },
        {
            "location": "/exiftool/#expanded-basic-usage",
            "text": "exiftool -a -u -G:1:2 filename",
            "title": "Expanded basic usage"
        },
        {
            "location": "/exiftool/#add-missing-lens-data-on-rokinon-85mm",
            "text": "exiftool \\\n  -overwrite_original \\\n  -LensModel='Rokinon 85mm f/1.4' \\\n  -FocalLength='85' \\\n  -LongFocal='85' \\\n  -ShortFocal='85' \\\n  filename.dng",
            "title": "Add missing lens data on Rokinon 85mm"
        },
        {
            "location": "/exiftool/#correct-exif-time-for-instance-to-sync-with-gps-time",
            "text": "# exiftool -AllDates-='Y:M:D H:M:S'\nexiftool -AllDates+='0:0:0 0:1:56'",
            "title": "Correct EXIF time, for instance to sync with GPS time"
        },
        {
            "location": "/exiftool/#set-all-dates-to-something-obviously-wrong-useful-for-scanned-images",
            "text": "exiftool -alldates='1900:01:01 01:01:01' *",
            "title": "Set all dates to something obviously wrong (useful for scanned images)"
        },
        {
            "location": "/exiftool/#rename-gpx-files-based-on-the-capture-time",
            "text": "You will end up with a filename like  2013-09-30-23-35-40.gpx  based off of the  first  trkpt timestamp.  exiftool -d '%Y%m%d-%H-%M-%S' '-FileName<${GpxTrkTrksegTrkptTime;tr/ /-/;tr/:/-/;tr(/Z/)()d;}%-c.gpx' *.gpx",
            "title": "Rename GPX files based on the capture time"
        },
        {
            "location": "/exiftool/#rename-files-to-their-original-date-and-time-using-a-lower-case-file-extension",
            "text": "exiftool \"-FileName<CreateDate\" -d \"%Y%m%d-%H-%M-%S%%-c.%%le\" *.jpg",
            "title": "Rename files to their original date and time using a lower case file extension"
        },
        {
            "location": "/exiftool/#rename-files-using-a-combination-of-tags",
            "text": "The '%-c' string here adds a '-1' if there are two of the same target filename, and increments if there are more, but is null for unique filenames.  exiftool -d '%Y%m%d-%H-%M-%S' '-FileName<${CreateDate;}_${Headline;}%-c.%e'",
            "title": "Rename files using a combination of tags"
        },
        {
            "location": "/exiftool/#set-file-modify-time-to-image-capture-time",
            "text": "exiftool \"-FileModifyDate<DateTimeOriginal\" *.jpg",
            "title": "Set file modify time to image capture time"
        },
        {
            "location": "/exiftool/#generate-a-table-of-filename-camera-model-and-file-size-in-bytes-sorted-by-bytes",
            "text": "find /src_dir/ -iname '*.dng' |\n  xargs  exiftool -p '$filename,$Model,$FileSize#' 2>/dev/null |\n  sort   -t, -k3 -n |\n  column -s, -t",
            "title": "Generate a table of Filename, Camera Model and File Size in bytes, sorted by bytes"
        },
        {
            "location": "/exiftool/#generate-rsync-commands-for-files-matching-a-string",
            "text": "exiftool -d \"%s\" -p 'rsync -aP $filename ~/Desktop/Stuff/ # $VideoFrameRate' 201411{2,3}* | grep -v '# 29\\.'",
            "title": "Generate rsync commands for files matching a string"
        },
        {
            "location": "/exiftool/#rename-files-to-their-shuttercount",
            "text": "Filenames will not be changed if ShutterCount field is not populated.  exiftool -P '-filename<${ShutterCount;}.%e' *.dng",
            "title": "Rename files to their ShutterCount"
        },
        {
            "location": "/exiftool/#rename-files-based-on-a-set-of-possible-names",
            "text": "Exiftool will use the last parameter where all variables are present.  exiftool -P -d '%F-%H-%M-%S' \\\n  '-filename<${DateTimeOriginal} - ${Make;}.%e' \\\n  '-filename<${CreateDate} - ${Make;}.%e' \\\n  '-filename<${DateTimeOriginal} - ${Make;} - ${Model;}.%e' \\\n  '-filename<${CreateDate} - ${Make;} - ${Model;}.%e' \\\n  '-filename<${DateTimeOriginal} - ${Make;} - ${Model;} - ${ShutterCount}.%e' \\\n  '-filename<${CreateDate} - ${Make;} - ${Model;} - ${ShutterCount}.%e' \\\n  *.dng",
            "title": "Rename files based on a set of possible names"
        },
        {
            "location": "/exiftool/#use-testname-tag-target-to-test-what-files-would-be-renamed-to",
            "text": "This block builds an array of possible tags to use as a filename, creates an exiftool argument string from that array, then tests what files would be named to. This is useful when dealing with files from various sources that don't all use the same tag to store the original media creation time. By using  TestName  instead of  FileName  as the target, we observe what would occur, essentially a dry-run, instead of actually renaming the files.  There is a funky behavior of %-c when you operate on a file that should ideally not be renamed. Exiftool will toggle back and forth each run appending and removing  -1 .  This assumes GNU xargs for the  -r  flag.  #!/usr/bin/env bash\nset -x\n\n# The last valid variable from this list is used as the filename source\ncreate_date_sources=(\n  TrackCreateDate\n  RIFF:DateTimeOriginal\n  MediaCreateDate\n  FileModifyDate\n  DateTimeOriginal\n  CreateDate\n)\n\nfor opt in \"${create_date_sources[@]}\" ; do\n  args+=( \"-TestName<${opt}\" ) ;\ndone ;\n\nargs+=( '-d' './%Y/%m/%Y%m%d-%H-%M-%S%%-c.%%le' )\n\nfind . -maxdepth 1 -type f ! -name '*.sh' -print0 | xargs -0 -r exiftool \"${args[@]}\"",
            "title": "Use TestName tag target to test what files would be renamed to"
        },
        {
            "location": "/exiftool/#rename-music-files-in-a-directory",
            "text": "There is a big gotcha here, which is that slashes will create directories where they appear, which can cause serious problems. The  ${Tag;s/\\//_/}  syntax replaces  /  with  _ , but there may be other characters that can cause unexpected results. This is a great place to use  -TestName  to inspect what would change before using  -FileName  to make the changes.  exiftool \\\n  '-FileName<${Artist;s/\\//_/} - ${Title;s/\\//_/}.%e' \\\n  '-FileName<${Artist;s/\\//_/} - ${Album;s/\\//_/} - ${Title;s/\\//_/}.%e' \\\n  *.mp3 *.m4a",
            "title": "Rename music files in a directory"
        },
        {
            "location": "/exiftool/#move-short-videos-to-one-dir-long-videos-to-another-dir",
            "text": "In iOS, if you have Live Photo enabled it creates little movies each time you take a photo. While these can be very interesting context around photos, they can be quite irritating if you're playing through a collection of videos where these are mixed with videos of more moderate duration. The following code snip separates videos with a duration of more than 10 seconds from those with equal or lesser duration.  # -TestName is used here so it does not destroy data. Replace this with FileName to make this actually work.\n# $Duration# has the # sign appended to make this tag machine readable so it can accurately be compared.\n# We must use perl's numeric comparisons (>, <=), not string comparisons (gt, le)\n# exiftool does not support if else syntax, so for the else condition you must run a second command.\n\nlong_args=(  \"-TestName<${opt}\" '-d' \"${working_path}/long/%Y/%m/%Y%m%d-%H-%M-%S%%-c.%%le\"  '-if' '${Duration#} >  10' )\nshort_args=( \"-TestName<${opt}\" '-d' \"${working_path}/short/%Y/%m/%Y%m%d-%H-%M-%S%%-c.%%le\" '-if' '${Duration#} <= 10' )\n\nfind \"${PWD}\" -maxdepth 1 -type f -print0 | xargs -0 -r exiftool \"${long_args[@]}\"\nfind \"${PWD}\" -maxdepth 1 -type f -print0 | xargs -0 -r exiftool \"${short_args[@]}\"",
            "title": "Move short videos to one dir, long videos to another dir"
        },
        {
            "location": "/exiftool/#see-also",
            "text": "graphicsmagick  imagemagick  jpeginfo  sips",
            "title": "See Also"
        },
        {
            "location": "/fedramp/",
            "text": "Fedramp\n\n\n\n\nhttps://en.wikipedia.org/wiki/FedRAMP\n\n\nhttps://www.fedramp.gov/",
            "title": "Fedramp"
        },
        {
            "location": "/fedramp/#fedramp",
            "text": "https://en.wikipedia.org/wiki/FedRAMP  https://www.fedramp.gov/",
            "title": "Fedramp"
        },
        {
            "location": "/ffmpeg/",
            "text": "ffmpeg is a tool for editing movie files.\n\n\n\n\nhttps://ffmpeg.org\n\n\n\n\nExamples\n\n\nConvert container format\n\n\nfor X in *.mov ; do ffmpeg -i \"${X}\" -c copy -map 0 \"${X%.mov}.mp4\" ; done ;\n\n\n\n\nTime Lapse\n\n\nGenerate a movie from an image sequence like 001.jpg-999.jpg\n\n\nffmpeg -r 10 -b 1800 -i %03d.jpg test1800.mp4\n\n\nRename files as a sequence:\n\n\ni=0 ;\nfind . -type f |\n  while read -r F ; do\n    let i=${i}+1 ;\n    fn=$(printf %06d ${i}) ;\n    mv \"${F}\" \"${fn}.jpg\" ;\n  done ;\n\n\n\n\nSample some of the middle of the time-lapse\n\n\nffmpeg -pattern_type sequence -start_number 3000 -r 30 -i %06d.jpg -s 1440x1080 -frames 120 \"$(date +%F_%T).mp4\"\n\n\nTurn these images into a video\n\n\nffmpeg -pattern_type sequence -r 30 -i %06d.jpg -s 1440x1080 \"$(date +%F_%T).mp4\"\n\n\nAudio Replace\n\n\nReplace the audio of DSC_4436.AVI with 01 Gymnopedie 1.mp3 and limit the duration of the output so the music doesn't play beyond the end of the video.\n\n\nffmpeg -t 00:00:47.99 -i DSC_4436.AVI -i \"01 Gymnopedie 1.mp3\" -map 0:0 -map 1:0 -vcodec copy -acodec copy output.AVI\n\n\nSlow down video to half speed, drop audio\n\n\nffmpeg -i DHO_8751.MOV -an -vf \"setpts=(2/1)*PTS\" output.mp4\n\n\nExtract two seconds worth of frames at 24fps starting at 15m\n\n\nffmpeg -i movie.mkv -r 24 -t 00:00:02.00 -ss 00:15:00 temp/movie-%4d.jpg\n\n\nDetect errors in files\n\n\nffmpeg -v error -i 20091024-08-46-00.mpg -f null - 2>> error.log",
            "title": "Ffmpeg"
        },
        {
            "location": "/ffmpeg/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/ffmpeg/#convert-container-format",
            "text": "for X in *.mov ; do ffmpeg -i \"${X}\" -c copy -map 0 \"${X%.mov}.mp4\" ; done ;",
            "title": "Convert container format"
        },
        {
            "location": "/ffmpeg/#time-lapse",
            "text": "",
            "title": "Time Lapse"
        },
        {
            "location": "/ffmpeg/#generate-a-movie-from-an-image-sequence-like-001jpg-999jpg",
            "text": "ffmpeg -r 10 -b 1800 -i %03d.jpg test1800.mp4",
            "title": "Generate a movie from an image sequence like 001.jpg-999.jpg"
        },
        {
            "location": "/ffmpeg/#rename-files-as-a-sequence",
            "text": "i=0 ;\nfind . -type f |\n  while read -r F ; do\n    let i=${i}+1 ;\n    fn=$(printf %06d ${i}) ;\n    mv \"${F}\" \"${fn}.jpg\" ;\n  done ;",
            "title": "Rename files as a sequence:"
        },
        {
            "location": "/ffmpeg/#sample-some-of-the-middle-of-the-time-lapse",
            "text": "ffmpeg -pattern_type sequence -start_number 3000 -r 30 -i %06d.jpg -s 1440x1080 -frames 120 \"$(date +%F_%T).mp4\"",
            "title": "Sample some of the middle of the time-lapse"
        },
        {
            "location": "/ffmpeg/#turn-these-images-into-a-video",
            "text": "ffmpeg -pattern_type sequence -r 30 -i %06d.jpg -s 1440x1080 \"$(date +%F_%T).mp4\"",
            "title": "Turn these images into a video"
        },
        {
            "location": "/ffmpeg/#audio-replace",
            "text": "Replace the audio of DSC_4436.AVI with 01 Gymnopedie 1.mp3 and limit the duration of the output so the music doesn't play beyond the end of the video.  ffmpeg -t 00:00:47.99 -i DSC_4436.AVI -i \"01 Gymnopedie 1.mp3\" -map 0:0 -map 1:0 -vcodec copy -acodec copy output.AVI",
            "title": "Audio Replace"
        },
        {
            "location": "/ffmpeg/#slow-down-video-to-half-speed-drop-audio",
            "text": "ffmpeg -i DHO_8751.MOV -an -vf \"setpts=(2/1)*PTS\" output.mp4",
            "title": "Slow down video to half speed, drop audio"
        },
        {
            "location": "/ffmpeg/#extract-two-seconds-worth-of-frames-at-24fps-starting-at-15m",
            "text": "ffmpeg -i movie.mkv -r 24 -t 00:00:02.00 -ss 00:15:00 temp/movie-%4d.jpg",
            "title": "Extract two seconds worth of frames at 24fps starting at 15m"
        },
        {
            "location": "/ffmpeg/#detect-errors-in-files",
            "text": "ffmpeg -v error -i 20091024-08-46-00.mpg -f null - 2>> error.log",
            "title": "Detect errors in files"
        },
        {
            "location": "/figlet/",
            "text": "Figlet prints horizontal text in ascii drawings.\n\n\nExamples\n\n\nPrint text\n\n\n$ figlet hello\n  _          _ _\n | |__   ___| | | ___\n | '_ \\ / _ \\ | |/ _ \\\n | | | |  __/ | | (_) |\n |_| |_|\\___|_|_|\\___/\n\n\n\n\nShow available fonts\n\n\n$ showfigfonts | head\n3-d :\n  ****             **\n */// *           /**\n/    /*           /**\n   ***  *****  ******\n  /// */////  **///**\n *   /*      /**  /**\n/ ****       //******\n ////         //////\n\n\n\n\nUse a font\n\n\n$ figlet -f 3-d hello\n **               **  **\n/**              /** /**\n/**       *****  /** /**  ******\n/******  **///** /** /** **////**\n/**///**/******* /** /**/**   /**\n/**  /**/**////  /** /**/**   /**\n/**  /**//****** *** ***//******\n//   //  ////// /// ///  //////\n\n\n\n\nSee Also\n\n\n\n\ncowsay",
            "title": "Figlet"
        },
        {
            "location": "/figlet/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/figlet/#print-text",
            "text": "$ figlet hello\n  _          _ _\n | |__   ___| | | ___\n | '_ \\ / _ \\ | |/ _ \\\n | | | |  __/ | | (_) |\n |_| |_|\\___|_|_|\\___/",
            "title": "Print text"
        },
        {
            "location": "/figlet/#show-available-fonts",
            "text": "$ showfigfonts | head\n3-d :\n  ****             **\n */// *           /**\n/    /*           /**\n   ***  *****  ******\n  /// */////  **///**\n *   /*      /**  /**\n/ ****       //******\n ////         //////",
            "title": "Show available fonts"
        },
        {
            "location": "/figlet/#use-a-font",
            "text": "$ figlet -f 3-d hello\n **               **  **\n/**              /** /**\n/**       *****  /** /**  ******\n/******  **///** /** /** **////**\n/**///**/******* /** /**/**   /**\n/**  /**/**////  /** /**/**   /**\n/**  /**//****** *** ***//******\n//   //  ////// /// ///  //////",
            "title": "Use a font"
        },
        {
            "location": "/figlet/#see-also",
            "text": "cowsay",
            "title": "See Also"
        },
        {
            "location": "/file-downloaders/",
            "text": "There are so many ways to download files!\n\n\n\n\naria2\n - multi threaded multi connection multi protocol resumable downloader\n\n\ncurl\n - the swiss army knife of downloaders\n\n\nhttpstat\n - download and show a some useful connection information\n\n\nwget\n - great for automated downloads, mirroring, and downloading sets",
            "title": "File downloaders"
        },
        {
            "location": "/find/",
            "text": "The \nfind\n util letes you search a filesystem for things that match filesystem attributes. Unfortunately this is one of those tools where BSD and GNU deviate syntactically and featurewise, and GNU mostly wins.\n\n\nExamples\n\n\nFind and delete empty directories 2 levels deep or deeper\n\n\nfind \"${PWD}\" -mindepth 2 -type d -empty -delete\n\n\nFind based on a regex\n\n\nfind /tank/movies -regextype egrep -iregex '.*\\.(mov|mp4)$'\n\n\nFind files and perform operations on them\n\n\nOne at a time:\n\n\nfind \"${PWD}\" -type d -exec dot_clean {} \\;\n\n\nOr several in batches, similar to how xargs handles things:\n\n\nfind \"${PWD}\" -type d -exec dot_clean {} \\+\n\n\nFind files that match a glob\n\n\nfind \"${PWD}\" -name '????????-??-??-??_[0-9][0-9][0-9]???.dng'\n\n\nAlter permissions on some files that are not already set correctly\n\n\nfind . -mindepth 2 -type f ! -perm 444 -exec chmod 444 {} \\+\n\n\nFind files in the current directory that do not match any of several listed filenames\n\n\nfind . -maxdepth 1 -type f ! -iname '.*' ! -name .DS_Store ! -name '*.db'\n\n\nCorrectly handle spaces when piping to xargs\n\n\nfind /Applications -mindepth 1 -maxdepth 1 -type d -name '* *' -print0 | xargs -0 -n1 echo\n\n\nFind executable files\n\n\nThis finds all files where an executable bit is set.\n\n\nWith BSD find:\n\n\nfind . -type f -perm +111\n\n\nWith GNU find:\n\n\nfind . -type f -executable",
            "title": "Find"
        },
        {
            "location": "/find/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/find/#find-and-delete-empty-directories-2-levels-deep-or-deeper",
            "text": "find \"${PWD}\" -mindepth 2 -type d -empty -delete",
            "title": "Find and delete empty directories 2 levels deep or deeper"
        },
        {
            "location": "/find/#find-based-on-a-regex",
            "text": "find /tank/movies -regextype egrep -iregex '.*\\.(mov|mp4)$'",
            "title": "Find based on a regex"
        },
        {
            "location": "/find/#find-files-and-perform-operations-on-them",
            "text": "One at a time:  find \"${PWD}\" -type d -exec dot_clean {} \\;  Or several in batches, similar to how xargs handles things:  find \"${PWD}\" -type d -exec dot_clean {} \\+",
            "title": "Find files and perform operations on them"
        },
        {
            "location": "/find/#find-files-that-match-a-glob",
            "text": "find \"${PWD}\" -name '????????-??-??-??_[0-9][0-9][0-9]???.dng'",
            "title": "Find files that match a glob"
        },
        {
            "location": "/find/#alter-permissions-on-some-files-that-are-not-already-set-correctly",
            "text": "find . -mindepth 2 -type f ! -perm 444 -exec chmod 444 {} \\+",
            "title": "Alter permissions on some files that are not already set correctly"
        },
        {
            "location": "/find/#find-files-in-the-current-directory-that-do-not-match-any-of-several-listed-filenames",
            "text": "find . -maxdepth 1 -type f ! -iname '.*' ! -name .DS_Store ! -name '*.db'",
            "title": "Find files in the current directory that do not match any of several listed filenames"
        },
        {
            "location": "/find/#correctly-handle-spaces-when-piping-to-xargs",
            "text": "find /Applications -mindepth 1 -maxdepth 1 -type d -name '* *' -print0 | xargs -0 -n1 echo",
            "title": "Correctly handle spaces when piping to xargs"
        },
        {
            "location": "/find/#find-executable-files",
            "text": "This finds all files where an executable bit is set.  With BSD find:  find . -type f -perm +111  With GNU find:  find . -type f -executable",
            "title": "Find executable files"
        },
        {
            "location": "/findmnt/",
            "text": "\"findmnt will list all mounted filesytems or search for a filesystem. The findmnt command is able to search in /etc/fstab, /etc/fstab.d, /etc/mtab or /proc/self/mountinfo. If device or mountpoint is not given, all filesystems are shown.\" - \nman findmnt\n\n\nExamples\n\n\nSimple usage\n\n\nHere is the output of \nfindmnt\n on an \nUbuntu\n 16.04 \nVagrant\n box:\n\n\nTARGET                                SOURCE     FSTYPE     OPTIONS\n/                                     /dev/sda1  ext4       rw,relatime,data=ordered\n\u251c\u2500/sys                                sysfs      sysfs      rw,nosuid,nodev,noexec,relatime\n\u2502 \u251c\u2500/sys/kernel/security              securityfs securityfs rw,nosuid,nodev,noexec,relatime\n\u2502 \u251c\u2500/sys/fs/cgroup                    tmpfs      tmpfs      ro,nosuid,nodev,noexec,mode=755\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/systemd          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/cpu,cpuacct      cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,cpu,cpuacct\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/perf_event       cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,perf_event\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/hugetlb          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,hugetlb\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/blkio            cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,blkio\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/devices          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,devices\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/cpuset           cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,cpuset\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/memory           cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,memory\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/net_cls,net_prio cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,net_cls,net_prio\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/freezer          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,freezer\n\u2502 \u2502 \u2514\u2500/sys/fs/cgroup/pids             cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,pids\n\u2502 \u251c\u2500/sys/fs/pstore                    pstore     pstore     rw,nosuid,nodev,noexec,relatime\n\u2502 \u251c\u2500/sys/kernel/debug                 debugfs    debugfs    rw,relatime\n\u2502 \u2514\u2500/sys/fs/fuse/connections          fusectl    fusectl    rw,relatime\n\u251c\u2500/proc                               proc       proc       rw,nosuid,nodev,noexec,relatime\n\u2502 \u2514\u2500/proc/sys/fs/binfmt_misc          systemd-1  autofs     rw,relatime,fd=33,pgrp=1,timeout=0,minproto=5,maxproto=5,direct\n\u251c\u2500/dev                                udev       devtmpfs   rw,nosuid,relatime,size=500888k,nr_inodes=125222,mode=755\n\u2502 \u251c\u2500/dev/pts                          devpts     devpts     rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\n\u2502 \u251c\u2500/dev/shm                          tmpfs      tmpfs      rw,nosuid,nodev\n\u2502 \u251c\u2500/dev/hugepages                    hugetlbfs  hugetlbfs  rw,relatime\n\u2502 \u2514\u2500/dev/mqueue                       mqueue     mqueue     rw,relatime\n\u251c\u2500/run                                tmpfs      tmpfs      rw,nosuid,noexec,relatime,size=101596k,mode=755\n\u2502 \u251c\u2500/run/lock                         tmpfs      tmpfs      rw,nosuid,nodev,noexec,relatime,size=5120k\n\u2502 \u2514\u2500/run/user/1000                    tmpfs      tmpfs      rw,nosuid,nodev,relatime,size=101596k,mode=700,uid=1000,gid=1000\n\u251c\u2500/var/lib/lxcfs                      lxcfs      fuse.lxcfs rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other\n\u2514\u2500/vagrant                            vagrant    vboxsf     rw,nodev,relatime\n\n\n\n\nOutput as key/value pairs per device\n\n\n$ findmnt -P\nTARGET=\"/sys\" SOURCE=\"sysfs\" FSTYPE=\"sysfs\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/proc\" SOURCE=\"proc\" FSTYPE=\"proc\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/dev\" SOURCE=\"udev\" FSTYPE=\"devtmpfs\" OPTIONS=\"rw,nosuid,relatime,size=500888k,nr_inodes=125222,mode=755\"\nTARGET=\"/dev/pts\" SOURCE=\"devpts\" FSTYPE=\"devpts\" OPTIONS=\"rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\"\nTARGET=\"/run\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,noexec,relatime,size=101596k,mode=755\"\nTARGET=\"/\" SOURCE=\"/dev/sda1\" FSTYPE=\"ext4\" OPTIONS=\"rw,relatime,data=ordered\"\nTARGET=\"/sys/kernel/security\" SOURCE=\"securityfs\" FSTYPE=\"securityfs\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/dev/shm\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,nodev\"\nTARGET=\"/run/lock\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,size=5120k\"\nTARGET=\"/sys/fs/cgroup\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"ro,nosuid,nodev,noexec,mode=755\"\nTARGET=\"/sys/fs/cgroup/systemd\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd\"\nTARGET=\"/sys/fs/pstore\" SOURCE=\"pstore\" FSTYPE=\"pstore\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/sys/fs/cgroup/net_cls,net_prio\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,net_cls,net_prio\"\nTARGET=\"/sys/fs/cgroup/perf_event\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,perf_event\"\nTARGET=\"/sys/fs/cgroup/cpu,cpuacct\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,cpu,cpuacct\"\nTARGET=\"/sys/fs/cgroup/hugetlb\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,hugetlb\"\nTARGET=\"/sys/fs/cgroup/memory\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,memory\"\nTARGET=\"/sys/fs/cgroup/devices\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,devices\"\nTARGET=\"/sys/fs/cgroup/freezer\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,freezer\"\nTARGET=\"/sys/fs/cgroup/cpuset\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,cpuset\"\nTARGET=\"/sys/fs/cgroup/blkio\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,blkio\"\nTARGET=\"/sys/fs/cgroup/pids\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,pids\"\nTARGET=\"/proc/sys/fs/binfmt_misc\" SOURCE=\"systemd-1\" FSTYPE=\"autofs\" OPTIONS=\"rw,relatime,fd=26,pgrp=1,timeout=0,minproto=5,maxproto=5,direct\"\nTARGET=\"/sys/kernel/debug\" SOURCE=\"debugfs\" FSTYPE=\"debugfs\" OPTIONS=\"rw,relatime\"\nTARGET=\"/dev/hugepages\" SOURCE=\"hugetlbfs\" FSTYPE=\"hugetlbfs\" OPTIONS=\"rw,relatime\"\nTARGET=\"/dev/mqueue\" SOURCE=\"mqueue\" FSTYPE=\"mqueue\" OPTIONS=\"rw,relatime\"\nTARGET=\"/sys/fs/fuse/connections\" SOURCE=\"fusectl\" FSTYPE=\"fusectl\" OPTIONS=\"rw,relatime\"\nTARGET=\"/var/lib/lxcfs\" SOURCE=\"lxcfs\" FSTYPE=\"fuse.lxcfs\" OPTIONS=\"rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other\"\nTARGET=\"/vagrant\" SOURCE=\"vagrant\" FSTYPE=\"vboxsf\" OPTIONS=\"rw,nodev,relatime\"\nTARGET=\"/run/user/1000\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,nodev,relatime,size=101596k,mode=700,uid=1000,gid=1000\"\n\n\n\n\nOutput as JSON\n\n\n$ findmnt -J\n{\n   \"filesystems\": [\n      {\"target\": \"/\", \"source\": \"/dev/sda1\", \"fstype\": \"ext4\", \"options\": \"rw,relatime,data=ordered\",\n         \"children\": [\n            {\"target\": \"/sys\", \"source\": \"sysfs\", \"fstype\": \"sysfs\", \"options\": \"rw,nosuid,nodev,noexec,relatime\",\n               \"children\": [\n                  {\"target\": \"/sys/kernel/security\", \"source\": \"securityfs\", \"fstype\": \"securityfs\", \"options\": \"rw,nosuid,nodev,noexec,relatime\"},\n                  {\"target\": \"/sys/fs/cgroup\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"ro,nosuid,nodev,noexec,mode=755\",\n                     \"children\": [\n                        {\"target\": \"/sys/fs/cgroup/systemd\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd\"},\n                        {\"target\": \"/sys/fs/cgroup/net_cls,net_prio\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,net_cls,net_prio\"},\n                        {\"target\": \"/sys/fs/cgroup/perf_event\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,perf_event\"},\n                        {\"target\": \"/sys/fs/cgroup/cpu,cpuacct\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,cpu,cpuacct\"},\n                        {\"target\": \"/sys/fs/cgroup/hugetlb\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,hugetlb\"},\n                        {\"target\": \"/sys/fs/cgroup/memory\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,memory\"},\n                        {\"target\": \"/sys/fs/cgroup/devices\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,devices\"},\n                        {\"target\": \"/sys/fs/cgroup/freezer\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,freezer\"},\n                        {\"target\": \"/sys/fs/cgroup/cpuset\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,cpuset\"},\n                        {\"target\": \"/sys/fs/cgroup/blkio\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,blkio\"},\n                        {\"target\": \"/sys/fs/cgroup/pids\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,pids\"}\n                     ]\n                  },\n                  {\"target\": \"/sys/fs/pstore\", \"source\": \"pstore\", \"fstype\": \"pstore\", \"options\": \"rw,nosuid,nodev,noexec,relatime\"},\n                  {\"target\": \"/sys/kernel/debug\", \"source\": \"debugfs\", \"fstype\": \"debugfs\", \"options\": \"rw,relatime\"},\n                  {\"target\": \"/sys/fs/fuse/connections\", \"source\": \"fusectl\", \"fstype\": \"fusectl\", \"options\": \"rw,relatime\"}\n               ]\n            },\n            {\"target\": \"/proc\", \"source\": \"proc\", \"fstype\": \"proc\", \"options\": \"rw,nosuid,nodev,noexec,relatime\",\n               \"children\": [\n                  {\"target\": \"/proc/sys/fs/binfmt_misc\", \"source\": \"systemd-1\", \"fstype\": \"autofs\", \"options\": \"rw,relatime,fd=26,pgrp=1,timeout=0,minproto=5,maxproto=5,direct\"}\n               ]\n            },\n            {\"target\": \"/dev\", \"source\": \"udev\", \"fstype\": \"devtmpfs\", \"options\": \"rw,nosuid,relatime,size=500888k,nr_inodes=125222,mode=755\",\n               \"children\": [\n                  {\"target\": \"/dev/pts\", \"source\": \"devpts\", \"fstype\": \"devpts\", \"options\": \"rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\"},\n                  {\"target\": \"/dev/shm\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,nodev\"},\n                  {\"target\": \"/dev/hugepages\", \"source\": \"hugetlbfs\", \"fstype\": \"hugetlbfs\", \"options\": \"rw,relatime\"},\n                  {\"target\": \"/dev/mqueue\", \"source\": \"mqueue\", \"fstype\": \"mqueue\", \"options\": \"rw,relatime\"}\n               ]\n            },\n            {\"target\": \"/run\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,noexec,relatime,size=101596k,mode=755\",\n               \"children\": [\n                  {\"target\": \"/run/lock\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,nodev,noexec,relatime,size=5120k\"},\n                  {\"target\": \"/run/user/1000\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,nodev,relatime,size=101596k,mode=700,uid=1000,gid=1000\"}\n               ]\n            },\n            {\"target\": \"/var/lib/lxcfs\", \"source\": \"lxcfs\", \"fstype\": \"fuse.lxcfs\", \"options\": \"rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other\"},\n            {\"target\": \"/vagrant\", \"source\": \"vagrant\", \"fstype\": \"vboxsf\", \"options\": \"rw,nodev,relatime\"},\n         ]\n      }\n   ]\n}\n\n\n\n\nSee also\n\n\n\n\nlsblk",
            "title": "Findmnt"
        },
        {
            "location": "/findmnt/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/findmnt/#simple-usage",
            "text": "Here is the output of  findmnt  on an  Ubuntu  16.04  Vagrant  box:  TARGET                                SOURCE     FSTYPE     OPTIONS\n/                                     /dev/sda1  ext4       rw,relatime,data=ordered\n\u251c\u2500/sys                                sysfs      sysfs      rw,nosuid,nodev,noexec,relatime\n\u2502 \u251c\u2500/sys/kernel/security              securityfs securityfs rw,nosuid,nodev,noexec,relatime\n\u2502 \u251c\u2500/sys/fs/cgroup                    tmpfs      tmpfs      ro,nosuid,nodev,noexec,mode=755\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/systemd          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/cpu,cpuacct      cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,cpu,cpuacct\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/perf_event       cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,perf_event\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/hugetlb          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,hugetlb\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/blkio            cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,blkio\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/devices          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,devices\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/cpuset           cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,cpuset\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/memory           cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,memory\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/net_cls,net_prio cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,net_cls,net_prio\n\u2502 \u2502 \u251c\u2500/sys/fs/cgroup/freezer          cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,freezer\n\u2502 \u2502 \u2514\u2500/sys/fs/cgroup/pids             cgroup     cgroup     rw,nosuid,nodev,noexec,relatime,pids\n\u2502 \u251c\u2500/sys/fs/pstore                    pstore     pstore     rw,nosuid,nodev,noexec,relatime\n\u2502 \u251c\u2500/sys/kernel/debug                 debugfs    debugfs    rw,relatime\n\u2502 \u2514\u2500/sys/fs/fuse/connections          fusectl    fusectl    rw,relatime\n\u251c\u2500/proc                               proc       proc       rw,nosuid,nodev,noexec,relatime\n\u2502 \u2514\u2500/proc/sys/fs/binfmt_misc          systemd-1  autofs     rw,relatime,fd=33,pgrp=1,timeout=0,minproto=5,maxproto=5,direct\n\u251c\u2500/dev                                udev       devtmpfs   rw,nosuid,relatime,size=500888k,nr_inodes=125222,mode=755\n\u2502 \u251c\u2500/dev/pts                          devpts     devpts     rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\n\u2502 \u251c\u2500/dev/shm                          tmpfs      tmpfs      rw,nosuid,nodev\n\u2502 \u251c\u2500/dev/hugepages                    hugetlbfs  hugetlbfs  rw,relatime\n\u2502 \u2514\u2500/dev/mqueue                       mqueue     mqueue     rw,relatime\n\u251c\u2500/run                                tmpfs      tmpfs      rw,nosuid,noexec,relatime,size=101596k,mode=755\n\u2502 \u251c\u2500/run/lock                         tmpfs      tmpfs      rw,nosuid,nodev,noexec,relatime,size=5120k\n\u2502 \u2514\u2500/run/user/1000                    tmpfs      tmpfs      rw,nosuid,nodev,relatime,size=101596k,mode=700,uid=1000,gid=1000\n\u251c\u2500/var/lib/lxcfs                      lxcfs      fuse.lxcfs rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other\n\u2514\u2500/vagrant                            vagrant    vboxsf     rw,nodev,relatime",
            "title": "Simple usage"
        },
        {
            "location": "/findmnt/#output-as-keyvalue-pairs-per-device",
            "text": "$ findmnt -P\nTARGET=\"/sys\" SOURCE=\"sysfs\" FSTYPE=\"sysfs\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/proc\" SOURCE=\"proc\" FSTYPE=\"proc\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/dev\" SOURCE=\"udev\" FSTYPE=\"devtmpfs\" OPTIONS=\"rw,nosuid,relatime,size=500888k,nr_inodes=125222,mode=755\"\nTARGET=\"/dev/pts\" SOURCE=\"devpts\" FSTYPE=\"devpts\" OPTIONS=\"rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\"\nTARGET=\"/run\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,noexec,relatime,size=101596k,mode=755\"\nTARGET=\"/\" SOURCE=\"/dev/sda1\" FSTYPE=\"ext4\" OPTIONS=\"rw,relatime,data=ordered\"\nTARGET=\"/sys/kernel/security\" SOURCE=\"securityfs\" FSTYPE=\"securityfs\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/dev/shm\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,nodev\"\nTARGET=\"/run/lock\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,size=5120k\"\nTARGET=\"/sys/fs/cgroup\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"ro,nosuid,nodev,noexec,mode=755\"\nTARGET=\"/sys/fs/cgroup/systemd\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd\"\nTARGET=\"/sys/fs/pstore\" SOURCE=\"pstore\" FSTYPE=\"pstore\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime\"\nTARGET=\"/sys/fs/cgroup/net_cls,net_prio\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,net_cls,net_prio\"\nTARGET=\"/sys/fs/cgroup/perf_event\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,perf_event\"\nTARGET=\"/sys/fs/cgroup/cpu,cpuacct\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,cpu,cpuacct\"\nTARGET=\"/sys/fs/cgroup/hugetlb\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,hugetlb\"\nTARGET=\"/sys/fs/cgroup/memory\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,memory\"\nTARGET=\"/sys/fs/cgroup/devices\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,devices\"\nTARGET=\"/sys/fs/cgroup/freezer\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,freezer\"\nTARGET=\"/sys/fs/cgroup/cpuset\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,cpuset\"\nTARGET=\"/sys/fs/cgroup/blkio\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,blkio\"\nTARGET=\"/sys/fs/cgroup/pids\" SOURCE=\"cgroup\" FSTYPE=\"cgroup\" OPTIONS=\"rw,nosuid,nodev,noexec,relatime,pids\"\nTARGET=\"/proc/sys/fs/binfmt_misc\" SOURCE=\"systemd-1\" FSTYPE=\"autofs\" OPTIONS=\"rw,relatime,fd=26,pgrp=1,timeout=0,minproto=5,maxproto=5,direct\"\nTARGET=\"/sys/kernel/debug\" SOURCE=\"debugfs\" FSTYPE=\"debugfs\" OPTIONS=\"rw,relatime\"\nTARGET=\"/dev/hugepages\" SOURCE=\"hugetlbfs\" FSTYPE=\"hugetlbfs\" OPTIONS=\"rw,relatime\"\nTARGET=\"/dev/mqueue\" SOURCE=\"mqueue\" FSTYPE=\"mqueue\" OPTIONS=\"rw,relatime\"\nTARGET=\"/sys/fs/fuse/connections\" SOURCE=\"fusectl\" FSTYPE=\"fusectl\" OPTIONS=\"rw,relatime\"\nTARGET=\"/var/lib/lxcfs\" SOURCE=\"lxcfs\" FSTYPE=\"fuse.lxcfs\" OPTIONS=\"rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other\"\nTARGET=\"/vagrant\" SOURCE=\"vagrant\" FSTYPE=\"vboxsf\" OPTIONS=\"rw,nodev,relatime\"\nTARGET=\"/run/user/1000\" SOURCE=\"tmpfs\" FSTYPE=\"tmpfs\" OPTIONS=\"rw,nosuid,nodev,relatime,size=101596k,mode=700,uid=1000,gid=1000\"",
            "title": "Output as key/value pairs per device"
        },
        {
            "location": "/findmnt/#output-as-json",
            "text": "$ findmnt -J\n{\n   \"filesystems\": [\n      {\"target\": \"/\", \"source\": \"/dev/sda1\", \"fstype\": \"ext4\", \"options\": \"rw,relatime,data=ordered\",\n         \"children\": [\n            {\"target\": \"/sys\", \"source\": \"sysfs\", \"fstype\": \"sysfs\", \"options\": \"rw,nosuid,nodev,noexec,relatime\",\n               \"children\": [\n                  {\"target\": \"/sys/kernel/security\", \"source\": \"securityfs\", \"fstype\": \"securityfs\", \"options\": \"rw,nosuid,nodev,noexec,relatime\"},\n                  {\"target\": \"/sys/fs/cgroup\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"ro,nosuid,nodev,noexec,mode=755\",\n                     \"children\": [\n                        {\"target\": \"/sys/fs/cgroup/systemd\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd\"},\n                        {\"target\": \"/sys/fs/cgroup/net_cls,net_prio\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,net_cls,net_prio\"},\n                        {\"target\": \"/sys/fs/cgroup/perf_event\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,perf_event\"},\n                        {\"target\": \"/sys/fs/cgroup/cpu,cpuacct\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,cpu,cpuacct\"},\n                        {\"target\": \"/sys/fs/cgroup/hugetlb\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,hugetlb\"},\n                        {\"target\": \"/sys/fs/cgroup/memory\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,memory\"},\n                        {\"target\": \"/sys/fs/cgroup/devices\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,devices\"},\n                        {\"target\": \"/sys/fs/cgroup/freezer\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,freezer\"},\n                        {\"target\": \"/sys/fs/cgroup/cpuset\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,cpuset\"},\n                        {\"target\": \"/sys/fs/cgroup/blkio\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,blkio\"},\n                        {\"target\": \"/sys/fs/cgroup/pids\", \"source\": \"cgroup\", \"fstype\": \"cgroup\", \"options\": \"rw,nosuid,nodev,noexec,relatime,pids\"}\n                     ]\n                  },\n                  {\"target\": \"/sys/fs/pstore\", \"source\": \"pstore\", \"fstype\": \"pstore\", \"options\": \"rw,nosuid,nodev,noexec,relatime\"},\n                  {\"target\": \"/sys/kernel/debug\", \"source\": \"debugfs\", \"fstype\": \"debugfs\", \"options\": \"rw,relatime\"},\n                  {\"target\": \"/sys/fs/fuse/connections\", \"source\": \"fusectl\", \"fstype\": \"fusectl\", \"options\": \"rw,relatime\"}\n               ]\n            },\n            {\"target\": \"/proc\", \"source\": \"proc\", \"fstype\": \"proc\", \"options\": \"rw,nosuid,nodev,noexec,relatime\",\n               \"children\": [\n                  {\"target\": \"/proc/sys/fs/binfmt_misc\", \"source\": \"systemd-1\", \"fstype\": \"autofs\", \"options\": \"rw,relatime,fd=26,pgrp=1,timeout=0,minproto=5,maxproto=5,direct\"}\n               ]\n            },\n            {\"target\": \"/dev\", \"source\": \"udev\", \"fstype\": \"devtmpfs\", \"options\": \"rw,nosuid,relatime,size=500888k,nr_inodes=125222,mode=755\",\n               \"children\": [\n                  {\"target\": \"/dev/pts\", \"source\": \"devpts\", \"fstype\": \"devpts\", \"options\": \"rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\"},\n                  {\"target\": \"/dev/shm\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,nodev\"},\n                  {\"target\": \"/dev/hugepages\", \"source\": \"hugetlbfs\", \"fstype\": \"hugetlbfs\", \"options\": \"rw,relatime\"},\n                  {\"target\": \"/dev/mqueue\", \"source\": \"mqueue\", \"fstype\": \"mqueue\", \"options\": \"rw,relatime\"}\n               ]\n            },\n            {\"target\": \"/run\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,noexec,relatime,size=101596k,mode=755\",\n               \"children\": [\n                  {\"target\": \"/run/lock\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,nodev,noexec,relatime,size=5120k\"},\n                  {\"target\": \"/run/user/1000\", \"source\": \"tmpfs\", \"fstype\": \"tmpfs\", \"options\": \"rw,nosuid,nodev,relatime,size=101596k,mode=700,uid=1000,gid=1000\"}\n               ]\n            },\n            {\"target\": \"/var/lib/lxcfs\", \"source\": \"lxcfs\", \"fstype\": \"fuse.lxcfs\", \"options\": \"rw,nosuid,nodev,relatime,user_id=0,group_id=0,allow_other\"},\n            {\"target\": \"/vagrant\", \"source\": \"vagrant\", \"fstype\": \"vboxsf\", \"options\": \"rw,nodev,relatime\"},\n         ]\n      }\n   ]\n}",
            "title": "Output as JSON"
        },
        {
            "location": "/findmnt/#see-also",
            "text": "lsblk",
            "title": "See also"
        },
        {
            "location": "/flask/",
            "text": "\"Flask is a microframework for Python based on Werkzeug, Jinja 2 and good intentions.\" - \nhttp://flask.pocoo.org/\n\n\n\n\nhttps://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world",
            "title": "Flask"
        },
        {
            "location": "/fortune/",
            "text": "fortune is a unix command that displays a random fortune on the CLI.\n\n\nMake a fortune file\n\n\n\n\nCreate a file that has each fortune separated by a line containing only a \n%\n symbol.\n\n\nRun \nstrfile fortunes.txt\n, which will create \nfortunes.txt.dat\n\n\nYou can then see the fortunes with \nfortune fortunes.txt\n. This also works with many files in a single directory: \nfor file in *.txt ; do strfile \"${file}\" ; done ; fortune .",
            "title": "Fortune"
        },
        {
            "location": "/fortune/#make-a-fortune-file",
            "text": "Create a file that has each fortune separated by a line containing only a  %  symbol.  Run  strfile fortunes.txt , which will create  fortunes.txt.dat  You can then see the fortunes with  fortune fortunes.txt . This also works with many files in a single directory:  for file in *.txt ; do strfile \"${file}\" ; done ; fortune .",
            "title": "Make a fortune file"
        },
        {
            "location": "/genicam/",
            "text": "\"The Generic Interface for Cameras standard is the base for plug & play handling of cameras and devices.\" - \nhttp://www.emva.org/standards-technology/genicam/",
            "title": "Genicam"
        },
        {
            "location": "/geodata/",
            "text": "http://geojson.org\n\n\nhttps://tools.ietf.org/html/rfc7946\n\n\nhttps://www.gpsbabel.org",
            "title": "Geodata"
        },
        {
            "location": "/git/",
            "text": "baddass version control\n\n\nLinks\n\n\n\n\nhttp://gitref.org/\n\n\nhttp://repo.or.cz/w/git.git/blob/HEAD:/contrib/completion/git-completion.bash\n\n\nhttp://git-scm.com/book/en/Getting-Started-Git-Basics\n\n\nhttp://git-scm.com/book/en/Git-on-the-Server-Setting-Up-the-Server\n\n\nhttp://scottchacon.com/2011/08/31/github-flow.html\n\n\nhttps://guides.github.com/introduction/flow/index.html\n\n\nhttp://nvie.com/posts/a-successful-git-branching-model/\n\n\nhttps://training.github.com/kit/intermediate/\n - Training\n\n\nhttps://github.com/git/git/tree/master/Documentation/RelNotes\n - Release Notes\n\n\n\n\nExamples\n\n\ngit init\n\n\nCreate a git repository for the CWD\n\n\ngit init\necho \"\" >> .gitignore\necho \"# Ignore other unneeded files.\n*.swp\n*~\n.DS_Store\" >> .gitignore\n\n\n\n\ngit clone\n\n\nClone a local repo\n\n\ngit clone /path/to/repo\n\n\n\n\nClone a remote git repo via ssh\n\n\ngit clone user@ssh_server:/opt/git/project\n\n\n\n\ngit filesystem operations\n\n\nAdd everything in the CWD to the git repo\n\n\ngit add .\n\n\n\n\nRename a file in the git repo\n\n\nThis also renames the filesystem file.\n\n\ngit mv README.rdoc README.md\n\n\n\n\nDelete a file from the repo\n\n\ngit rm filename\n\n\n\n\ngit status\n\n\nCheck the status of git\n\n\ngit status\n\n\n\n\ngit commit\n\n\nCommit the current changes\n\n\ngit commit -m \"Initial commit\"\n\n\n\n\nCommit all changes with commit -a\n\n\ngit commit -a -m \"Improve the README file\"\n\n\n\n\nSkip git commit hooks\n\n\ngit commit --no-verify\n\n\n\n\ngit config\n\n\ngit config\n interacts with configs. There are three scopes: --local, --global, --system.\n\n\n\n\nLocal = per-repo settings. IE: stored in .git/config directory for the repo\n\n\nGlobal = per-user settings. IE: stored in ~/.gitconfig\n\n\nSystem = per-system settings, found in /etc/ or wherever git is looking for system settings.\n\n\n\n\nGit client setup\n\n\nThis creates and modifies ~/.gitconfig with some parameters:\n\n\ngit config --global user.name \"Daniel Hoherd\"\ngit config --global user.email daniel.hoherd@gmail.com\ngit config --global alias.co checkout\ngit config --global core.editor \"vim\"\ngit config --global merge.tool vimdiff\ngit config --global log.date iso\n\n\n\n\nEdit a .git/config file with some params\n\n\ngit config --replace-all svn-remote.svn.url https://svn.example.com/ops/\ngit config --replace-all svn-remote.svn.fetch ops:refs/remotes/trunk\ngit config --add svn-remote.svn.preserve-empty-dirs true\ngit config --unset svn-remote.svn.branches\ngit config --unset svn-remote.svn.tags\ngit config --add svn.authorsfile /srv-cluster/git-svn/git/author.txt\n\n\n\n\nExport your .gitconfig in a git config friendly format\n\n\ngit config --list\n\n\n\n\ngit diff\n\n\nShow differences between objects and stuff.\n\n\ndiff between staged and committed\n\n\nThis is useful when you're adding files that were not previously in the repo alongside changes to existing files, since a bare \ngit diff\n before adding the files will only show changes to files that were already in the repo.\n\n\ngit diff --staged\n\n\n\n\ndiff that shows per-word colored differences\n\n\ngit diff --color-words\n\n\n\n\nMachine readable word diff\n\n\ngit diff --word-diff\n\n\n\n\nDiff and ignore whitespace\n\n\nThis does not ignore line ending changes or blank line insertion and removals.\n\n\ngit diff -w\n\n\n\n\nShow diffs between master and a given date\n\n\ngit diff $(git rev-list -n1 --before=\"1 month ago\" master)\n\n\n\n\nShow what has changed since a point in time\n\n\ngit whatchanged --since=\"18 hours ago\" -p\n\n\n\n\nor...\n\n\ngit whatchanged --since=\"18 hours ago\" --until=\"6 hours ago\" -p\n\n\n\n\ngit blame\n\n\ngit blame\n shows information about the commit associated with each line of a file.\n\n\nSimple usage\n\n\ngit blame <filename>\n\n\n\n\nShow non-whitespace changes in blame\n\n\nWhen somebody has reformatted code but didn't make any code changes, this will show the prior commits where something more than whitespace changed.\n\n\ngit blame -w <filename>\n\n\n\n\ngit log\n\n\nShows commit history.\n\n\nView the commit history\n\n\ngit log\n\n\n\n\nShow one log entry\n\n\ngit log -1\n\n\n\n\nShow git commits that contain a given string\n\n\nThis searches the content of the diff, not the commit message.\n\n\ngit log -S search_string\n\n\n\n\nShow commit messages that match a given regex\n\n\ngit log --grep='[Ww]hitespace'\n\n\n\n\nShow logs for a given dir in the last 3 days\n\n\ngit log --since=3.days modules/profile_sensu\n\n\n\n\nShow raw log history for 5 most recent commits\n\n\nUseful for seeing TZ settings.\n\n\ngit log --format=raw -5\n\n\n\n\nReally pretty logs\n\n\nlog --graph --oneline --decorate --all\n\n\n\n\ngit show\n\n\nShow the changes from a specific sha\n\n\ngit show f73f9ec7c07e\n\n\n\n\nShow a complete file as of a given sha\n\n\nThis is an absolute path from the git root, not relative to CWD. This command will show the whole file as of the given sha.\n\n\ngit show f73f9ec7c07e:dir/filename.yaml\n\n\n\n\ngit branches\n\n\nBranches are an integral part of git. They allow you to work on distinct changes without mixing them all up together.\n\n\nCreate a branch\n\n\ngit checkout -b readme-fix\n\n\n\n\nCheck which branch you're in\n\n\ngit branch\n\n\n\n\nRename (move) a branch\n\n\ngit branch -m oldname newname\n\n\n\n\ngit merge\n\n\nThis lets you merge two branches.\n\n\nMerge branch with master\n\n\ngit checkout master\ngit merge readme-fix-branch\ngit branch -d readme-fix-branch\n\n\n\n\ndisable fast-forward merges\n\n\nYou can control how the history is kept when merging. By default, fast-forward merges occur, which replays the commits on the branch that is being merged into. By disabling this you can see several commits being merged from one branch into another, making it easier to roll back that whole series of commits without digging through the history to see where each commit from the branch came from.\n\n\ngit config --global merge.ff false\n\n\n\n\nremotes\n\n\nAdd a remote\n\n\ngit remote add upstream https://github.com/danielhoherd/homepass\n\n\n\n\nPush to a specific remote\n\n\n# push to the master branch of the remote named upstream\ngit push upstream master\n\n\n\n\nAlter the source of origin\n\n\nIf you move your repo to another location, use this command to change the upstream URL:\n\n\ngit remote set-url origin https://user@newhost/newpath/reponame\n\n\n\n\ngit reset\n\n\ngit reset\n allows you to reset your state to what it was at a previous point.\n\n\nReset to a prior state based on what has been done locally\n\n\nThe reflog is a log of what steps have been performed locally. You can view the reflog, then reset to a prior state.\n\n\ngit reflog # show all HEAD changes\ngit reset --hard 45e0ae5 # reset all git tracked state to 45e0ae5\n\n\n\n\nAlternately, you can use a date:\n\n\ngit reflog --date=iso # absolute date based reflog references\ngit reset \"HEAD@{2015-03-25 14:45:30 -0700}\" --hard\n\n\n\n\nHard reset of local changes\n\n\nThis will abandon all local changes and resolve merge conflicts\n\n\ngit fetch origin\ngit reset --hard origin/master\n\n\n\n\ngit clean\n\n\nRemove all untracked files and directories\n\n\nThis is useful after your reset to a prior state. It deletes all files and directories that show up in the untracked section of \ngit status\n\n\ngit clean -ffdx\n\n\n\n\nMisc tricks\n\n\nRefresh all Git repos in a path\n\n\nfind /var/www/html/mediawiki/ -name .git | while read -r X ; do\n  pushd \"$(dirname \"${X}\")\" && \\\n  [ $(git remote -v | wc -l) -gt 0 ] && \\\n  git pull && \\\n  popd ;\ndone ;\n\n\n\n\nShow a numbered list of remote branches sorted by last commit date\n\n\ngit branch -r | grep -v HEAD | xargs -r -n1 git log -1 \\\n--pretty=format:'%ad %h%d %an | %s %n' --date=iso -1 | sort | nl -ba\n\n\n\n\nBranch cleanup\n\n\ngit gc --prune=now\ngit remote prune origin",
            "title": "Git"
        },
        {
            "location": "/git/#links",
            "text": "http://gitref.org/  http://repo.or.cz/w/git.git/blob/HEAD:/contrib/completion/git-completion.bash  http://git-scm.com/book/en/Getting-Started-Git-Basics  http://git-scm.com/book/en/Git-on-the-Server-Setting-Up-the-Server  http://scottchacon.com/2011/08/31/github-flow.html  https://guides.github.com/introduction/flow/index.html  http://nvie.com/posts/a-successful-git-branching-model/  https://training.github.com/kit/intermediate/  - Training  https://github.com/git/git/tree/master/Documentation/RelNotes  - Release Notes",
            "title": "Links"
        },
        {
            "location": "/git/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/git/#git-init",
            "text": "",
            "title": "git init"
        },
        {
            "location": "/git/#create-a-git-repository-for-the-cwd",
            "text": "git init\necho \"\" >> .gitignore\necho \"# Ignore other unneeded files.\n*.swp\n*~\n.DS_Store\" >> .gitignore",
            "title": "Create a git repository for the CWD"
        },
        {
            "location": "/git/#git-clone",
            "text": "",
            "title": "git clone"
        },
        {
            "location": "/git/#clone-a-local-repo",
            "text": "git clone /path/to/repo",
            "title": "Clone a local repo"
        },
        {
            "location": "/git/#clone-a-remote-git-repo-via-ssh",
            "text": "git clone user@ssh_server:/opt/git/project",
            "title": "Clone a remote git repo via ssh"
        },
        {
            "location": "/git/#git-filesystem-operations",
            "text": "",
            "title": "git filesystem operations"
        },
        {
            "location": "/git/#add-everything-in-the-cwd-to-the-git-repo",
            "text": "git add .",
            "title": "Add everything in the CWD to the git repo"
        },
        {
            "location": "/git/#rename-a-file-in-the-git-repo",
            "text": "This also renames the filesystem file.  git mv README.rdoc README.md",
            "title": "Rename a file in the git repo"
        },
        {
            "location": "/git/#delete-a-file-from-the-repo",
            "text": "git rm filename",
            "title": "Delete a file from the repo"
        },
        {
            "location": "/git/#git-status",
            "text": "",
            "title": "git status"
        },
        {
            "location": "/git/#check-the-status-of-git",
            "text": "git status",
            "title": "Check the status of git"
        },
        {
            "location": "/git/#git-commit",
            "text": "",
            "title": "git commit"
        },
        {
            "location": "/git/#commit-the-current-changes",
            "text": "git commit -m \"Initial commit\"",
            "title": "Commit the current changes"
        },
        {
            "location": "/git/#commit-all-changes-with-commit-a",
            "text": "git commit -a -m \"Improve the README file\"",
            "title": "Commit all changes with commit -a"
        },
        {
            "location": "/git/#skip-git-commit-hooks",
            "text": "git commit --no-verify",
            "title": "Skip git commit hooks"
        },
        {
            "location": "/git/#git-config",
            "text": "git config  interacts with configs. There are three scopes: --local, --global, --system.   Local = per-repo settings. IE: stored in .git/config directory for the repo  Global = per-user settings. IE: stored in ~/.gitconfig  System = per-system settings, found in /etc/ or wherever git is looking for system settings.",
            "title": "git config"
        },
        {
            "location": "/git/#git-client-setup",
            "text": "This creates and modifies ~/.gitconfig with some parameters:  git config --global user.name \"Daniel Hoherd\"\ngit config --global user.email daniel.hoherd@gmail.com\ngit config --global alias.co checkout\ngit config --global core.editor \"vim\"\ngit config --global merge.tool vimdiff\ngit config --global log.date iso",
            "title": "Git client setup"
        },
        {
            "location": "/git/#edit-a-gitconfig-file-with-some-params",
            "text": "git config --replace-all svn-remote.svn.url https://svn.example.com/ops/\ngit config --replace-all svn-remote.svn.fetch ops:refs/remotes/trunk\ngit config --add svn-remote.svn.preserve-empty-dirs true\ngit config --unset svn-remote.svn.branches\ngit config --unset svn-remote.svn.tags\ngit config --add svn.authorsfile /srv-cluster/git-svn/git/author.txt",
            "title": "Edit a .git/config file with some params"
        },
        {
            "location": "/git/#export-your-gitconfig-in-a-git-config-friendly-format",
            "text": "git config --list",
            "title": "Export your .gitconfig in a git config friendly format"
        },
        {
            "location": "/git/#git-diff",
            "text": "Show differences between objects and stuff.",
            "title": "git diff"
        },
        {
            "location": "/git/#diff-between-staged-and-committed",
            "text": "This is useful when you're adding files that were not previously in the repo alongside changes to existing files, since a bare  git diff  before adding the files will only show changes to files that were already in the repo.  git diff --staged",
            "title": "diff between staged and committed"
        },
        {
            "location": "/git/#diff-that-shows-per-word-colored-differences",
            "text": "git diff --color-words",
            "title": "diff that shows per-word colored differences"
        },
        {
            "location": "/git/#machine-readable-word-diff",
            "text": "git diff --word-diff",
            "title": "Machine readable word diff"
        },
        {
            "location": "/git/#diff-and-ignore-whitespace",
            "text": "This does not ignore line ending changes or blank line insertion and removals.  git diff -w",
            "title": "Diff and ignore whitespace"
        },
        {
            "location": "/git/#show-diffs-between-master-and-a-given-date",
            "text": "git diff $(git rev-list -n1 --before=\"1 month ago\" master)",
            "title": "Show diffs between master and a given date"
        },
        {
            "location": "/git/#show-what-has-changed-since-a-point-in-time",
            "text": "git whatchanged --since=\"18 hours ago\" -p  or...  git whatchanged --since=\"18 hours ago\" --until=\"6 hours ago\" -p",
            "title": "Show what has changed since a point in time"
        },
        {
            "location": "/git/#git-blame",
            "text": "git blame  shows information about the commit associated with each line of a file.",
            "title": "git blame"
        },
        {
            "location": "/git/#simple-usage",
            "text": "git blame <filename>",
            "title": "Simple usage"
        },
        {
            "location": "/git/#show-non-whitespace-changes-in-blame",
            "text": "When somebody has reformatted code but didn't make any code changes, this will show the prior commits where something more than whitespace changed.  git blame -w <filename>",
            "title": "Show non-whitespace changes in blame"
        },
        {
            "location": "/git/#git-log",
            "text": "Shows commit history.",
            "title": "git log"
        },
        {
            "location": "/git/#view-the-commit-history",
            "text": "git log",
            "title": "View the commit history"
        },
        {
            "location": "/git/#show-one-log-entry",
            "text": "git log -1",
            "title": "Show one log entry"
        },
        {
            "location": "/git/#show-git-commits-that-contain-a-given-string",
            "text": "This searches the content of the diff, not the commit message.  git log -S search_string",
            "title": "Show git commits that contain a given string"
        },
        {
            "location": "/git/#show-commit-messages-that-match-a-given-regex",
            "text": "git log --grep='[Ww]hitespace'",
            "title": "Show commit messages that match a given regex"
        },
        {
            "location": "/git/#show-logs-for-a-given-dir-in-the-last-3-days",
            "text": "git log --since=3.days modules/profile_sensu",
            "title": "Show logs for a given dir in the last 3 days"
        },
        {
            "location": "/git/#show-raw-log-history-for-5-most-recent-commits",
            "text": "Useful for seeing TZ settings.  git log --format=raw -5",
            "title": "Show raw log history for 5 most recent commits"
        },
        {
            "location": "/git/#really-pretty-logs",
            "text": "log --graph --oneline --decorate --all",
            "title": "Really pretty logs"
        },
        {
            "location": "/git/#git-show",
            "text": "",
            "title": "git show"
        },
        {
            "location": "/git/#show-the-changes-from-a-specific-sha",
            "text": "git show f73f9ec7c07e",
            "title": "Show the changes from a specific sha"
        },
        {
            "location": "/git/#show-a-complete-file-as-of-a-given-sha",
            "text": "This is an absolute path from the git root, not relative to CWD. This command will show the whole file as of the given sha.  git show f73f9ec7c07e:dir/filename.yaml",
            "title": "Show a complete file as of a given sha"
        },
        {
            "location": "/git/#git-branches",
            "text": "Branches are an integral part of git. They allow you to work on distinct changes without mixing them all up together.",
            "title": "git branches"
        },
        {
            "location": "/git/#create-a-branch",
            "text": "git checkout -b readme-fix",
            "title": "Create a branch"
        },
        {
            "location": "/git/#check-which-branch-youre-in",
            "text": "git branch",
            "title": "Check which branch you're in"
        },
        {
            "location": "/git/#rename-move-a-branch",
            "text": "git branch -m oldname newname",
            "title": "Rename (move) a branch"
        },
        {
            "location": "/git/#git-merge",
            "text": "This lets you merge two branches.",
            "title": "git merge"
        },
        {
            "location": "/git/#merge-branch-with-master",
            "text": "git checkout master\ngit merge readme-fix-branch\ngit branch -d readme-fix-branch",
            "title": "Merge branch with master"
        },
        {
            "location": "/git/#disable-fast-forward-merges",
            "text": "You can control how the history is kept when merging. By default, fast-forward merges occur, which replays the commits on the branch that is being merged into. By disabling this you can see several commits being merged from one branch into another, making it easier to roll back that whole series of commits without digging through the history to see where each commit from the branch came from.  git config --global merge.ff false",
            "title": "disable fast-forward merges"
        },
        {
            "location": "/git/#remotes",
            "text": "",
            "title": "remotes"
        },
        {
            "location": "/git/#add-a-remote",
            "text": "git remote add upstream https://github.com/danielhoherd/homepass",
            "title": "Add a remote"
        },
        {
            "location": "/git/#push-to-a-specific-remote",
            "text": "# push to the master branch of the remote named upstream\ngit push upstream master",
            "title": "Push to a specific remote"
        },
        {
            "location": "/git/#alter-the-source-of-origin",
            "text": "If you move your repo to another location, use this command to change the upstream URL:  git remote set-url origin https://user@newhost/newpath/reponame",
            "title": "Alter the source of origin"
        },
        {
            "location": "/git/#git-reset",
            "text": "git reset  allows you to reset your state to what it was at a previous point.",
            "title": "git reset"
        },
        {
            "location": "/git/#reset-to-a-prior-state-based-on-what-has-been-done-locally",
            "text": "The reflog is a log of what steps have been performed locally. You can view the reflog, then reset to a prior state.  git reflog # show all HEAD changes\ngit reset --hard 45e0ae5 # reset all git tracked state to 45e0ae5  Alternately, you can use a date:  git reflog --date=iso # absolute date based reflog references\ngit reset \"HEAD@{2015-03-25 14:45:30 -0700}\" --hard",
            "title": "Reset to a prior state based on what has been done locally"
        },
        {
            "location": "/git/#hard-reset-of-local-changes",
            "text": "This will abandon all local changes and resolve merge conflicts  git fetch origin\ngit reset --hard origin/master",
            "title": "Hard reset of local changes"
        },
        {
            "location": "/git/#git-clean",
            "text": "",
            "title": "git clean"
        },
        {
            "location": "/git/#remove-all-untracked-files-and-directories",
            "text": "This is useful after your reset to a prior state. It deletes all files and directories that show up in the untracked section of  git status  git clean -ffdx",
            "title": "Remove all untracked files and directories"
        },
        {
            "location": "/git/#misc-tricks",
            "text": "",
            "title": "Misc tricks"
        },
        {
            "location": "/git/#refresh-all-git-repos-in-a-path",
            "text": "find /var/www/html/mediawiki/ -name .git | while read -r X ; do\n  pushd \"$(dirname \"${X}\")\" && \\\n  [ $(git remote -v | wc -l) -gt 0 ] && \\\n  git pull && \\\n  popd ;\ndone ;",
            "title": "Refresh all Git repos in a path"
        },
        {
            "location": "/git/#show-a-numbered-list-of-remote-branches-sorted-by-last-commit-date",
            "text": "git branch -r | grep -v HEAD | xargs -r -n1 git log -1 \\\n--pretty=format:'%ad %h%d %an | %s %n' --date=iso -1 | sort | nl -ba",
            "title": "Show a numbered list of remote branches sorted by last commit date"
        },
        {
            "location": "/git/#branch-cleanup",
            "text": "git gc --prune=now\ngit remote prune origin",
            "title": "Branch cleanup"
        },
        {
            "location": "/gitolite/",
            "text": "\"Gitolite allows you to setup git hosting on a central server, with fine-grained access control and many more powerful features.\" - \nhttp://gitolite.com\n\n\nExamples\n\n\nGet info about available repositories\n\n\nssh git@gitserver info",
            "title": "Gitolite"
        },
        {
            "location": "/gitolite/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/gitolite/#get-info-about-available-repositories",
            "text": "ssh git@gitserver info",
            "title": "Get info about available repositories"
        },
        {
            "location": "/glances/",
            "text": "\"Glances is a cross-platform system monitoring tool written in Python.\" - \nhttps://nicolargo.github.io/glances/\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Glances"
        },
        {
            "location": "/glances/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/golang/",
            "text": "\"Go is an open source programming language that makes it easy to build simple, reliable, and efficient software.\" - \nhttps://golang.org/\n\n\nLinks\n\n\n\n\nhttp://www.golangbootcamp.com/book/intro",
            "title": "Golang"
        },
        {
            "location": "/golang/#links",
            "text": "http://www.golangbootcamp.com/book/intro",
            "title": "Links"
        },
        {
            "location": "/google-cloud/",
            "text": "\"Google Cloud SDK is a set of tools that you can use to manage resources and applications hosted on Google Cloud Platform. These include the gcloud, gsutil, and bq command line tools. The gcloud command-line tool is downloaded along with the Cloud SDK\" - \nhttps://cloud.google.com/sdk/docs/\n\n\nLinks\n\n\n\n\nhttps://cloud.google.com/container-registry/docs/quickstart\n\n\n\n\nExamples\n\n\n\n\ngcloud container images list\n\n\ngcloud docker -- pull gcr.io/project-id/hello-world",
            "title": "Google cloud"
        },
        {
            "location": "/google-cloud/#links",
            "text": "https://cloud.google.com/container-registry/docs/quickstart",
            "title": "Links"
        },
        {
            "location": "/google-cloud/#examples",
            "text": "gcloud container images list  gcloud docker -- pull gcr.io/project-id/hello-world",
            "title": "Examples"
        },
        {
            "location": "/google-earth/",
            "text": "\"Google Earth is a computer program that renders a 3D representation of Earth based on satellite imagery. The program maps the Earth by superimposing satellite images, aerial photography, and GIS data onto a 3D globe, allowing users to see cities and landscapes from various angles.\" - \nhttps://en.wikipedia.org/wiki/Google_Earth\n\n\nLinks\n\n\n\n\nsimplekml\n - \"The python package simplekml was created to generate kml (or kmz). It was designed to alleviate the burden of having to study KML in order to achieve anything worthwhile with it. If you have a simple understanding of the structure of KML, then simplekml is easy to run with and create usable KML.\"\n\n\nhttps://doarama.com",
            "title": "Google earth"
        },
        {
            "location": "/google-earth/#links",
            "text": "simplekml  - \"The python package simplekml was created to generate kml (or kmz). It was designed to alleviate the burden of having to study KML in order to achieve anything worthwhile with it. If you have a simple understanding of the structure of KML, then simplekml is easy to run with and create usable KML.\"  https://doarama.com",
            "title": "Links"
        },
        {
            "location": "/google-sheets/",
            "text": "Links\n\n\n\n\ngspread\n - Python module for interacting with google spreadsheets\n\n\n\n\nTechniques\n\n\n\n\nFunction list - \nhttps://support.google.com/docs/table/25273?hl=en\n\n\n\n\nConditional Formatting\n\n\nRegex matching to color\n\n\nColorize rows with conditional formatting by using an expression like this:\n\n\n=REGEXMATCH($E:$E, \"some_regex\")\n\n\n\n\nThis regex is not anchored, so there is no need to prepend or append \n.*\n\n\nCell references in this case are relative unless prepended by a \n\\$\n. So, if you want to match the cell you are working on you would use \nA1:A1\n.\n\n\nColor every other row\n\n\n=MOD(ROW(),2)\n\n\n\n\nImport an RSS feed\n\n\n=IMPORTFEED(\"https://api.flickr.com/services/feeds/photos_public.gne\", B2, TRUE, 10)\n\n\n\n\nSum lines that match a string\n\n\nThis uses syntax similar to a glob search, but uses ~ instead of \\\n\n\n=COUNTIF(D:D,\"3*\")\n\n\n\n\nAutomatically resolve the DOW from a date\n\n\n=CHOOSE( weekday(A4), \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")",
            "title": "Links"
        },
        {
            "location": "/google-sheets/#links",
            "text": "gspread  - Python module for interacting with google spreadsheets",
            "title": "Links"
        },
        {
            "location": "/google-sheets/#techniques",
            "text": "Function list -  https://support.google.com/docs/table/25273?hl=en",
            "title": "Techniques"
        },
        {
            "location": "/google-sheets/#conditional-formatting",
            "text": "",
            "title": "Conditional Formatting"
        },
        {
            "location": "/google-sheets/#regex-matching-to-color",
            "text": "Colorize rows with conditional formatting by using an expression like this:  =REGEXMATCH($E:$E, \"some_regex\")  This regex is not anchored, so there is no need to prepend or append  .*  Cell references in this case are relative unless prepended by a  \\$ . So, if you want to match the cell you are working on you would use  A1:A1 .",
            "title": "Regex matching to color"
        },
        {
            "location": "/google-sheets/#color-every-other-row",
            "text": "=MOD(ROW(),2)",
            "title": "Color every other row"
        },
        {
            "location": "/google-sheets/#import-an-rss-feed",
            "text": "=IMPORTFEED(\"https://api.flickr.com/services/feeds/photos_public.gne\", B2, TRUE, 10)",
            "title": "Import an RSS feed"
        },
        {
            "location": "/google-sheets/#sum-lines-that-match-a-string",
            "text": "This uses syntax similar to a glob search, but uses ~ instead of \\  =COUNTIF(D:D,\"3*\")",
            "title": "Sum lines that match a string"
        },
        {
            "location": "/google-sheets/#automatically-resolve-the-dow-from-a-date",
            "text": "=CHOOSE( weekday(A4), \"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\")",
            "title": "Automatically resolve the DOW from a date"
        },
        {
            "location": "/google/",
            "text": "\"Google LLC is an American multinational technology company that specializes in Internet-related services and products.\" - \nhttps://en.wikipedia.org/wiki/Google\n\n\nLinks\n\n\n\n\nGoogle App Script\n\n\nExtending Google Docs\n\n\nDocument Service\n\n\nWeb Store Developer Dashboard\n\n\nService Accounts\n\n\nAPI Explorer",
            "title": "Google"
        },
        {
            "location": "/google/#links",
            "text": "Google App Script  Extending Google Docs  Document Service  Web Store Developer Dashboard  Service Accounts  API Explorer",
            "title": "Links"
        },
        {
            "location": "/graphicsmagick/",
            "text": "GraphicsMagick\n\n\n\"GraphicsMagick is the swiss army knife of image processing.\" - \nhttp://www.graphicsmagick.org/\n\n\nThis software purports to be more favorable than \nImageMagick\n.\n\n\nSee Also\n\n\n\n\nexiftool\n\n\nimagemagick\n\n\njpeginfo\n\n\nsips",
            "title": "GraphicsMagick"
        },
        {
            "location": "/graphicsmagick/#graphicsmagick",
            "text": "\"GraphicsMagick is the swiss army knife of image processing.\" -  http://www.graphicsmagick.org/  This software purports to be more favorable than  ImageMagick .",
            "title": "GraphicsMagick"
        },
        {
            "location": "/graphicsmagick/#see-also",
            "text": "exiftool  imagemagick  jpeginfo  sips",
            "title": "See Also"
        },
        {
            "location": "/grub/",
            "text": "\"GNU GRUB is a Multiboot boot loader. It was derived from GRUB, the GRand Unified Bootloader, which was originally designed and implemented by Erich Stefan Boleyn.\" - \nhttps://www.gnu.org/software/grub/\n\n\nExamples\n\n\nDisable onboard frame buffer\n\n\nI used this configuration to get text mode linux to boot on a Mac Mini with a bad graphics card that would not load a desktop environment. The machine was locking up at boot in OS X. Hardware test would boot with a striped color anomalies, but would never finish. Ubuntu Xenial would not boot correctly even to text mode without these settings.\n\n\nIn \n/etc/default/grub\n:\n\n\nGRUB_CMDLINE_LINUX_DEFAULT=\"video=vesafb:off nofb vga=normal nomodeset\"\n\n\n\n\nNotable commands, files and dirs\n\n\n\n\n/boot/grub/grub.cfg\n - The grub config that is actually used at boot\n\n\n/etc/grub.d\n - A directory with some of the configs that are combined to create /boot/grub/grub.cfg\n\n\n/etc/default/grub\n - Default grub options\n\n\nupdate-grub\n - Used to regenerate \n/boot/grub/grub.cfg\n\n\ngrub-set-default\n - Used to configure the default menu entry during reboot, only for bare metal machines\n\n\ngrub-set-default-legacy-ec2\n - Used to configure the default menu entry on ec2 machines grub-set-default-legacy-ec2",
            "title": "Grub"
        },
        {
            "location": "/grub/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/grub/#disable-onboard-frame-buffer",
            "text": "I used this configuration to get text mode linux to boot on a Mac Mini with a bad graphics card that would not load a desktop environment. The machine was locking up at boot in OS X. Hardware test would boot with a striped color anomalies, but would never finish. Ubuntu Xenial would not boot correctly even to text mode without these settings.  In  /etc/default/grub :  GRUB_CMDLINE_LINUX_DEFAULT=\"video=vesafb:off nofb vga=normal nomodeset\"",
            "title": "Disable onboard frame buffer"
        },
        {
            "location": "/grub/#notable-commands-files-and-dirs",
            "text": "/boot/grub/grub.cfg  - The grub config that is actually used at boot  /etc/grub.d  - A directory with some of the configs that are combined to create /boot/grub/grub.cfg  /etc/default/grub  - Default grub options  update-grub  - Used to regenerate  /boot/grub/grub.cfg  grub-set-default  - Used to configure the default menu entry during reboot, only for bare metal machines  grub-set-default-legacy-ec2  - Used to configure the default menu entry on ec2 machines grub-set-default-legacy-ec2",
            "title": "Notable commands, files and dirs"
        },
        {
            "location": "/hadoop/",
            "text": "\"The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models.\" - \nhttp://hadoop.apache.org/\n\n\nLinks\n\n\n\n\nOozie\n - Oozie is a workflow scheduler system to manage Apache Hadoop jobs.",
            "title": "Hadoop"
        },
        {
            "location": "/hadoop/#links",
            "text": "Oozie  - Oozie is a workflow scheduler system to manage Apache Hadoop jobs.",
            "title": "Links"
        },
        {
            "location": "/handbrake/",
            "text": "Handbrake\n is a tool for ripping DVD's into MPEG or AVI files.\n\n\nCLI Examples\n\n\n\n\nhttps://trac.handbrake.fr/wiki/CLIGuide\n\n\n\n\nDeinterlacing for iPad\n\n\nHandbrakeCLI -Z \"AppleTV\" --deinterlace fast --maxWidth 1024 -i infile -o outfile\n\n\n\n\nShow information about the source media for use with extended flags\n\n\nHandBrakeCLI -t 0 -i VIDEO_TS\n\n\n\n\nGenerate a 1000 frame preview of the AppleTV preset\n\n\n--stop-at\n is relative to the start, so it describes the number of frames in the output.\n\n\nHandBrakeCLI -i 2046/VIDEO_TS/ --start-at frame:5000 --stop-at frame:1000 -o foo.mp4 -Z AppleTV\n\n\n\n\nFix 4:3 aspect ratio with the expanded syntax of the AppleTV preset\n\n\nHandBrakeCLI \\\n-e x264 \\\n-q 20.0 \\\n-a 1,1 \\\n-E faac,ac3 \\\n-B 160,160 \\\n-6 dpl2,auto \\\n-R 48,Auto -D 0.0,0.0 \\\n-f mp4 \\\n-4 \\\n-X 960 \\\n--loose-anamorphic \\\n-m \\\n-x cabac=0:ref=2:me=umh:b-adapt=2:weightb=0:trellis=0:weightp=0 \\\n--custom-anamorphic \\\n--pixel-aspect 4:3",
            "title": "Handbrake"
        },
        {
            "location": "/handbrake/#cli-examples",
            "text": "https://trac.handbrake.fr/wiki/CLIGuide",
            "title": "CLI Examples"
        },
        {
            "location": "/handbrake/#deinterlacing-for-ipad",
            "text": "HandbrakeCLI -Z \"AppleTV\" --deinterlace fast --maxWidth 1024 -i infile -o outfile",
            "title": "Deinterlacing for iPad"
        },
        {
            "location": "/handbrake/#show-information-about-the-source-media-for-use-with-extended-flags",
            "text": "HandBrakeCLI -t 0 -i VIDEO_TS",
            "title": "Show information about the source media for use with extended flags"
        },
        {
            "location": "/handbrake/#generate-a-1000-frame-preview-of-the-appletv-preset",
            "text": "--stop-at  is relative to the start, so it describes the number of frames in the output.  HandBrakeCLI -i 2046/VIDEO_TS/ --start-at frame:5000 --stop-at frame:1000 -o foo.mp4 -Z AppleTV",
            "title": "Generate a 1000 frame preview of the AppleTV preset"
        },
        {
            "location": "/handbrake/#fix-43-aspect-ratio-with-the-expanded-syntax-of-the-appletv-preset",
            "text": "HandBrakeCLI \\\n-e x264 \\\n-q 20.0 \\\n-a 1,1 \\\n-E faac,ac3 \\\n-B 160,160 \\\n-6 dpl2,auto \\\n-R 48,Auto -D 0.0,0.0 \\\n-f mp4 \\\n-4 \\\n-X 960 \\\n--loose-anamorphic \\\n-m \\\n-x cabac=0:ref=2:me=umh:b-adapt=2:weightb=0:trellis=0:weightp=0 \\\n--custom-anamorphic \\\n--pixel-aspect 4:3",
            "title": "Fix 4:3 aspect ratio with the expanded syntax of the AppleTV preset"
        },
        {
            "location": "/helm/",
            "text": "\"The Kubernetes Package Manager\" - \nhttps://github.com/kubernetes/helm\n\n\nTips\n\n\nShow notes for a deployed service\n\n\nNotes are printed when you install a service, but they can be viewed again by running \nhelm status <release_name>\n where \n is one of the releases from \nhelm list\n.",
            "title": "Helm"
        },
        {
            "location": "/helm/#tips",
            "text": "",
            "title": "Tips"
        },
        {
            "location": "/helm/#show-notes-for-a-deployed-service",
            "text": "Notes are printed when you install a service, but they can be viewed again by running  helm status <release_name>  where   is one of the releases from  helm list .",
            "title": "Show notes for a deployed service"
        },
        {
            "location": "/home-assistant/",
            "text": "\"Home Assistant is an open-source home automation platform running on Python 3. Track and control all devices at home and automate control.\" - \nhttps://home-assistant.io/\n\n\n\"Hass.io turns your Raspberry Pi (or another device) into the ultimate home automation hub powered by Home Assistant. With Hass.io you can focus on integrating your devices and writing automations.\" - \nhttps://home-assistant.io/hassio/",
            "title": "Home assistant"
        },
        {
            "location": "/hp/",
            "text": "Links\n\n\n\n\nhttp://cciss.sourceforge.net\n - RAID software for linux\n\n\niLO firmware upgrade is done from in linux using CP012567.scexe\n\n\nProcurve\n ethernet switches\n\n\nMicroserver N40L or N54L for \nzfs\n or \nFreeNAS\n\n\nCustom Microserver BIOS: \nhttp://www.avforums.com/forums/networking-nas/1521657-hp-n36l-n40l-n54l-microserver-updated-ahci-bios-support.html",
            "title": "Links"
        },
        {
            "location": "/hp/#links",
            "text": "http://cciss.sourceforge.net  - RAID software for linux  iLO firmware upgrade is done from in linux using CP012567.scexe  Procurve  ethernet switches  Microserver N40L or N54L for  zfs  or  FreeNAS  Custom Microserver BIOS:  http://www.avforums.com/forums/networking-nas/1521657-hp-n36l-n40l-n54l-microserver-updated-ahci-bios-support.html",
            "title": "Links"
        },
        {
            "location": "/htop/",
            "text": "\"an interactive process viewer for Unix systems.\" - \nhttp://hisham.hm/htop/\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Htop"
        },
        {
            "location": "/htop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/httpstat/",
            "text": "\"curl statistics made simple\" - \nhttps://github.com/reorx/httpstat\n\n\nUsage\n\n\nSimple usage\n\n\n$ httpstat http://hoherd.com/\nConnected to 192.30.252.153:80 from 127.0.0.1:61646\n\nHTTP/1.1 200 OK\nServer: GitHub.com\nDate: Mon, 29 Jan 2018 23:24:52 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 405\nVary: Accept-Encoding\nVary: Accept-Encoding\nLast-Modified: Tue, 04 Apr 2017 16:43:44 GMT\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: F0D0:1973:5CF2FD:846C00:5A6FAD44\nExpires: Mon, 29 Jan 2018 23:34:52 GMT\nCache-Control: max-age=600\nAccept-Ranges: bytes\n\nBody stored in: /var/folders/2t/rnzxpxd54y7832mx_xjvxl30bb2qzp/T/tmphVaBFx\n\n  DNS Lookup   TCP Connection   Server Processing   Content Transfer\n[     5ms    |       0ms      |       237ms       |        1ms       ]\n             |                |                   |                  |\n    namelookup:5ms            |                   |                  |\n                        connect:5ms               |                  |\n                                      starttransfer:242ms            |\n                                                                 total:243ms\n\n\n\n\nSee also\n\n\n\n\ncurl\n - what httpstat wraps to get its stats",
            "title": "Httpstat"
        },
        {
            "location": "/httpstat/#usage",
            "text": "",
            "title": "Usage"
        },
        {
            "location": "/httpstat/#simple-usage",
            "text": "$ httpstat http://hoherd.com/\nConnected to 192.30.252.153:80 from 127.0.0.1:61646\n\nHTTP/1.1 200 OK\nServer: GitHub.com\nDate: Mon, 29 Jan 2018 23:24:52 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 405\nVary: Accept-Encoding\nVary: Accept-Encoding\nLast-Modified: Tue, 04 Apr 2017 16:43:44 GMT\nAccess-Control-Allow-Origin: *\nX-GitHub-Request-Id: F0D0:1973:5CF2FD:846C00:5A6FAD44\nExpires: Mon, 29 Jan 2018 23:34:52 GMT\nCache-Control: max-age=600\nAccept-Ranges: bytes\n\nBody stored in: /var/folders/2t/rnzxpxd54y7832mx_xjvxl30bb2qzp/T/tmphVaBFx\n\n  DNS Lookup   TCP Connection   Server Processing   Content Transfer\n[     5ms    |       0ms      |       237ms       |        1ms       ]\n             |                |                   |                  |\n    namelookup:5ms            |                   |                  |\n                        connect:5ms               |                  |\n                                      starttransfer:242ms            |\n                                                                 total:243ms",
            "title": "Simple usage"
        },
        {
            "location": "/httpstat/#see-also",
            "text": "curl  - what httpstat wraps to get its stats",
            "title": "See also"
        },
        {
            "location": "/iTunes/",
            "text": "https://github.com/liamks/pyitunes\n\n\n\n\nMetadata\n\n\n\n\nSkips are counted after within 2-10 seconds in iTunes, 3-10(?) seconds in iOS.",
            "title": "iTunes"
        },
        {
            "location": "/iTunes/#metadata",
            "text": "Skips are counted after within 2-10 seconds in iTunes, 3-10(?) seconds in iOS.",
            "title": "Metadata"
        },
        {
            "location": "/iftop/",
            "text": "\"display bandwidth usage on an interface\" - \nhttp://www.ex-parrot.com/pdw/iftop/\n\n\nNetwork interface top shows network usage between hosts and by port numbers, but unfortunately not by process. For that, \nsysdig\n or \niptraf\n.\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Iftop"
        },
        {
            "location": "/iftop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/image-formats/",
            "text": "arw - Sony Alpha raw format\n\n\ncr2 - Canon raw format\n\n\ndng - Adobe digital negative\n\n\ngif - Compuserve Graphics Interchange Format\n\n\njpg - Most common image format on the internet\n\n\nnef - Nikon raw format\n\n\npng - Lossless rasterized image format\n\n\ntiff - Lossless rasterized image format\n\n\nwebp - https://en.wikipedia.org/wiki/WebP",
            "title": "Image formats"
        },
        {
            "location": "/imagemagick/",
            "text": "ImageMagick\n\n\n\"ImageMagick is a free and open-source software suite for displaying, converting, and editing raster image and vector image files. It can read and write over 200 image file formats.\" - \nhttps://en.wikipedia.org/wiki/ImageMagick\n\n\nImageMagick is a framework for manipulating images. \nconvert\n is the CLI front-end for it, and there are other modules/libraries for php, perl, etc..\n\n\nLimitations\n\n\n\n\nDoes '''NOT''' handle DNG files. In OS X use \nsips\n to do this.\n\n\n\n\nTechniques\n\n\nOverlay the date on the image\n\n\nfor X in *.jpg ; do\n  convert ${X} -font Times-Roman -pointsize 70 -fill black -annotate +100+100 %[exif:DateTimeOriginal] ${X}-date.jpg\ndone\n\nfor X in *date.jpg ; do\n  convert ${X} -font Times-Roman -pointsize 70 -fill white -annotate +98+98 %[exif:DateTimeOriginal] ${X}-date2.jpg\ndone\n\n\n\n\nDelete all tags and metadata\n\n\nconvert -strip infile.jpg outfile.jpg\n\n\n\n\nGenerate blurry, dark terminal backgrounds from normal backgrounds\n\n\nfor X in * ; do\n  convert -resize 1100x1100 \"${X}\" -blur 0x4 -fill black -colorize 75% terminal.\"${X}\"\ndone\n\n\n\n\nGenerate shady versions of desktop pictures in OS X\n\n\nfor X in /Library/Desktop\\ Pictures/*.jpg ; do\n  IMG=$(basename \"${X}\")\n  convert -resize 1100x1100 \"${X}\" -blur 0x4 -set option:modulate:colorspace hsb -modulate 20 ~/Pictures/terminal.\"${IMG}\"\ndone\n\n\n\n\nCrop the center of images out\n\n\nfor X in /Volumes/data-b/Timelapse/20120407-14* ; do\n  convert \"${X}\" -gravity Center -crop 1920x1080+0+0 $(basename ${X})\ndone\n\n\n\n\nAverage many photos for a long-exposure style shot\n\n\nconvert *.jpg -average average.jpg\n\n\n\n\nMultiply several images\n\n\nconvert *.jpg -background white -compose multiply -flatten multiply.jpg\n\n\n\n\nCombine images always using the minimum value\n\n\nconvert *.jpg -background white -compose darken -flatten minimum.jpg\n\n\n\n\nCombine images always using the maximum value\n\n\nconvert *.jpg -background black -compose lighten -flatten maximum.jpg\n\n\n\n\nSwap red and blue channels (for IR photos)\n\n\nconvert infile.jpg -separate -swap 0,2 -combine swapped.jpg\n\n\n\n\nAnimate some images\n\n\nconvert -delay 20 -loop 0 *.jpg animation.gif\n\n\n\n\nSee Also\n\n\n\n\nexiftool\n\n\ngraphicsmagick\n\n\njpeginfo\n\n\nsips",
            "title": "ImageMagick"
        },
        {
            "location": "/imagemagick/#imagemagick",
            "text": "\"ImageMagick is a free and open-source software suite for displaying, converting, and editing raster image and vector image files. It can read and write over 200 image file formats.\" -  https://en.wikipedia.org/wiki/ImageMagick  ImageMagick is a framework for manipulating images.  convert  is the CLI front-end for it, and there are other modules/libraries for php, perl, etc..",
            "title": "ImageMagick"
        },
        {
            "location": "/imagemagick/#limitations",
            "text": "Does '''NOT''' handle DNG files. In OS X use  sips  to do this.",
            "title": "Limitations"
        },
        {
            "location": "/imagemagick/#techniques",
            "text": "",
            "title": "Techniques"
        },
        {
            "location": "/imagemagick/#overlay-the-date-on-the-image",
            "text": "for X in *.jpg ; do\n  convert ${X} -font Times-Roman -pointsize 70 -fill black -annotate +100+100 %[exif:DateTimeOriginal] ${X}-date.jpg\ndone\n\nfor X in *date.jpg ; do\n  convert ${X} -font Times-Roman -pointsize 70 -fill white -annotate +98+98 %[exif:DateTimeOriginal] ${X}-date2.jpg\ndone",
            "title": "Overlay the date on the image"
        },
        {
            "location": "/imagemagick/#delete-all-tags-and-metadata",
            "text": "convert -strip infile.jpg outfile.jpg",
            "title": "Delete all tags and metadata"
        },
        {
            "location": "/imagemagick/#generate-blurry-dark-terminal-backgrounds-from-normal-backgrounds",
            "text": "for X in * ; do\n  convert -resize 1100x1100 \"${X}\" -blur 0x4 -fill black -colorize 75% terminal.\"${X}\"\ndone",
            "title": "Generate blurry, dark terminal backgrounds from normal backgrounds"
        },
        {
            "location": "/imagemagick/#generate-shady-versions-of-desktop-pictures-in-os-x",
            "text": "for X in /Library/Desktop\\ Pictures/*.jpg ; do\n  IMG=$(basename \"${X}\")\n  convert -resize 1100x1100 \"${X}\" -blur 0x4 -set option:modulate:colorspace hsb -modulate 20 ~/Pictures/terminal.\"${IMG}\"\ndone",
            "title": "Generate shady versions of desktop pictures in OS X"
        },
        {
            "location": "/imagemagick/#crop-the-center-of-images-out",
            "text": "for X in /Volumes/data-b/Timelapse/20120407-14* ; do\n  convert \"${X}\" -gravity Center -crop 1920x1080+0+0 $(basename ${X})\ndone",
            "title": "Crop the center of images out"
        },
        {
            "location": "/imagemagick/#average-many-photos-for-a-long-exposure-style-shot",
            "text": "convert *.jpg -average average.jpg",
            "title": "Average many photos for a long-exposure style shot"
        },
        {
            "location": "/imagemagick/#multiply-several-images",
            "text": "convert *.jpg -background white -compose multiply -flatten multiply.jpg",
            "title": "Multiply several images"
        },
        {
            "location": "/imagemagick/#combine-images-always-using-the-minimum-value",
            "text": "convert *.jpg -background white -compose darken -flatten minimum.jpg",
            "title": "Combine images always using the minimum value"
        },
        {
            "location": "/imagemagick/#combine-images-always-using-the-maximum-value",
            "text": "convert *.jpg -background black -compose lighten -flatten maximum.jpg",
            "title": "Combine images always using the maximum value"
        },
        {
            "location": "/imagemagick/#swap-red-and-blue-channels-for-ir-photos",
            "text": "convert infile.jpg -separate -swap 0,2 -combine swapped.jpg",
            "title": "Swap red and blue channels (for IR photos)"
        },
        {
            "location": "/imagemagick/#animate-some-images",
            "text": "convert -delay 20 -loop 0 *.jpg animation.gif",
            "title": "Animate some images"
        },
        {
            "location": "/imagemagick/#see-also",
            "text": "exiftool  graphicsmagick  jpeginfo  sips",
            "title": "See Also"
        },
        {
            "location": "/img2xterm/",
            "text": "Converts images into xterm 256 color output for viewing when there is no graphical display. Unfortuntely as of 2016-09-07 I can't find this in an easily distributable package.\n\n\nhttps://github.com/rossy/img2xterm",
            "title": "Img2xterm"
        },
        {
            "location": "/innotop/",
            "text": "\"innotop is a 'top' clone for MySQL with many features and flexibility.\" - \nhttps://github.com/innotop/innotop\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Innotop"
        },
        {
            "location": "/innotop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/inotify/",
            "text": "\"inotify - monitoring file system events\" - \nman inotify\n\n\n\"inotifywatch - gather filesystem access statistics using inotify\" - \nman inotifywatch\n\n\n\"The inotify cron daemon (incrond) is a daemon which monitors filesystem events and executes commands defined in system and user tables. It's (sic) use is generally similar to cron(8).\" - \nman incrond\n\n\n\n\nExamples\n\n\nContinuously show filesystem events on a file\n\n\nThis shows a datestamp when /var/log/syslog is modified. Theoretically we could use \n%N\n to get millisecond precision, but it doesn't work.\n\n\nsudo sudo inotifywait -m --timefmt '%F %T.%z' --format '%T %w %e %f' /var/log/syslog",
            "title": "Inotify"
        },
        {
            "location": "/inotify/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/inotify/#continuously-show-filesystem-events-on-a-file",
            "text": "This shows a datestamp when /var/log/syslog is modified. Theoretically we could use  %N  to get millisecond precision, but it doesn't work.  sudo sudo inotifywait -m --timefmt '%F %T.%z' --format '%T %w %e %f' /var/log/syslog",
            "title": "Continuously show filesystem events on a file"
        },
        {
            "location": "/iotop/",
            "text": "iotop tracks disk I/O by process, and prints a summary report that is refreshed every interval.\n\n\nLinux Examples\n\n\nShow cumulative stats for processes actually using IO\n\n\niotop\u00a0-oa\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Iotop"
        },
        {
            "location": "/iotop/#linux-examples",
            "text": "",
            "title": "Linux Examples"
        },
        {
            "location": "/iotop/#show-cumulative-stats-for-processes-actually-using-io",
            "text": "iotop\u00a0-oa",
            "title": "Show cumulative stats for processes actually using IO"
        },
        {
            "location": "/iotop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/ip/",
            "text": "This is about the ip command in Linux.\n\n\nExamples\n\n\nThe commands here can be shortened like cisco or other network device commands.\n\n\nShow IP neighbors\n\n\nip neighbor show\n\n\n\n\nShow all configured IP addresses\n\n\nThis is more reliable than ifconfig, which sometimes omits entries.\n\n\nip -f inet addr\n\n\n\n\nShow information about eth0\n\n\nThis shows information about eth0 and all the virtual interfaces brought up on the physical interface.\n\n\nip addr show eth0\n\n\n\n\nMonitor IP changes\n\n\nip mon all\n\n\n\n\nShow interfaces that would route to a given network address\n\n\nip addr show to 10.1.8.0/24\n\n\n\n\nShow negotiated speeds for all interfaces\n\n\nip -o link show | awk -F: '{print $2}' | while read -r X ; do\n  sudo ethtool ${X} | egrep 'Settings|Speed' | xargs echo\ndone | column -t -s:",
            "title": "Ip"
        },
        {
            "location": "/ip/#examples",
            "text": "The commands here can be shortened like cisco or other network device commands.",
            "title": "Examples"
        },
        {
            "location": "/ip/#show-ip-neighbors",
            "text": "ip neighbor show",
            "title": "Show IP neighbors"
        },
        {
            "location": "/ip/#show-all-configured-ip-addresses",
            "text": "This is more reliable than ifconfig, which sometimes omits entries.  ip -f inet addr",
            "title": "Show all configured IP addresses"
        },
        {
            "location": "/ip/#show-information-about-eth0",
            "text": "This shows information about eth0 and all the virtual interfaces brought up on the physical interface.  ip addr show eth0",
            "title": "Show information about eth0"
        },
        {
            "location": "/ip/#monitor-ip-changes",
            "text": "ip mon all",
            "title": "Monitor IP changes"
        },
        {
            "location": "/ip/#show-interfaces-that-would-route-to-a-given-network-address",
            "text": "ip addr show to 10.1.8.0/24",
            "title": "Show interfaces that would route to a given network address"
        },
        {
            "location": "/ip/#show-negotiated-speeds-for-all-interfaces",
            "text": "ip -o link show | awk -F: '{print $2}' | while read -r X ; do\n  sudo ethtool ${X} | egrep 'Settings|Speed' | xargs echo\ndone | column -t -s:",
            "title": "Show negotiated speeds for all interfaces"
        },
        {
            "location": "/iperf/",
            "text": "\"iperf3: A TCP, UDP, and SCTP network bandwidth measurement tool\" - \nhttps://github.com/esnet/iperf\n\n\nLinks\n\n\n\n\nSample usage - \nhttps://fasterdata.es.net/performance-testing/network-troubleshooting-tools/iperf/",
            "title": "Iperf"
        },
        {
            "location": "/iperf/#links",
            "text": "Sample usage -  https://fasterdata.es.net/performance-testing/network-troubleshooting-tools/iperf/",
            "title": "Links"
        },
        {
            "location": "/ipmi/",
            "text": "The Intelligent Platform Management Interface (IPMI) is a set of computer interface specifications for an autonomous computer subsystem that provides management and monitoring capabilities independently of the host system's CPU, firmware (BIOS or UEFI) and operating system.\n\n\nManaging servers with IPMI\n\n\nDefault Users\n\n\nThe default users are 'Administrator' for HPs, 'root' for Dells, and 'ADMIN' for Silicon Mechanics.\n\n\nServer Setup\n\n\nIPMI uses COM2 aka ttyS1 for the serial port on Dells and HPs, COM3 aka ttyS2 on Silicon Mechanics.\n\n\nCommon Remote Commands\n\n\nSee if a server is on\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power status\n\n\n\n\nTurn a server on\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power on\n\n\n\n\nTurn a server off\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power off\n\n\n\n\nTell a server to PXEBoot\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power off\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis bootdev pxe\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power on\n\n\n\n\nConnect to the serial console\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sol activate\n\n\n\n\nDisplay the system event log\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sel list\n\n\n\n\nClear the system event log\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sel clear\n\n\n\n\nDisplay sensor information\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sdr list\n\n\n\n\nDisconnect another serial console session\n\n\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sol deactivate\n\n\n\n\nShow bootdev help\n\n\nipmitool -H 10.5.8.30 -U ADMIN -P ADMIN chassis bootdev none options=help\n\n\n\n\nCommon Local Commands\n\n\nThese commands require root access in most environments.\n\n\nView all configured LAN parameters\n\n\nipmitool lan print\n\n\n\n\nYou can view individual \"channels\" which are logical interfaces by giving the number:\n\n\nipmitool lan print 1\n\n\n\n\nReset the BMC\n\n\nIf a host loses it's IPMI (iLO, etc.) IP connectivity, issue this command from the host itself\n\n\nipmitool mc reset cold\n\n\n\n\nHow to fix /dev/ipmi errors\n\n\nFor errors like\n\n\nCould not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0\n\n\nmodprobe ipmi_msghandler\nmodprobe ipmi_devintf\nmodprobe ipmi_si\n\n\n\n\nSee Also\n\n\n\n\nhttp://www.intel.com/design/servers/ipmi/",
            "title": "Ipmi"
        },
        {
            "location": "/ipmi/#managing-servers-with-ipmi",
            "text": "",
            "title": "Managing servers with IPMI"
        },
        {
            "location": "/ipmi/#default-users",
            "text": "The default users are 'Administrator' for HPs, 'root' for Dells, and 'ADMIN' for Silicon Mechanics.",
            "title": "Default Users"
        },
        {
            "location": "/ipmi/#server-setup",
            "text": "IPMI uses COM2 aka ttyS1 for the serial port on Dells and HPs, COM3 aka ttyS2 on Silicon Mechanics.",
            "title": "Server Setup"
        },
        {
            "location": "/ipmi/#common-remote-commands",
            "text": "",
            "title": "Common Remote Commands"
        },
        {
            "location": "/ipmi/#see-if-a-server-is-on",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power status",
            "title": "See if a server is on"
        },
        {
            "location": "/ipmi/#turn-a-server-on",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power on",
            "title": "Turn a server on"
        },
        {
            "location": "/ipmi/#turn-a-server-off",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power off",
            "title": "Turn a server off"
        },
        {
            "location": "/ipmi/#tell-a-server-to-pxeboot",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power off\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis bootdev pxe\nipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP chassis power on",
            "title": "Tell a server to PXEBoot"
        },
        {
            "location": "/ipmi/#connect-to-the-serial-console",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sol activate",
            "title": "Connect to the serial console"
        },
        {
            "location": "/ipmi/#display-the-system-event-log",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sel list",
            "title": "Display the system event log"
        },
        {
            "location": "/ipmi/#clear-the-system-event-log",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sel clear",
            "title": "Clear the system event log"
        },
        {
            "location": "/ipmi/#display-sensor-information",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sdr list",
            "title": "Display sensor information"
        },
        {
            "location": "/ipmi/#disconnect-another-serial-console-session",
            "text": "ipmitool -I lanplus -U $USER -P $PASSWORD -H $IPMI_IP sol deactivate",
            "title": "Disconnect another serial console session"
        },
        {
            "location": "/ipmi/#show-bootdev-help",
            "text": "ipmitool -H 10.5.8.30 -U ADMIN -P ADMIN chassis bootdev none options=help",
            "title": "Show bootdev help"
        },
        {
            "location": "/ipmi/#common-local-commands",
            "text": "These commands require root access in most environments.",
            "title": "Common Local Commands"
        },
        {
            "location": "/ipmi/#view-all-configured-lan-parameters",
            "text": "ipmitool lan print  You can view individual \"channels\" which are logical interfaces by giving the number:  ipmitool lan print 1",
            "title": "View all configured LAN parameters"
        },
        {
            "location": "/ipmi/#reset-the-bmc",
            "text": "If a host loses it's IPMI (iLO, etc.) IP connectivity, issue this command from the host itself  ipmitool mc reset cold",
            "title": "Reset the BMC"
        },
        {
            "location": "/ipmi/#how-to-fix-devipmi-errors",
            "text": "For errors like  Could not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0  modprobe ipmi_msghandler\nmodprobe ipmi_devintf\nmodprobe ipmi_si",
            "title": "How to fix /dev/ipmi errors"
        },
        {
            "location": "/ipmi/#see-also",
            "text": "http://www.intel.com/design/servers/ipmi/",
            "title": "See Also"
        },
        {
            "location": "/iptables/",
            "text": "iptables is the built-in linux firewall.\n\n\nExamples\n\n\n\n\nHow to simulate a slow network link: \nhttp://blogs.kde.org/node/1878\n\n\n\n\nAllow MySQL\n\n\niptables -A INPUT -i eth0 -p tcp -m tcp --dport 3306 -j ACCEPT\n\n\n\n\nSSH blocking\n\n\nBetter idea: \nfail2ban\n\n\nBasically, it lets people connect with SSH 5 times within a minute, but with a mandatory 5 second wait before connection attempts.  Once they hit 5 attempts in a minute they get banned for an hour. Several IP ranges are exceptions where access is always allowed.\n\n\niptables -I INPUT 1 -s 172.16.0.0/16 -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -I INPUT 2 -s 17.1.2.0/27   -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -I INPUT 3 -s 18.3.4.0/27   -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -I INPUT 4 -s 19.5.6.0/24   -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -N SSH\niptables -N SSH_ABL\niptables -A SSH -m recent --name SSH_ABL --update --seconds 3600 -j REJECT\niptables -A SSH -m recent --name SSH --rcheck --seconds 60 --hitcount 5 -j SSH_ABL\niptables -A SSH_ABL -m recent --name SSH_ABL --set -j LOG --log-level warn --log-prefix \"ABL: +SSH: \"\niptables -A SSH_ABL -j REJECT\niptables -A SSH -m recent --name SSH --rcheck --seconds 5 -j LOG --log-level warn --log-prefix \"RATE: \"\niptables -A SSH -m recent --name SSH --update --seconds 5 -j REJECT\niptables -A SSH -m recent --name SSH_ABL --remove -j LOG --log-level warn --log-prefix \"ABL: -SSH: \"\niptables -A SSH -m recent --name SSH --set -j ACCEPT\niptables -A INPUT -m state --state NEW -p tcp -m tcp --dport 22 -j SSH\niptables -L",
            "title": "Iptables"
        },
        {
            "location": "/iptables/#examples",
            "text": "How to simulate a slow network link:  http://blogs.kde.org/node/1878",
            "title": "Examples"
        },
        {
            "location": "/iptables/#allow-mysql",
            "text": "iptables -A INPUT -i eth0 -p tcp -m tcp --dport 3306 -j ACCEPT",
            "title": "Allow MySQL"
        },
        {
            "location": "/iptables/#ssh-blocking",
            "text": "Better idea:  fail2ban  Basically, it lets people connect with SSH 5 times within a minute, but with a mandatory 5 second wait before connection attempts.  Once they hit 5 attempts in a minute they get banned for an hour. Several IP ranges are exceptions where access is always allowed.  iptables -I INPUT 1 -s 172.16.0.0/16 -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -I INPUT 2 -s 17.1.2.0/27   -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -I INPUT 3 -s 18.3.4.0/27   -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -I INPUT 4 -s 19.5.6.0/24   -m state --state NEW -p tcp -m tcp --dport 22 -j ACCEPT\niptables -N SSH\niptables -N SSH_ABL\niptables -A SSH -m recent --name SSH_ABL --update --seconds 3600 -j REJECT\niptables -A SSH -m recent --name SSH --rcheck --seconds 60 --hitcount 5 -j SSH_ABL\niptables -A SSH_ABL -m recent --name SSH_ABL --set -j LOG --log-level warn --log-prefix \"ABL: +SSH: \"\niptables -A SSH_ABL -j REJECT\niptables -A SSH -m recent --name SSH --rcheck --seconds 5 -j LOG --log-level warn --log-prefix \"RATE: \"\niptables -A SSH -m recent --name SSH --update --seconds 5 -j REJECT\niptables -A SSH -m recent --name SSH_ABL --remove -j LOG --log-level warn --log-prefix \"ABL: -SSH: \"\niptables -A SSH -m recent --name SSH --set -j ACCEPT\niptables -A INPUT -m state --state NEW -p tcp -m tcp --dport 22 -j SSH\niptables -L",
            "title": "SSH blocking"
        },
        {
            "location": "/jargon/",
            "text": "bikeshedding\n - The term was coined as a metaphor to illuminate Parkinson's Law of Triviality. Parkinson observed that a committee whose job is to approve plans for a nuclear power plant may spend the majority of its time on relatively unimportant but easy-to-grasp issues, such as what materials to use for the staff bikeshed, while neglecting the design of the power plant itself, which is far more important but also far more difficult to criticize constructively.\n\n\ncargo cult\n - software containing elements that are included because of successful utilization elsewhere, unnecessary for the task at hand.\n\n\nCunningham's law\n - The best way to get the right answer on the Internet is not to ask a question, it's to post the wrong answer.\n\n\n[deterministic] - In mathematics and physics, a deterministic system is a system in which no randomness is involved in the development of future states of the system. A deterministic model will thus always produce the same output from a given starting condition or initial state.\n\n\nDRY\n - Don't Repeat Yourself. \"Every piece of knowledge must have a single, unambiguous, authoritative representation within a system\"\n\n\nidempotent\n - Idempotence is the property of certain operations in mathematics and computer science, that they can be applied multiple times without changing the result beyond the initial application.\n\n\nKISS\n - Keep It Simple, Stupid!\n\n\nmartian packet\n - A Martian packet is an IP packet which specifies a source or destination address that is reserved for special-use by Internet Assigned Numbers Authority.\n\n\nmonotonic\n - A function or set of values that always increases or always decreases.\n\n\nwarrant canary\n - Text on a website that states the company or person has never been served with a secret government subpoena. Once the statement is removed, the users can assume the company or person has been served and has been told not to talk about it.\n\n\nYAGNI\n - a principle that states a programmer should not add functionality until deemed necessary.\n\n\nyak shaving\n - Any apparently useless activity which, by allowing you to overcome intermediate difficulties, allows you to solve a larger problem.",
            "title": "Jargon"
        },
        {
            "location": "/jdupes/",
            "text": "\"finds and performs actions upon duplicate files\" - \nman jdupes\n\n\njdupes\n is based on \nfdupes\n and is not written in java as the name may lead you to assume.\n\n\nExamples\n\n\nRecursively find all duplicates in a dir\n\n\njdupes\u00a0-r\u00a0/path/to/dir\n\n\n\n\nCreate hard-links of any duplicate files\n\n\njdupes -r -L /path/\n\n\n\n\nLinks\n\n\n\n\nhttps://github.com/jbruchon/jdupes",
            "title": "Jdupes"
        },
        {
            "location": "/jdupes/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/jdupes/#recursively-find-all-duplicates-in-a-dir",
            "text": "jdupes\u00a0-r\u00a0/path/to/dir",
            "title": "Recursively find all duplicates in a dir"
        },
        {
            "location": "/jdupes/#create-hard-links-of-any-duplicate-files",
            "text": "jdupes -r -L /path/",
            "title": "Create hard-links of any duplicate files"
        },
        {
            "location": "/jdupes/#links",
            "text": "https://github.com/jbruchon/jdupes",
            "title": "Links"
        },
        {
            "location": "/jmespath/",
            "text": "\"JMESPath is a query language for JSON.\" - \nhttp://jmespath.org\n\n\nLinks\n\n\n\n\nhttps://github.com/jmespath/jp\n\n\nhttps://github.com/jmespath/jmespath.terminal",
            "title": "Jmespath"
        },
        {
            "location": "/jmespath/#links",
            "text": "https://github.com/jmespath/jp  https://github.com/jmespath/jmespath.terminal",
            "title": "Links"
        },
        {
            "location": "/jot/",
            "text": "jot is a BSD CLI tool to generate sequences or random data, usually numbers.\n\n\nTricks\n\n\nGenerate 37 evenly space floating point numbers (with two significant digits) between -10 and +10\n\n\njot 37 -10 10.00\n\n\n\n\nGenerate two 12 alphanumeric random character passwords with rs\n\n\njot -rc 24 48 123 | rs -g 0 12\n\n\n\n\nGenerate 5 capital alphanumeric strings\n\n\njot -rc 500 48 90 | grep '[A-Z0-9]' | rs -g 5 32",
            "title": "Jot"
        },
        {
            "location": "/jot/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/jot/#generate-37-evenly-space-floating-point-numbers-with-two-significant-digits-between-10-and-10",
            "text": "jot 37 -10 10.00",
            "title": "Generate 37 evenly space floating point numbers (with two significant digits) between -10 and +10"
        },
        {
            "location": "/jot/#generate-two-12-alphanumeric-random-character-passwords-with-rs",
            "text": "jot -rc 24 48 123 | rs -g 0 12",
            "title": "Generate two 12 alphanumeric random character passwords with rs"
        },
        {
            "location": "/jot/#generate-5-capital-alphanumeric-strings",
            "text": "jot -rc 500 48 90 | grep '[A-Z0-9]' | rs -g 5 32",
            "title": "Generate 5 capital alphanumeric strings"
        },
        {
            "location": "/jpeginfo/",
            "text": "\"jpeginfo - prints information and tests integrity of JPEG/JFIF files.\" - man jpeginfo\n\n\nExample\n\n\nTest integrity of all files in a dir\n\n\njpeginfo -c *\n\n\n\n\nTest integrity of files and delete any corrupt files\n\n\njpeginfo -c -d *\n\n\n\n\nSee Also\n\n\n\n\nexiftool\n\n\ngraphicsmagick\n\n\nimagemagick\n\n\nsips",
            "title": "Jpeginfo"
        },
        {
            "location": "/jpeginfo/#example",
            "text": "",
            "title": "Example"
        },
        {
            "location": "/jpeginfo/#test-integrity-of-all-files-in-a-dir",
            "text": "jpeginfo -c *",
            "title": "Test integrity of all files in a dir"
        },
        {
            "location": "/jpeginfo/#test-integrity-of-files-and-delete-any-corrupt-files",
            "text": "jpeginfo -c -d *",
            "title": "Test integrity of files and delete any corrupt files"
        },
        {
            "location": "/jpeginfo/#see-also",
            "text": "exiftool  graphicsmagick  imagemagick  sips",
            "title": "See Also"
        },
        {
            "location": "/jq/",
            "text": "\"jq is a lightweight and flexible command-line JSON processor.\" - \nhttps://stedolan.github.io/jq/\n\n\nExamples\n\n\nSort a json file\n\n\njq -S . foo.json\n\n\n\n\nGrab first element of an array, and print the value of 'timestamp' of that element.\n\n\necho '\n[\n  {\n    \"foo\": \"this is foo string\",\n    \"timestamp\": \"this is the timestamp\"\n  },\n  {\n    \"second element\": \"second element value\"\n  }\n]' | jq '.[0].timestamp'\n\n\n\n\nConstruct Flickr URLs from an API call\n\n\ncurl -s \"https://api.flickr.com/services/rest/?\"\\\n\"&api_key=9c72f03c0583a34bd703bd82d8773cc0\"\\\n\"&format=json\"\\\n\"&method=flickr.photos.getRecent\"\\\n\"&nojsoncallback=1\" |\n  jq -S '\n    .[\"photos\"][\"photo\"][] |\n    \"https://flickr.com/photos/\" + .owner + \"/\" + .id\n  '\n\n\n\n\nUse mco to find packages of a certain version on a certain OS\n\n\nThis example could be used as an alternative to grep, where only the value of a key/value pair is matched.\n\n\nmco rpc package status package=apt -j -F lsbdistcodename=trusty |\n  jq -c '\n    .[] |\n    select(.data.ensure == \"1.0.1ubuntu2\") | {\n      version: .data.ensure, hostname: .sender\n    }\n  '\n\n\n\n\nPrint only objects whose name matches a string\n\n\nThis example echoes some yaml, uses python to convert it to json, then filters matching data using \njq\n. It could be used as an alternative to grep, where only the key of a key/value pair is matched.\n\n\necho \"\ndata:\n  - This is a string, not an object, and contains the substrings foo and bar\n  - name: foo_name\n    value: foo_value\n  - name: bar_name\n    value: bar_value\" |\npython -c \"import yaml, sys, json; print json.dumps(yaml.safe_load(sys.stdin))\" |\njq '\n  .[\"data\"][] |\n  select(type==\"object\") |\n  select (.name | . and contains(\"bar_n\"))\n'\n\n\n\n\nBuild a json entry from scratch\n\n\nThis uses bash paramber expansion and subshell syntax, and may not work in other shells.\n\n\ncreate_json() {\n  local user=${1:-${USER}}\n  local host=${2:-${HOSTNAME}}\n  local more_stuff=${3:-$(uname -a)}\n  json=$(\n    jq -c -n \\\n      --arg timestamp  \"$(date \"+%F %T%z\")\" \\\n      --arg host       \"${host}\" \\\n      --arg user       \"${user}\" \\\n      --arg more_stuff \"${more_stuff}\" \\\n      '{\n        timestamp:  $timestamp,\n        host:       $host,\n        user:       $user,\n        more_stuff: $more_stuff\n      }'\n  )\n  echo \"$json\"\n}\n\n\n\n\nRender yaml with anchors as json data\n\n\nThis example shows how you can use python and jq to view the result of dereferenced yaml anchors, a construct that is not supported by json. This example is less about how to use \njq\n syntaxes, and more about how it can be used to view data that is otherwise difficult to sort through.\n\n\necho \"\njob1: &template\n  directory: /tmp\n  extra_parameters: nosuid,noatime\n  remote_host: 10.1.1.1\n  user: nobody\njob2:\n  <<: *template\n  remote_host: 10.2.2.2\njob3:\n  <<: *template\n  remote_host: 10.3.3.3\n\" |\npython -c \"import yaml, sys, json; print json.dumps(yaml.safe_load(sys.stdin))\" |\njq -S .\n\n\n\n\nSelect matches, and print a subset of values\n\n\njq '.[] | select(.data.ensure != \"purged\") | [.sender,.data.ensure]' $*\n\n\n\n\nOutput bare values for use as inputs\n\n\nThis is a contrived example, the better way to get this info would be \nawless list instances --format tsv --columns name,privateip,launched\n\n\n$ awless list instances --format json | jq -r '.[] | \"\\(.Name) \\(.PrivateIP) \\(.Launched)\"' | column -t\nsalt-master       172.18.9.48   2015-04-10T21:28:03Z\nconsul-server-01  172.18.9.116  2015-05-15T06:13:19Z\nconsul-server-02  172.18.9.117  2015-05-15T06:13:19Z\nconsul-server-03  172.18.9.118  2015-05-15T06:13:19Z\n\n\n\n\nSee Also\n\n\n\n\nTutorial",
            "title": "Jq"
        },
        {
            "location": "/jq/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/jq/#sort-a-json-file",
            "text": "jq -S . foo.json",
            "title": "Sort a json file"
        },
        {
            "location": "/jq/#grab-first-element-of-an-array-and-print-the-value-of-timestamp-of-that-element",
            "text": "echo '\n[\n  {\n    \"foo\": \"this is foo string\",\n    \"timestamp\": \"this is the timestamp\"\n  },\n  {\n    \"second element\": \"second element value\"\n  }\n]' | jq '.[0].timestamp'",
            "title": "Grab first element of an array, and print the value of 'timestamp' of that element."
        },
        {
            "location": "/jq/#construct-flickr-urls-from-an-api-call",
            "text": "curl -s \"https://api.flickr.com/services/rest/?\"\\\n\"&api_key=9c72f03c0583a34bd703bd82d8773cc0\"\\\n\"&format=json\"\\\n\"&method=flickr.photos.getRecent\"\\\n\"&nojsoncallback=1\" |\n  jq -S '\n    .[\"photos\"][\"photo\"][] |\n    \"https://flickr.com/photos/\" + .owner + \"/\" + .id\n  '",
            "title": "Construct Flickr URLs from an API call"
        },
        {
            "location": "/jq/#use-mco-to-find-packages-of-a-certain-version-on-a-certain-os",
            "text": "This example could be used as an alternative to grep, where only the value of a key/value pair is matched.  mco rpc package status package=apt -j -F lsbdistcodename=trusty |\n  jq -c '\n    .[] |\n    select(.data.ensure == \"1.0.1ubuntu2\") | {\n      version: .data.ensure, hostname: .sender\n    }\n  '",
            "title": "Use mco to find packages of a certain version on a certain OS"
        },
        {
            "location": "/jq/#print-only-objects-whose-name-matches-a-string",
            "text": "This example echoes some yaml, uses python to convert it to json, then filters matching data using  jq . It could be used as an alternative to grep, where only the key of a key/value pair is matched.  echo \"\ndata:\n  - This is a string, not an object, and contains the substrings foo and bar\n  - name: foo_name\n    value: foo_value\n  - name: bar_name\n    value: bar_value\" |\npython -c \"import yaml, sys, json; print json.dumps(yaml.safe_load(sys.stdin))\" |\njq '\n  .[\"data\"][] |\n  select(type==\"object\") |\n  select (.name | . and contains(\"bar_n\"))\n'",
            "title": "Print only objects whose name matches a string"
        },
        {
            "location": "/jq/#build-a-json-entry-from-scratch",
            "text": "This uses bash paramber expansion and subshell syntax, and may not work in other shells.  create_json() {\n  local user=${1:-${USER}}\n  local host=${2:-${HOSTNAME}}\n  local more_stuff=${3:-$(uname -a)}\n  json=$(\n    jq -c -n \\\n      --arg timestamp  \"$(date \"+%F %T%z\")\" \\\n      --arg host       \"${host}\" \\\n      --arg user       \"${user}\" \\\n      --arg more_stuff \"${more_stuff}\" \\\n      '{\n        timestamp:  $timestamp,\n        host:       $host,\n        user:       $user,\n        more_stuff: $more_stuff\n      }'\n  )\n  echo \"$json\"\n}",
            "title": "Build a json entry from scratch"
        },
        {
            "location": "/jq/#render-yaml-with-anchors-as-json-data",
            "text": "This example shows how you can use python and jq to view the result of dereferenced yaml anchors, a construct that is not supported by json. This example is less about how to use  jq  syntaxes, and more about how it can be used to view data that is otherwise difficult to sort through.  echo \"\njob1: &template\n  directory: /tmp\n  extra_parameters: nosuid,noatime\n  remote_host: 10.1.1.1\n  user: nobody\njob2:\n  <<: *template\n  remote_host: 10.2.2.2\njob3:\n  <<: *template\n  remote_host: 10.3.3.3\n\" |\npython -c \"import yaml, sys, json; print json.dumps(yaml.safe_load(sys.stdin))\" |\njq -S .",
            "title": "Render yaml with anchors as json data"
        },
        {
            "location": "/jq/#select-matches-and-print-a-subset-of-values",
            "text": "jq '.[] | select(.data.ensure != \"purged\") | [.sender,.data.ensure]' $*",
            "title": "Select matches, and print a subset of values"
        },
        {
            "location": "/jq/#output-bare-values-for-use-as-inputs",
            "text": "This is a contrived example, the better way to get this info would be  awless list instances --format tsv --columns name,privateip,launched  $ awless list instances --format json | jq -r '.[] | \"\\(.Name) \\(.PrivateIP) \\(.Launched)\"' | column -t\nsalt-master       172.18.9.48   2015-04-10T21:28:03Z\nconsul-server-01  172.18.9.116  2015-05-15T06:13:19Z\nconsul-server-02  172.18.9.117  2015-05-15T06:13:19Z\nconsul-server-03  172.18.9.118  2015-05-15T06:13:19Z",
            "title": "Output bare values for use as inputs"
        },
        {
            "location": "/jq/#see-also",
            "text": "Tutorial",
            "title": "See Also"
        },
        {
            "location": "/jupyter/",
            "text": "\"Project Jupyter exists to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages.\" - \nhttp://jupyter.org/\n\n\nLinks\n\n\n\n\nA gallery of interesting Jupyter Notebooks\n\n\nInteractive coding challenges\n\n\nPresenting Code Using Jupyter Notebook Slides",
            "title": "Jupyter"
        },
        {
            "location": "/jupyter/#links",
            "text": "A gallery of interesting Jupyter Notebooks  Interactive coding challenges  Presenting Code Using Jupyter Notebook Slides",
            "title": "Links"
        },
        {
            "location": "/keel/",
            "text": "\"Automated Kubernetes deployment updates\" - \nhttps://github.com/keel-hq/keel\n\n\n\"Kubectl is the new SSH. If you are using it to update production workloads, you are doing it wrong.\" - \nhttps://keel.sh/",
            "title": "Keel"
        },
        {
            "location": "/keybase/",
            "text": "Keybase is a free, open source security app. It's also a public directory of people.\n\n\n\n\nKeybase.io\n\n\nIntroducing the Keybase filesystem\n\n\nGithub.com/Keybase\n\n\n\n\nMy ID\n\n\n\n\nhttps://keybase.io/hoherd\n\n\nkeybase id hoherd",
            "title": "Keybase"
        },
        {
            "location": "/keybase/#my-id",
            "text": "https://keybase.io/hoherd  keybase id hoherd",
            "title": "My ID"
        },
        {
            "location": "/kubernetes/",
            "text": "\"Kubernetes is an open-source platform for automating deployment, scaling, and operations of application containers across clusters of hosts, providing container-centric infrastructure.\" - \nhttps://kubernetes.io/docs/whatisk8s\n\n\ncli usage\n\n\nkubeadm\n\n\n\"kubeadm: easily bootstrap a secure Kubernetes cluster.\" - \nkubeadm --help\n\n\n\n\nhttps://github.com/kubernetes/kubeadm\n\n\n\n\nkubectl\n\n\n\"kubectl controls the Kubernetes cluster manager.\" - \nkubectl --help\n\n\n\n\n\n\nhttps://github.com/kubernetes/kubectl\n\n\n\n\n\n\nkubectl get nodes\n\n\n\n\nkubectl config get-contexts\n\n\nkubectl config use-context foo\n\n\nkubectl get pods\n\n\nkubectl describe pod foo\n\n\n\n\nQuick and dirty installations\n\n\nkubespray\n\n\n\n\nhttps://github.com/kubernetes-incubator/kubespray\n\n\n\n\nManually on Ubuntu 16\n\n\nsudo swapoff -a # https://github.com/kubernetes/kubernetes/issues/53533\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\nsudo apt install -y apt-transport-https ca-certificates curl software-properties-common\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable\"\nsudo add-apt-repository \"deb http://apt.kubernetes.io/ kubernetes-xenial main\"\nsudo apt update\nsudo apt install -y kubelet kubeadm kubectl\n\n\n\n\nLinks\n\n\n\n\nhttps://kubernetes.io/docs/setup/independent/create-cluster-kubeadm\n\n\nhttps://blog.hypriot.com/post/setup-kubernetes-raspberry-pi-cluster\n\n\nhttps://docs.projectcalico.org/v3.0/introduction/\n\n\nhttps://kubernetes.io/docs/reference/glossary/\n\n\nhttps://kubernetes.io/docs/getting-started-guides/minikube/\n\n\nhttp://slack.kubernetes.io/",
            "title": "Kubernetes"
        },
        {
            "location": "/kubernetes/#cli-usage",
            "text": "",
            "title": "cli usage"
        },
        {
            "location": "/kubernetes/#kubeadm",
            "text": "\"kubeadm: easily bootstrap a secure Kubernetes cluster.\" -  kubeadm --help   https://github.com/kubernetes/kubeadm",
            "title": "kubeadm"
        },
        {
            "location": "/kubernetes/#kubectl",
            "text": "\"kubectl controls the Kubernetes cluster manager.\" -  kubectl --help    https://github.com/kubernetes/kubectl    kubectl get nodes   kubectl config get-contexts  kubectl config use-context foo  kubectl get pods  kubectl describe pod foo",
            "title": "kubectl"
        },
        {
            "location": "/kubernetes/#quick-and-dirty-installations",
            "text": "",
            "title": "Quick and dirty installations"
        },
        {
            "location": "/kubernetes/#kubespray",
            "text": "https://github.com/kubernetes-incubator/kubespray",
            "title": "kubespray"
        },
        {
            "location": "/kubernetes/#manually-on-ubuntu-16",
            "text": "sudo swapoff -a # https://github.com/kubernetes/kubernetes/issues/53533\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\nsudo apt install -y apt-transport-https ca-certificates curl software-properties-common\nsudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable\"\nsudo add-apt-repository \"deb http://apt.kubernetes.io/ kubernetes-xenial main\"\nsudo apt update\nsudo apt install -y kubelet kubeadm kubectl",
            "title": "Manually on Ubuntu 16"
        },
        {
            "location": "/kubernetes/#links",
            "text": "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm  https://blog.hypriot.com/post/setup-kubernetes-raspberry-pi-cluster  https://docs.projectcalico.org/v3.0/introduction/  https://kubernetes.io/docs/reference/glossary/  https://kubernetes.io/docs/getting-started-guides/minikube/  http://slack.kubernetes.io/",
            "title": "Links"
        },
        {
            "location": "/launchd/",
            "text": "launchd is MacOS X's init system.\n\n\nExample\n\n\nWatch Folder\n\n\nThis user LaunchAgent would be placed into \n$HOME/Library/LaunchAgents/photo_processor.plist\n.\n\n\nWe have to specify \n/bin/bash\n as the first ProgramArgument so OS X doesn't complain about DRM or mach-o executable shizz. This effectively limits us to bash 3.\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n  <dict>\n    <key>Label</key>\n    <string>photo_processor.sh</string>\n\n    <key>ProgramArguments</key><array>\n      <string>/bin/bash</string>\n      <string>/Users/hoherd/code/dho-bin/photo_processor.sh</string>\n    </array>\n\n    <key>WatchPaths</key>\n    <array>\n        <string>/Users/hoherd/Dropbox/yp/photo_queue/</string>\n    </array>\n\n  </dict>\n</plist>\n\n\n\n\nSee also\n\n\n\n\nhttps://github.com/jordansissel/pleaserun",
            "title": "Launchd"
        },
        {
            "location": "/launchd/#example",
            "text": "",
            "title": "Example"
        },
        {
            "location": "/launchd/#watch-folder",
            "text": "This user LaunchAgent would be placed into  $HOME/Library/LaunchAgents/photo_processor.plist .  We have to specify  /bin/bash  as the first ProgramArgument so OS X doesn't complain about DRM or mach-o executable shizz. This effectively limits us to bash 3.  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n  <dict>\n    <key>Label</key>\n    <string>photo_processor.sh</string>\n\n    <key>ProgramArguments</key><array>\n      <string>/bin/bash</string>\n      <string>/Users/hoherd/code/dho-bin/photo_processor.sh</string>\n    </array>\n\n    <key>WatchPaths</key>\n    <array>\n        <string>/Users/hoherd/Dropbox/yp/photo_queue/</string>\n    </array>\n\n  </dict>\n</plist>",
            "title": "Watch Folder"
        },
        {
            "location": "/launchd/#see-also",
            "text": "https://github.com/jordansissel/pleaserun",
            "title": "See also"
        },
        {
            "location": "/ldap/",
            "text": "Lightweight Directory Access Protocol\n\n\nAcronyms and stuff\n\n\n\n\no=organization\n\n\nc=country\n\n\ndn=distinguished_name\n\n\ndc=domain_component\n\n\nrdn=relative_distinguished_name\n\n\ncn=common_name\n\n\nuid=user_id\n\n\n\n\nTricks\n\n\nShow the whole ldap database\n\n\nFrom the LDAP server\n\n\nslapcat\n\n\n\n\nShow pwdFailureTime count and associated uid\n\n\nsudo slapcat 2>/dev/null | egrep '^(pwdFailureTime|uid:)' | uniq -c -w 14 | grep -B1 pwdFailureTime\n\n\n\n\nShow LDAP and local user account info\n\n\ngetent passwd maxb\n\n\n\n\nSearch an LDAP tree\n\n\nldapsearch -x -b \"dc=example,dc=com\"\n\n\n\n\nThis can be used when forwarding through \nssh -L 3389:127.0.0.1:389 remotehost\n\n\nldapsearch -x -h 127.0.0.1 -p 3389 -b \"dc=example,dc=com\"\n\n\n\n\nRun a search while authenticated\n\n\nThis logs in as danielh and searches for a record with uid=robertc\n\n\nldapsearch -x -b \"dc=example,dc=com\" -D \"uid=danielh,ou=people,dc=example,dc=com\" -W \"uid=danielh\"\n\n\n\n\nRefresh LDAP user cache on CentOS 6\n\n\nnscd -i passwd ; nscd -i group ; /etc/init.d/lldpad restart ; /etc/init.d/nslcd restart ; /etc/init.d/nscd restart ;\n\n\n\n\nSee Also\n\n\n\n\nApache Directory Studio graphical interface for LDAP: \nhttps://directory.apache.org/studio/\n\n\nA great series of articles on LDAP:  \nhttp://www.ldapman.org/articles/\n\n\nUbuntu Server LDAP integration:  \nhttps://help.ubuntu.com/community/LDAPClientAuthentication",
            "title": "Ldap"
        },
        {
            "location": "/ldap/#acronyms-and-stuff",
            "text": "o=organization  c=country  dn=distinguished_name  dc=domain_component  rdn=relative_distinguished_name  cn=common_name  uid=user_id",
            "title": "Acronyms and stuff"
        },
        {
            "location": "/ldap/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/ldap/#show-the-whole-ldap-database",
            "text": "From the LDAP server  slapcat",
            "title": "Show the whole ldap database"
        },
        {
            "location": "/ldap/#show-pwdfailuretime-count-and-associated-uid",
            "text": "sudo slapcat 2>/dev/null | egrep '^(pwdFailureTime|uid:)' | uniq -c -w 14 | grep -B1 pwdFailureTime",
            "title": "Show pwdFailureTime count and associated uid"
        },
        {
            "location": "/ldap/#show-ldap-and-local-user-account-info",
            "text": "getent passwd maxb",
            "title": "Show LDAP and local user account info"
        },
        {
            "location": "/ldap/#search-an-ldap-tree",
            "text": "ldapsearch -x -b \"dc=example,dc=com\"  This can be used when forwarding through  ssh -L 3389:127.0.0.1:389 remotehost  ldapsearch -x -h 127.0.0.1 -p 3389 -b \"dc=example,dc=com\"",
            "title": "Search an LDAP tree"
        },
        {
            "location": "/ldap/#run-a-search-while-authenticated",
            "text": "This logs in as danielh and searches for a record with uid=robertc  ldapsearch -x -b \"dc=example,dc=com\" -D \"uid=danielh,ou=people,dc=example,dc=com\" -W \"uid=danielh\"",
            "title": "Run a search while authenticated"
        },
        {
            "location": "/ldap/#refresh-ldap-user-cache-on-centos-6",
            "text": "nscd -i passwd ; nscd -i group ; /etc/init.d/lldpad restart ; /etc/init.d/nslcd restart ; /etc/init.d/nscd restart ;",
            "title": "Refresh LDAP user cache on CentOS 6"
        },
        {
            "location": "/ldap/#see-also",
            "text": "Apache Directory Studio graphical interface for LDAP:  https://directory.apache.org/studio/  A great series of articles on LDAP:   http://www.ldapman.org/articles/  Ubuntu Server LDAP integration:   https://help.ubuntu.com/community/LDAPClientAuthentication",
            "title": "See Also"
        },
        {
            "location": "/lego-mindstorms/",
            "text": "Lego Mindstorms\n\n\nTips\n\n\n\n\nev3 programming software is available via \ncask\n: \nbrew cask install lego-mindstorms-ev3\n\n\n\n\nLinks\n\n\n\n\nhttp://www.lego.com/en-us/mindstorms\n\n\nCommunity Gallery\n - Robot designs from lego mindstorm community.\n\n\nRobot Operating System for ev3\n\n\nBUILD A ROBOT\n - \"These robots give you the full EV3 experience, complete with building instructions, programming missions and the programming tool included in the new free EV3 Programmer App.\"\n\n\nLEGO MINDSTORMS EV3 source code\n\n\nBrickPi\n - \"This project combines the brains of a Raspberry Pi with the brawn of a LEGO MINDSTORMS NXT\"\n\n\nev3dev\n - \"ev3dev is a Debian Linux-based operating system that runs on several LEGO\u00ae MINDSTORMS compatible platforms including the LEGO\u00ae MINDSTORMS EV3 and Raspberry Pi-powered BrickPi.\"\n\n\nhttp://botbench.com/\n\n\nhttp://robotsquare.com/\n\n\n\n\nVideos\n\n\n\n\n\n\n\n\nlink\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nhttps://youtu.be/Ii4ElBLvp6Q\n\n\nActive differential system for RWD traction control\n\n\n\n\n\n\nhttps://youtu.be/t-c6ktfzwW0\n\n\nArm robot\n\n\n\n\n\n\nhttps://youtu.be/961IdKfa5rI\n\n\nArm robot - 3 axis, 360 degree motion, lightweight\n\n\n\n\n\n\nhttps://youtu.be/yAtmdyyIRbE\n\n\nArm robot on treads\n\n\n\n\n\n\nhttps://youtu.be/P6b60zf1g18\n\n\nBALANC3R and Gyro Boy, self balancing Segway style bots\n\n\n\n\n\n\nhttps://youtu.be/zR4BKgj9WSc\n\n\nBrick2014 EV3 6-Axis Robot Arm\n\n\n\n\n\n\nhttps://youtu.be/2zbBCmNoaXs\n\n\nBrickPi walkthrough\n\n\n\n\n\n\nhttps://youtu.be/cETV5WGB6kQ\n\n\nBridge layer\n\n\n\n\n\n\nhttps://youtu.be/bFgO-C2TAV8\n\n\nClash of Clans player\n\n\n\n\n\n\nhttps://youtu.be/np3qWZVyvIU\n\n\nCoin sorter\n\n\n\n\n\n\nhttps://youtu.be/oUJ4L4kmbHw\n\n\nComplicated bridge layer\n\n\n\n\n\n\nhttps://youtu.be/GOQENxeL4nY\n\n\nConvert rotation into \nreciprocating motion\n of a piston\n\n\n\n\n\n\nhttps://youtu.be/cPfPGh0yUos\n\n\nDifferential gearing demonstrated with lego\n\n\n\n\n\n\nhttps://youtu.be/9pjpQoZoW6E\n\n\nEV3 Print3rbot\n\n\n\n\n\n\nhttps://youtu.be/-tXY_Hf3fvU\n\n\nGopro 3 axis pan/tilt/slide\n\n\n\n\n\n\nhttps://youtu.be/qHQZcRPqUkY\n\n\nGreat Ball Contraption\n\n\n\n\n\n\nhttps://youtu.be/d7jXaffklVg\n\n\nLine Follower\n\n\n\n\n\n\nhttps://youtu.be/4xXCmw4Y5iA\n\n\nPlotter\n\n\n\n\n\n\nhttps://youtu.be/WG4FyoCjgdk\n\n\nRubik's Cube solver\n\n\n\n\n\n\nhttps://youtu.be/1Ihjh_F7jn0\n\n\nSpirograph\n\n\n\n\n\n\nhttps://youtu.be/59-osMTBQmY\n\n\nSpirograph\n\n\n\n\n\n\nhttps://youtu.be/9AI33m26KeM\n\n\nSpirograph\n\n\n\n\n\n\nhttps://youtu.be/mtbV47LTuz8\n\n\nSpirograph\n\n\n\n\n\n\nhttps://youtu.be/b5E-VyQOfNM\n\n\nSteampunk walking ship\n\n\n\n\n\n\nhttps://youtu.be/Mp8Y2yjV4fU\n\n\nSudoku solver\n\n\n\n\n\n\nhttps://youtu.be/qkhSj2cAKWg\n\n\nTelepresence\n\n\n\n\n\n\nhttps://youtu.be/A_mA72r3ZiQ\n\n\nTime Twister - mechanical digital clock\n\n\n\n\n\n\nhttps://youtu.be/O9Ha6cM0RjI\n\n\nTime Twister 3 - mechanical digital clock\n\n\n\n\n\n\nhttps://youtu.be/staapsj3eRQ\n\n\nWorld Record Rubik's Cube solver\n\n\n\n\n\n\n\n\nSee also\n\n\n\n\nRobotics",
            "title": "Lego mindstorms"
        },
        {
            "location": "/lego-mindstorms/#tips",
            "text": "ev3 programming software is available via  cask :  brew cask install lego-mindstorms-ev3",
            "title": "Tips"
        },
        {
            "location": "/lego-mindstorms/#links",
            "text": "http://www.lego.com/en-us/mindstorms  Community Gallery  - Robot designs from lego mindstorm community.  Robot Operating System for ev3  BUILD A ROBOT  - \"These robots give you the full EV3 experience, complete with building instructions, programming missions and the programming tool included in the new free EV3 Programmer App.\"  LEGO MINDSTORMS EV3 source code  BrickPi  - \"This project combines the brains of a Raspberry Pi with the brawn of a LEGO MINDSTORMS NXT\"  ev3dev  - \"ev3dev is a Debian Linux-based operating system that runs on several LEGO\u00ae MINDSTORMS compatible platforms including the LEGO\u00ae MINDSTORMS EV3 and Raspberry Pi-powered BrickPi.\"  http://botbench.com/  http://robotsquare.com/",
            "title": "Links"
        },
        {
            "location": "/lego-mindstorms/#videos",
            "text": "link  description      https://youtu.be/Ii4ElBLvp6Q  Active differential system for RWD traction control    https://youtu.be/t-c6ktfzwW0  Arm robot    https://youtu.be/961IdKfa5rI  Arm robot - 3 axis, 360 degree motion, lightweight    https://youtu.be/yAtmdyyIRbE  Arm robot on treads    https://youtu.be/P6b60zf1g18  BALANC3R and Gyro Boy, self balancing Segway style bots    https://youtu.be/zR4BKgj9WSc  Brick2014 EV3 6-Axis Robot Arm    https://youtu.be/2zbBCmNoaXs  BrickPi walkthrough    https://youtu.be/cETV5WGB6kQ  Bridge layer    https://youtu.be/bFgO-C2TAV8  Clash of Clans player    https://youtu.be/np3qWZVyvIU  Coin sorter    https://youtu.be/oUJ4L4kmbHw  Complicated bridge layer    https://youtu.be/GOQENxeL4nY  Convert rotation into  reciprocating motion  of a piston    https://youtu.be/cPfPGh0yUos  Differential gearing demonstrated with lego    https://youtu.be/9pjpQoZoW6E  EV3 Print3rbot    https://youtu.be/-tXY_Hf3fvU  Gopro 3 axis pan/tilt/slide    https://youtu.be/qHQZcRPqUkY  Great Ball Contraption    https://youtu.be/d7jXaffklVg  Line Follower    https://youtu.be/4xXCmw4Y5iA  Plotter    https://youtu.be/WG4FyoCjgdk  Rubik's Cube solver    https://youtu.be/1Ihjh_F7jn0  Spirograph    https://youtu.be/59-osMTBQmY  Spirograph    https://youtu.be/9AI33m26KeM  Spirograph    https://youtu.be/mtbV47LTuz8  Spirograph    https://youtu.be/b5E-VyQOfNM  Steampunk walking ship    https://youtu.be/Mp8Y2yjV4fU  Sudoku solver    https://youtu.be/qkhSj2cAKWg  Telepresence    https://youtu.be/A_mA72r3ZiQ  Time Twister - mechanical digital clock    https://youtu.be/O9Ha6cM0RjI  Time Twister 3 - mechanical digital clock    https://youtu.be/staapsj3eRQ  World Record Rubik's Cube solver",
            "title": "Videos"
        },
        {
            "location": "/lego-mindstorms/#see-also",
            "text": "Robotics",
            "title": "See also"
        },
        {
            "location": "/linksys/",
            "text": "Linksys makes a variety of networking devices. They are owned by Cisco.\n\n\nea3500\n\n\n\n\nhttp://www.linksys.com/us/support-product?pid=01t80000003K7bbAAC\n\n\n\n\n1.1.40.162464\n\n\n\n\nBug where if 5ghz is enabled, 2.4ghz sometimes will not be accessible. Only workaround is to use only 2.4ghz or 5ghz, not both. Even then sometimes the configs can end up in a funky state where neither will work, and you have to re-configure the wifi settings using wired ethernet.",
            "title": "Linksys"
        },
        {
            "location": "/linksys/#ea3500",
            "text": "http://www.linksys.com/us/support-product?pid=01t80000003K7bbAAC",
            "title": "ea3500"
        },
        {
            "location": "/linksys/#1140162464",
            "text": "Bug where if 5ghz is enabled, 2.4ghz sometimes will not be accessible. Only workaround is to use only 2.4ghz or 5ghz, not both. Even then sometimes the configs can end up in a funky state where neither will work, and you have to re-configure the wifi settings using wired ethernet.",
            "title": "1.1.40.162464"
        },
        {
            "location": "/linux-performance-monitoring/",
            "text": "Notes from the Linux Performance Monitoring talk at Velocity 2015 - \nPart 1\n, \nPart 2\n\n\nhttp://www.brendangregg.com/linuxperf.html\n\n\nUSE\n\n\n\n\nUtilization\n\n\nSaturation\n\n\nErrors\n\n\n\n\nObservability Tools\n\n\n\n\natop (atop uses the linux kernel event interface rather than sampling on screen updates, so it is better for viewing systems affected by short-lived processes)\n\n\nhtop\n\n\nvmstat -Sm 1\n\n\niostat -xmdz 1\n\n\nmpstat -P ALL 1\n\n\nfree -m\n\n\nsar -n DEV 1\n\n\nstrace -tttT # very disruptive of system performance, slows system significantly\n\n\ntcpdump\n\n\npidstat -t 1\n\n\npidstat -d\n\n\nswapon -s\n\n\nlsof\n\n\nsar -n TCP,ETCP,DEV 1\n\n\ncollectl\n\n\ndstat\n\n\nstrace 2>&1 | head -n 100 # since there's no strace -c N\n\n\nss\n\n\niptraf\n\n\nslabtop\n\n\npcstat\n\n\nperf\n\n\ntiptop\n\n\nrdmsr\n\n\nperf-tools/execsnoop\n\n\n\n\nBenchmarking tools\n\n\n\n\nunixbench\n\n\nimbench\n\n\nsysbench\n\n\nlmbench\n\n\nfio\n\n\npchar\n\n\niperf\n\n\n\n\nTuning tools\n\n\n\n\nsysctl\n\n\nulimit\n\n\nchcpu\n\n\n\n\nStatic tools\n\n\nTracing\n\n\n\n\nftrace\n\n\niosnoop\n\n\niolatency\n\n\nopensnoop\n\n\ntpoint\n\n\nfunccount\n\n\nfuncgraph\n\n\nkprobe\n\n\nbytehist\n\n\nstap",
            "title": "Linux performance monitoring"
        },
        {
            "location": "/linux-performance-monitoring/#use",
            "text": "Utilization  Saturation  Errors",
            "title": "USE"
        },
        {
            "location": "/linux-performance-monitoring/#observability-tools",
            "text": "atop (atop uses the linux kernel event interface rather than sampling on screen updates, so it is better for viewing systems affected by short-lived processes)  htop  vmstat -Sm 1  iostat -xmdz 1  mpstat -P ALL 1  free -m  sar -n DEV 1  strace -tttT # very disruptive of system performance, slows system significantly  tcpdump  pidstat -t 1  pidstat -d  swapon -s  lsof  sar -n TCP,ETCP,DEV 1  collectl  dstat  strace 2>&1 | head -n 100 # since there's no strace -c N  ss  iptraf  slabtop  pcstat  perf  tiptop  rdmsr  perf-tools/execsnoop",
            "title": "Observability Tools"
        },
        {
            "location": "/linux-performance-monitoring/#benchmarking-tools",
            "text": "unixbench  imbench  sysbench  lmbench  fio  pchar  iperf",
            "title": "Benchmarking tools"
        },
        {
            "location": "/linux-performance-monitoring/#tuning-tools",
            "text": "sysctl  ulimit  chcpu",
            "title": "Tuning tools"
        },
        {
            "location": "/linux-performance-monitoring/#static-tools",
            "text": "",
            "title": "Static tools"
        },
        {
            "location": "/linux-performance-monitoring/#tracing",
            "text": "ftrace  iosnoop  iolatency  opensnoop  tpoint  funccount  funcgraph  kprobe  bytehist  stap",
            "title": "Tracing"
        },
        {
            "location": "/linux/",
            "text": "\"Linux is a family of free and open-source software operating systems built around the Linux kernel.\" - \nhttps://en.wikipedia.org/wiki/Linux\n\n\nMost linux distros are built on GNU tools, and this article is relevant in distinguishing the importance GNU plays in the linux ecosystem: \nhttps://www.gnu.org/gnu/why-gnu-linux.en.html\n\n\nPerformance monitoring\n\n\n\n\nLinux Load Averages: Solving the Mystery\n\n\nBrendan Gregg's Linux Performance page\n\n\nNotes from the Linux Performance Monitoring talk at Velocity 2015\n\n\n\n\nTricks\n\n\nConfigure a system to reboot on kernel panic\n\n\nThese lines should be added to \nsysctl.conf\n\n\n#\u00a0Reboot\u00a0after\u00a010\u00a0seconds\u00a0if\u00a0kernel\u00a0panics\nkernel.panic\u00a0=\u00a010  \n#\u00a0Treat\u00a0all\u00a0oopses\u00a0as\u00a0panics  \nkernel.panic_on_oops\u00a0=\u00a01\n\n\n\n\nForce reboot on corrupt system\n\n\nFor times that commands like \nreboot\n and \nshutdown\n are not available.\n\n\necho\u00a01\u00a0>\u00a0/proc/sys/kernel/sysrq\necho\u00a0b\u00a0>\u00a0/proc/sysrq-trigger\n\n\n\n\nSee also\n\n\n\n\nlxc\n\n\n\n\nDistros\n\n\n\n\nrhel\n\n\nubuntu\n\n\n\n\nInit systems\n\n\n\n\nsystemd\n\n\nupstart\n\n\n\n\nFilesystems\n\n\n\n\nFilesystem Heirarchy Standards: \nhttp://www.pathname.com/fhs/pub/fhs-2.3.html\n\n\nLVM\n\n\nZFS",
            "title": "Linux"
        },
        {
            "location": "/linux/#performance-monitoring",
            "text": "Linux Load Averages: Solving the Mystery  Brendan Gregg's Linux Performance page  Notes from the Linux Performance Monitoring talk at Velocity 2015",
            "title": "Performance monitoring"
        },
        {
            "location": "/linux/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/linux/#configure-a-system-to-reboot-on-kernel-panic",
            "text": "These lines should be added to  sysctl.conf  #\u00a0Reboot\u00a0after\u00a010\u00a0seconds\u00a0if\u00a0kernel\u00a0panics\nkernel.panic\u00a0=\u00a010  \n#\u00a0Treat\u00a0all\u00a0oopses\u00a0as\u00a0panics  \nkernel.panic_on_oops\u00a0=\u00a01",
            "title": "Configure a system to reboot on kernel panic"
        },
        {
            "location": "/linux/#force-reboot-on-corrupt-system",
            "text": "For times that commands like  reboot  and  shutdown  are not available.  echo\u00a01\u00a0>\u00a0/proc/sys/kernel/sysrq\necho\u00a0b\u00a0>\u00a0/proc/sysrq-trigger",
            "title": "Force reboot on corrupt system"
        },
        {
            "location": "/linux/#see-also",
            "text": "lxc",
            "title": "See also"
        },
        {
            "location": "/linux/#distros",
            "text": "rhel  ubuntu",
            "title": "Distros"
        },
        {
            "location": "/linux/#init-systems",
            "text": "systemd  upstart",
            "title": "Init systems"
        },
        {
            "location": "/linux/#filesystems",
            "text": "Filesystem Heirarchy Standards:  http://www.pathname.com/fhs/pub/fhs-2.3.html  LVM  ZFS",
            "title": "Filesystems"
        },
        {
            "location": "/lsblk/",
            "text": "\"lsblk  lists information about all available or the specified block devices.  The lsblk command reads the sysfs filesystem and udev db to gather information.\" - \nman lsblkq\n\n\nExamples\n\n\nSimple usage\n\n\nHere is the output of \nlsblk\n on an \nUbuntu\n 16.04 \nVagrant\n box:\n\n\n$ lsblk\nNAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\nsda      8:0    0  10G  0 disk\n\u2514\u2500sda1   8:1    0  10G  0 part /\nsdb      8:16   0  10M  0 disk\n\n\n\n\nShow filesystem information\n\n\n$ lsblk -f\nNAME   FSTYPE  LABEL           UUID                                 MOUNTPOINT\nsda\n\u2514\u2500sda1 ext4    cloudimg-rootfs 73ea38ed-7fcd-4871-8afa-17d36f4e4bfc /\nsdb    iso9660 cidata          2017-08-15-16-47-34-00\n\n\n\n\nShow all available information\n\n\nThe output here is really wide, but reformatting it through JSON makes it easier to read. Thankfully \nlsblk\n has a JSON output option, unlike many unix CLI tools.\n\n\n$ lsblk -O -J | jq .\n{\n  \"blockdevices\": [\n    {\n      \"name\": \"sda\",\n      \"kname\": \"sda\",\n      \"maj:min\": \"8:0\",\n      \"fstype\": null,\n      \"mountpoint\": null,\n      \"label\": null,\n      \"uuid\": null,\n      \"parttype\": null,\n      \"partlabel\": null,\n      \"partuuid\": null,\n      \"partflags\": null,\n      \"ra\": \"128\",\n      \"ro\": \"0\",\n      \"rm\": \"0\",\n      \"hotplug\": \"0\",\n      \"model\": \"HARDDISK        \",\n      \"serial\": null,\n      \"size\": \"10G\",\n      \"state\": \"running\",\n      \"owner\": \"root\",\n      \"group\": \"disk\",\n      \"mode\": \"brw-rw----\",\n      \"alignment\": \"0\",\n      \"min-io\": \"512\",\n      \"opt-io\": \"0\",\n      \"phy-sec\": \"512\",\n      \"log-sec\": \"512\",\n      \"rota\": \"1\",\n      \"sched\": \"deadline\",\n      \"rq-size\": \"128\",\n      \"type\": \"disk\",\n      \"disc-aln\": \"0\",\n      \"disc-gran\": \"0B\",\n      \"disc-max\": \"0B\",\n      \"disc-zero\": \"0\",\n      \"wsame\": \"0B\",\n      \"wwn\": null,\n      \"rand\": \"1\",\n      \"pkname\": null,\n      \"hctl\": \"2:0:0:0\",\n      \"tran\": \"spi\",\n      \"subsystems\": \"block:scsi:pci\",\n      \"rev\": \"1.0 \",\n      \"vendor\": \"VBOX    \",\n      \"children\": [\n        {\n          \"name\": \"sda1\",\n          \"kname\": \"sda1\",\n          \"maj:min\": \"8:1\",\n          \"fstype\": \"ext4\",\n          \"mountpoint\": \"/\",\n          \"label\": \"cloudimg-rootfs\",\n          \"uuid\": \"73ea38ed-7fcd-4871-8afa-17d36f4e4bfc\",\n          \"parttype\": \"0x83\",\n          \"partlabel\": null,\n          \"partuuid\": \"8d714561-01\",\n          \"partflags\": \"0x80\",\n          \"ra\": \"128\",\n          \"ro\": \"0\",\n          \"rm\": \"0\",\n          \"hotplug\": \"0\",\n          \"model\": null,\n          \"serial\": null,\n          \"size\": \"10G\",\n          \"state\": null,\n          \"owner\": \"root\",\n          \"group\": \"disk\",\n          \"mode\": \"brw-rw----\",\n          \"alignment\": \"0\",\n          \"min-io\": \"512\",\n          \"opt-io\": \"0\",\n          \"phy-sec\": \"512\",\n          \"log-sec\": \"512\",\n          \"rota\": \"1\",\n          \"sched\": \"deadline\",\n          \"rq-size\": \"128\",\n          \"type\": \"part\",\n          \"disc-aln\": \"0\",\n          \"disc-gran\": \"0B\",\n          \"disc-max\": \"0B\",\n          \"disc-zero\": \"0\",\n          \"wsame\": \"0B\",\n          \"wwn\": null,\n          \"rand\": \"1\",\n          \"pkname\": \"sda\",\n          \"hctl\": null,\n          \"tran\": null,\n          \"subsystems\": \"block:scsi:pci\",\n          \"rev\": null,\n          \"vendor\": null\n        }\n      ]\n    },\n    {\n      \"name\": \"sdb\",\n      \"kname\": \"sdb\",\n      \"maj:min\": \"8:16\",\n      \"fstype\": \"iso9660\",\n      \"mountpoint\": null,\n      \"label\": \"cidata\",\n      \"uuid\": \"2017-08-15-16-47-34-00\",\n      \"parttype\": null,\n      \"partlabel\": null,\n      \"partuuid\": null,\n      \"partflags\": null,\n      \"ra\": \"128\",\n      \"ro\": \"0\",\n      \"rm\": \"0\",\n      \"hotplug\": \"0\",\n      \"model\": \"HARDDISK        \",\n      \"serial\": null,\n      \"size\": \"10M\",\n      \"state\": \"running\",\n      \"owner\": \"root\",\n      \"group\": \"disk\",\n      \"mode\": \"brw-rw----\",\n      \"alignment\": \"0\",\n      \"min-io\": \"512\",\n      \"opt-io\": \"0\",\n      \"phy-sec\": \"512\",\n      \"log-sec\": \"512\",\n      \"rota\": \"1\",\n      \"sched\": \"deadline\",\n      \"rq-size\": \"128\",\n      \"type\": \"disk\",\n      \"disc-aln\": \"0\",\n      \"disc-gran\": \"0B\",\n      \"disc-max\": \"0B\",\n      \"disc-zero\": \"0\",\n      \"wsame\": \"32M\",\n      \"wwn\": null,\n      \"rand\": \"1\",\n      \"pkname\": null,\n      \"hctl\": \"2:0:1:0\",\n      \"tran\": \"spi\",\n      \"subsystems\": \"block:scsi:pci\",\n      \"rev\": \"1.0 \",\n      \"vendor\": \"VBOX    \"\n    }\n  ]\n}\n\n\n\n\nSee also\n\n\n\n\nfindmnt",
            "title": "Lsblk"
        },
        {
            "location": "/lsblk/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/lsblk/#simple-usage",
            "text": "Here is the output of  lsblk  on an  Ubuntu  16.04  Vagrant  box:  $ lsblk\nNAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\nsda      8:0    0  10G  0 disk\n\u2514\u2500sda1   8:1    0  10G  0 part /\nsdb      8:16   0  10M  0 disk",
            "title": "Simple usage"
        },
        {
            "location": "/lsblk/#show-filesystem-information",
            "text": "$ lsblk -f\nNAME   FSTYPE  LABEL           UUID                                 MOUNTPOINT\nsda\n\u2514\u2500sda1 ext4    cloudimg-rootfs 73ea38ed-7fcd-4871-8afa-17d36f4e4bfc /\nsdb    iso9660 cidata          2017-08-15-16-47-34-00",
            "title": "Show filesystem information"
        },
        {
            "location": "/lsblk/#show-all-available-information",
            "text": "The output here is really wide, but reformatting it through JSON makes it easier to read. Thankfully  lsblk  has a JSON output option, unlike many unix CLI tools.  $ lsblk -O -J | jq .\n{\n  \"blockdevices\": [\n    {\n      \"name\": \"sda\",\n      \"kname\": \"sda\",\n      \"maj:min\": \"8:0\",\n      \"fstype\": null,\n      \"mountpoint\": null,\n      \"label\": null,\n      \"uuid\": null,\n      \"parttype\": null,\n      \"partlabel\": null,\n      \"partuuid\": null,\n      \"partflags\": null,\n      \"ra\": \"128\",\n      \"ro\": \"0\",\n      \"rm\": \"0\",\n      \"hotplug\": \"0\",\n      \"model\": \"HARDDISK        \",\n      \"serial\": null,\n      \"size\": \"10G\",\n      \"state\": \"running\",\n      \"owner\": \"root\",\n      \"group\": \"disk\",\n      \"mode\": \"brw-rw----\",\n      \"alignment\": \"0\",\n      \"min-io\": \"512\",\n      \"opt-io\": \"0\",\n      \"phy-sec\": \"512\",\n      \"log-sec\": \"512\",\n      \"rota\": \"1\",\n      \"sched\": \"deadline\",\n      \"rq-size\": \"128\",\n      \"type\": \"disk\",\n      \"disc-aln\": \"0\",\n      \"disc-gran\": \"0B\",\n      \"disc-max\": \"0B\",\n      \"disc-zero\": \"0\",\n      \"wsame\": \"0B\",\n      \"wwn\": null,\n      \"rand\": \"1\",\n      \"pkname\": null,\n      \"hctl\": \"2:0:0:0\",\n      \"tran\": \"spi\",\n      \"subsystems\": \"block:scsi:pci\",\n      \"rev\": \"1.0 \",\n      \"vendor\": \"VBOX    \",\n      \"children\": [\n        {\n          \"name\": \"sda1\",\n          \"kname\": \"sda1\",\n          \"maj:min\": \"8:1\",\n          \"fstype\": \"ext4\",\n          \"mountpoint\": \"/\",\n          \"label\": \"cloudimg-rootfs\",\n          \"uuid\": \"73ea38ed-7fcd-4871-8afa-17d36f4e4bfc\",\n          \"parttype\": \"0x83\",\n          \"partlabel\": null,\n          \"partuuid\": \"8d714561-01\",\n          \"partflags\": \"0x80\",\n          \"ra\": \"128\",\n          \"ro\": \"0\",\n          \"rm\": \"0\",\n          \"hotplug\": \"0\",\n          \"model\": null,\n          \"serial\": null,\n          \"size\": \"10G\",\n          \"state\": null,\n          \"owner\": \"root\",\n          \"group\": \"disk\",\n          \"mode\": \"brw-rw----\",\n          \"alignment\": \"0\",\n          \"min-io\": \"512\",\n          \"opt-io\": \"0\",\n          \"phy-sec\": \"512\",\n          \"log-sec\": \"512\",\n          \"rota\": \"1\",\n          \"sched\": \"deadline\",\n          \"rq-size\": \"128\",\n          \"type\": \"part\",\n          \"disc-aln\": \"0\",\n          \"disc-gran\": \"0B\",\n          \"disc-max\": \"0B\",\n          \"disc-zero\": \"0\",\n          \"wsame\": \"0B\",\n          \"wwn\": null,\n          \"rand\": \"1\",\n          \"pkname\": \"sda\",\n          \"hctl\": null,\n          \"tran\": null,\n          \"subsystems\": \"block:scsi:pci\",\n          \"rev\": null,\n          \"vendor\": null\n        }\n      ]\n    },\n    {\n      \"name\": \"sdb\",\n      \"kname\": \"sdb\",\n      \"maj:min\": \"8:16\",\n      \"fstype\": \"iso9660\",\n      \"mountpoint\": null,\n      \"label\": \"cidata\",\n      \"uuid\": \"2017-08-15-16-47-34-00\",\n      \"parttype\": null,\n      \"partlabel\": null,\n      \"partuuid\": null,\n      \"partflags\": null,\n      \"ra\": \"128\",\n      \"ro\": \"0\",\n      \"rm\": \"0\",\n      \"hotplug\": \"0\",\n      \"model\": \"HARDDISK        \",\n      \"serial\": null,\n      \"size\": \"10M\",\n      \"state\": \"running\",\n      \"owner\": \"root\",\n      \"group\": \"disk\",\n      \"mode\": \"brw-rw----\",\n      \"alignment\": \"0\",\n      \"min-io\": \"512\",\n      \"opt-io\": \"0\",\n      \"phy-sec\": \"512\",\n      \"log-sec\": \"512\",\n      \"rota\": \"1\",\n      \"sched\": \"deadline\",\n      \"rq-size\": \"128\",\n      \"type\": \"disk\",\n      \"disc-aln\": \"0\",\n      \"disc-gran\": \"0B\",\n      \"disc-max\": \"0B\",\n      \"disc-zero\": \"0\",\n      \"wsame\": \"32M\",\n      \"wwn\": null,\n      \"rand\": \"1\",\n      \"pkname\": null,\n      \"hctl\": \"2:0:1:0\",\n      \"tran\": \"spi\",\n      \"subsystems\": \"block:scsi:pci\",\n      \"rev\": \"1.0 \",\n      \"vendor\": \"VBOX    \"\n    }\n  ]\n}",
            "title": "Show all available information"
        },
        {
            "location": "/lsblk/#see-also",
            "text": "findmnt",
            "title": "See also"
        },
        {
            "location": "/lsof/",
            "text": "lsof lists open files. This CLI tool is available on most *nix OSes.\n\n\nExamples\n\n\nList files open by a given user\n\n\nlsof -u username\n\n\n\n\nshow listening TCP sockets\n\n\nSince everything in unix is a file, including network sockets, you can list open sockets and the programs that have them open. However, this is notably unreliable in Docker, so don't trust this completely. When in doubt, double check against \nss -l\n.\n\n\nlsof -iTCP -sTCP:LISTEN\n\n\n\n\nShow a sorted list of processes by listening port\n\n\nlsof -iTCP -sTCP:LISTEN -P | sort -k2 -t: -n\n\n\n\n\nshow what process is using port 80 or 443 with port numbers\n\n\n# -n makes lsof not resolve hostnames from ip addresses\n# -P makes lsof not resolve service names for port numbers.\n# -iTCP shows IP TCP sockets.\n\nlsof -nP -iTCP:80,443\n\n\n\n\nshow the selinux context for sockets\n\n\nlsof -i -Z\n\n\n\n\nSee man page for extended syntax around Z\n\n\nSee Also\n\n\n\n\nProcess Explorer - LSOF type functionality for windows.",
            "title": "Lsof"
        },
        {
            "location": "/lsof/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/lsof/#list-files-open-by-a-given-user",
            "text": "lsof -u username",
            "title": "List files open by a given user"
        },
        {
            "location": "/lsof/#show-listening-tcp-sockets",
            "text": "Since everything in unix is a file, including network sockets, you can list open sockets and the programs that have them open. However, this is notably unreliable in Docker, so don't trust this completely. When in doubt, double check against  ss -l .  lsof -iTCP -sTCP:LISTEN",
            "title": "show listening TCP sockets"
        },
        {
            "location": "/lsof/#show-a-sorted-list-of-processes-by-listening-port",
            "text": "lsof -iTCP -sTCP:LISTEN -P | sort -k2 -t: -n",
            "title": "Show a sorted list of processes by listening port"
        },
        {
            "location": "/lsof/#show-what-process-is-using-port-80-or-443-with-port-numbers",
            "text": "# -n makes lsof not resolve hostnames from ip addresses\n# -P makes lsof not resolve service names for port numbers.\n# -iTCP shows IP TCP sockets.\n\nlsof -nP -iTCP:80,443",
            "title": "show what process is using port 80 or 443 with port numbers"
        },
        {
            "location": "/lsof/#show-the-selinux-context-for-sockets",
            "text": "lsof -i -Z  See man page for extended syntax around Z",
            "title": "show the selinux context for sockets"
        },
        {
            "location": "/lsof/#see-also",
            "text": "Process Explorer - LSOF type functionality for windows.",
            "title": "See Also"
        },
        {
            "location": "/lvm/",
            "text": "Linux Logical Volume Manager.\n\n\n\n\nTutorial\n\n\nOverview\n\n\nManaging\n\n\n\n\nGeneral flow\n\n\nPhysical volumes (pv) are grouped into volume groups (vg). Volume groups are sliced up into logical volumes (lv). Because of that, the general flow is something like:\n\n\n# Partitioning is not necessary, so no need for fdisk or sgdisk\npvcreate /dev/sd{x..z}\nvgcreate vg_scratch /dev/sd{x..z}\nlvcreate -l 95%FREE -n lv_scratch vg_scratch\nmkfs.ext4 /dev/vg_scratch/lv_scratch\n\n\n\n\nExamples\n\n\nShow a bunch of info\n\n\npvdisplay -v\npvs -v\npvs -a\npvs --segments\nvgdisplay -v\nvgs -v\nvgs -a -o +devices\n\n\n\n\nShow system disks and if they are in an LVM\n\n\nlvmdiskscan\n\n\nShow all logical volumes\n\n\nlvs\n\n\nActivate all volume groups\n\n\nvgchange -a y\n\n\nCreate a physical volume\n\n\nphysical volumes are groups of physical disks that can be used to create logical volumes\n\n\npvcreate pv_name /dev/sdb2 /dev/sdc2\n\n\nCreate a logical volume\n\n\nThis creates a specifically named logical volume on a volume group named vg_data\n\n\nlvcreate -L 10G -n lv_name vg_data\n\n\nShow how each logical volume is set up\n\n\nlvdisplay\n\n\nShow free extents\n\n\nvgs -o vg_free_count\n\n\nExtend a volume group to 1TB\n\n\nlvextend -L 1T /dev/vgroot/lv_srv && \\\nresize2fs /dev/mapper/vgroot-lv_srv && \\\ndf -h /srv\n\n\n\n\nExtend a volume group to its max\n\n\nlvextend -l +100%FREE /dev/vgroot/lv_srv && \\\nresize2fs /dev/mapper/vgroot-lv_srv && \\\ndf -h /srv",
            "title": "Lvm"
        },
        {
            "location": "/lvm/#general-flow",
            "text": "Physical volumes (pv) are grouped into volume groups (vg). Volume groups are sliced up into logical volumes (lv). Because of that, the general flow is something like:  # Partitioning is not necessary, so no need for fdisk or sgdisk\npvcreate /dev/sd{x..z}\nvgcreate vg_scratch /dev/sd{x..z}\nlvcreate -l 95%FREE -n lv_scratch vg_scratch\nmkfs.ext4 /dev/vg_scratch/lv_scratch",
            "title": "General flow"
        },
        {
            "location": "/lvm/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/lvm/#show-a-bunch-of-info",
            "text": "pvdisplay -v\npvs -v\npvs -a\npvs --segments\nvgdisplay -v\nvgs -v\nvgs -a -o +devices",
            "title": "Show a bunch of info"
        },
        {
            "location": "/lvm/#show-system-disks-and-if-they-are-in-an-lvm",
            "text": "lvmdiskscan",
            "title": "Show system disks and if they are in an LVM"
        },
        {
            "location": "/lvm/#show-all-logical-volumes",
            "text": "lvs",
            "title": "Show all logical volumes"
        },
        {
            "location": "/lvm/#activate-all-volume-groups",
            "text": "vgchange -a y",
            "title": "Activate all volume groups"
        },
        {
            "location": "/lvm/#create-a-physical-volume",
            "text": "physical volumes are groups of physical disks that can be used to create logical volumes  pvcreate pv_name /dev/sdb2 /dev/sdc2",
            "title": "Create a physical volume"
        },
        {
            "location": "/lvm/#create-a-logical-volume",
            "text": "This creates a specifically named logical volume on a volume group named vg_data  lvcreate -L 10G -n lv_name vg_data",
            "title": "Create a logical volume"
        },
        {
            "location": "/lvm/#show-how-each-logical-volume-is-set-up",
            "text": "lvdisplay",
            "title": "Show how each logical volume is set up"
        },
        {
            "location": "/lvm/#show-free-extents",
            "text": "vgs -o vg_free_count",
            "title": "Show free extents"
        },
        {
            "location": "/lvm/#extend-a-volume-group-to-1tb",
            "text": "lvextend -L 1T /dev/vgroot/lv_srv && \\\nresize2fs /dev/mapper/vgroot-lv_srv && \\\ndf -h /srv",
            "title": "Extend a volume group to 1TB"
        },
        {
            "location": "/lvm/#extend-a-volume-group-to-its-max",
            "text": "lvextend -l +100%FREE /dev/vgroot/lv_srv && \\\nresize2fs /dev/mapper/vgroot-lv_srv && \\\ndf -h /srv",
            "title": "Extend a volume group to its max"
        },
        {
            "location": "/lxc/",
            "text": "\"LXC is a userspace interface for the Linux kernel containment features. Through a powerful API and simple tools, it lets Linux users easily create and manage system or application containers.\" - \nhttps://linuxcontainers.org\n \n\n\nSee Also\n\n\n\n\nDocker",
            "title": "Lxc"
        },
        {
            "location": "/lxc/#see-also",
            "text": "Docker",
            "title": "See Also"
        },
        {
            "location": "/machine-learning/",
            "text": "Machine learning is the subfield of computer science that, according to Arthur Samuel in 1959, gives \"computers the ability to learn without being explicitly programmed.\" - \nhttps://en.wikipedia.org/wiki/Machine_learning\n\n\nTerminology and concepts\n\n\n\n\nSupervised machine learning: The program is \"trained\" on a pre-defined set of \"training examples\", which then facilitate its ability to reach an accurate conclusion when given new data.\n\n\nUnsupervised machine learning: The program is given a bunch of data and must find patterns and relationships therein.\n\n\n\"The goal of ML is never to make 'perfect' guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful.\"\n\n\nMachine learning builds heavily on statistics.\n\n\n\n\nPrerequisites\n\n\n\n\nStatistics\n\n\nLinear Algebra\n\n\nCalculus\n\n\n\n\nResources\n\n\n\n\nReddit /r/machinelearning wiki\n\n\nData Science From Scratch book\n\n\nAndrew Ng's Coursera course on ML\n\n\nMachine Learning with Python\n / \nPractical Machine Learning Tutorial with Python Introduction\n\n\nYour First Machine Learning Project in Python Step-By-Step\n\n\nExample Machine Learning IPython Notebook\n\n\nFastML: Machine Learning Made Easy\n\n\nTensorflow\n\n\nMy Neural Network isn't working! What should I do?\n\n\nMachine Learning Recipes with Josh Gordon - Google Developers\n\n\n\n\nSee Also\n\n\n\n\nLife 3.0: Being Human in the Age of Artificial Intelligence: \nhttps://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598\n\n\nDeepMind and Blizzard open StarCraft II as an AI research environment",
            "title": "Machine learning"
        },
        {
            "location": "/machine-learning/#terminology-and-concepts",
            "text": "Supervised machine learning: The program is \"trained\" on a pre-defined set of \"training examples\", which then facilitate its ability to reach an accurate conclusion when given new data.  Unsupervised machine learning: The program is given a bunch of data and must find patterns and relationships therein.  \"The goal of ML is never to make 'perfect' guesses, because ML deals in domains where there is no such thing. The goal is to make guesses that are good enough to be useful.\"  Machine learning builds heavily on statistics.",
            "title": "Terminology and concepts"
        },
        {
            "location": "/machine-learning/#prerequisites",
            "text": "Statistics  Linear Algebra  Calculus",
            "title": "Prerequisites"
        },
        {
            "location": "/machine-learning/#resources",
            "text": "Reddit /r/machinelearning wiki  Data Science From Scratch book  Andrew Ng's Coursera course on ML  Machine Learning with Python  /  Practical Machine Learning Tutorial with Python Introduction  Your First Machine Learning Project in Python Step-By-Step  Example Machine Learning IPython Notebook  FastML: Machine Learning Made Easy  Tensorflow  My Neural Network isn't working! What should I do?  Machine Learning Recipes with Josh Gordon - Google Developers",
            "title": "Resources"
        },
        {
            "location": "/machine-learning/#see-also",
            "text": "Life 3.0: Being Human in the Age of Artificial Intelligence:  https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598  DeepMind and Blizzard open StarCraft II as an AI research environment",
            "title": "See Also"
        },
        {
            "location": "/make/",
            "text": "GNU make\n\n\nAutomatic variables\n\n\n$ cat Makefile\nall: foo_one foo_two\n\nfoo_%: bar_a bar_b\n    echo $*: this is $@ and it requires $^\n\nbar_%: baz\n    echo $*: this is $@ and it requires $^\n\nbaz:\n    echo this is baz\n\n$ make\necho this is baz\nthis is baz\necho a: this is bar_a and it requires baz\na: this is bar_a and it requires baz\necho b: this is bar_b and it requires baz\nb: this is bar_b and it requires baz\necho one: this is foo_one and it requires bar_a bar_b\none: this is foo_one and it requires bar_a bar_b\necho two: this is foo_two and it requires bar_a bar_b\ntwo: this is foo_two and it requires bar_a bar_b\n\n\n\n\nLinks\n\n\n\n\nhttps://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html\n\n\nhttps://www.gnu.org/software/make/manual/html_node/Standard-Targets.html",
            "title": "Make"
        },
        {
            "location": "/make/#automatic-variables",
            "text": "$ cat Makefile\nall: foo_one foo_two\n\nfoo_%: bar_a bar_b\n    echo $*: this is $@ and it requires $^\n\nbar_%: baz\n    echo $*: this is $@ and it requires $^\n\nbaz:\n    echo this is baz\n\n$ make\necho this is baz\nthis is baz\necho a: this is bar_a and it requires baz\na: this is bar_a and it requires baz\necho b: this is bar_b and it requires baz\nb: this is bar_b and it requires baz\necho one: this is foo_one and it requires bar_a bar_b\none: this is foo_one and it requires bar_a bar_b\necho two: this is foo_two and it requires bar_a bar_b\ntwo: this is foo_two and it requires bar_a bar_b",
            "title": "Automatic variables"
        },
        {
            "location": "/make/#links",
            "text": "https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html  https://www.gnu.org/software/make/manual/html_node/Standard-Targets.html",
            "title": "Links"
        },
        {
            "location": "/mdraid/",
            "text": "Linux software raid.\n\n\nExamples\n\n\nShow details of an array\n\n\nmdadm --detail /dev/md0\n\n\n\n\nLinks\n\n\n\n\nhttp://poweredgec.dell.com/\n - the Dell \nldstate\n command is a good view into software raid and hardware raid (eg: megaraid, sas2) under one command.\n\n\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/5/html/Deployment_Guide/s2-raid-manage-removing.html\n\n\nhttp://tldp.org/HOWTO/Software-RAID-HOWTO.html\n\n\nhttps://raid.wiki.kernel.org/index.php/Linux_Raid\n\n\nhttps://raid.wiki.kernel.org/index.php/RAID_setup",
            "title": "Mdraid"
        },
        {
            "location": "/mdraid/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/mdraid/#show-details-of-an-array",
            "text": "mdadm --detail /dev/md0",
            "title": "Show details of an array"
        },
        {
            "location": "/mdraid/#links",
            "text": "http://poweredgec.dell.com/  - the Dell  ldstate  command is a good view into software raid and hardware raid (eg: megaraid, sas2) under one command.  https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/5/html/Deployment_Guide/s2-raid-manage-removing.html  http://tldp.org/HOWTO/Software-RAID-HOWTO.html  https://raid.wiki.kernel.org/index.php/Linux_Raid  https://raid.wiki.kernel.org/index.php/RAID_setup",
            "title": "Links"
        },
        {
            "location": "/micropython/",
            "text": "\"MicroPython is a lean and efficient implementation of the Python 3 programming language that includes a small subset of the Python standard library and is optimised to run on microcontrollers and in constrained environments.\"- \nhttps://micropython.org\n\n\nhttps://docs.micropython.org\n\n\nHardware\n\n\n\n\nESP8266\n\n\npyboard\n\n\nArduino Due\n\n\nmicrobit\n\n\n\n\nSee also\n\n\n\n\nTalkPython.fm Episode #108: MicroPython and Open Source Hardware at Adafruit",
            "title": "Micropython"
        },
        {
            "location": "/micropython/#hardware",
            "text": "ESP8266  pyboard  Arduino Due  microbit",
            "title": "Hardware"
        },
        {
            "location": "/micropython/#see-also",
            "text": "TalkPython.fm Episode #108: MicroPython and Open Source Hardware at Adafruit",
            "title": "See also"
        },
        {
            "location": "/mqtt/",
            "text": "'MQTT is a machine-to-machine (M2M)/\"Internet of Things\" connectivity protocol.' - \nhttp://mqtt.org/",
            "title": "Mqtt"
        },
        {
            "location": "/mutt/",
            "text": "CLI e-mail client\n\n\nUsage\n\n\nhttp://www.mutt.org/doc/manual/manual-2.html\n\n\nj or Down       next-entry      move to the next entry\nk or Up         previous-entry  move to the previous entry\nz or PageDn     page-down       go to the next page\nZ or PageUp     page-up         go to the previous page\n= or Home       first-entry     jump to the first entry\n* or End        last-entry      jump to the last entry\nq               quit            exit the current menu\n?               help            list all keybindings for the current menu\n\n\n\n\nMessage Deletion\n\n\nhttp://www.sendmail.org/~ca/email/mutt/manual-4.html\n\n\n\n\nDelete e-mails older than 2012-12-01: \n[shift-d] ~d 1/12/12-1/1/1 # D/M/Y. this will only delete back to 2001-01-01\n\n\nDelete messages where the subject matches a search: \n[shift-d] ~b search\\ pattern\n\n\nDelete messages where the subject matches a search: \n[shift-d] ~s search\\ pattern\n\n\nDelete messages older than one month: \n[shift-d] ~d >1m\n\n\nDelete messages older than 14 days: \n[shift-d] ~d > 14d",
            "title": "Mutt"
        },
        {
            "location": "/mutt/#usage",
            "text": "http://www.mutt.org/doc/manual/manual-2.html  j or Down       next-entry      move to the next entry\nk or Up         previous-entry  move to the previous entry\nz or PageDn     page-down       go to the next page\nZ or PageUp     page-up         go to the previous page\n= or Home       first-entry     jump to the first entry\n* or End        last-entry      jump to the last entry\nq               quit            exit the current menu\n?               help            list all keybindings for the current menu",
            "title": "Usage"
        },
        {
            "location": "/mutt/#message-deletion",
            "text": "http://www.sendmail.org/~ca/email/mutt/manual-4.html   Delete e-mails older than 2012-12-01:  [shift-d] ~d 1/12/12-1/1/1 # D/M/Y. this will only delete back to 2001-01-01  Delete messages where the subject matches a search:  [shift-d] ~b search\\ pattern  Delete messages where the subject matches a search:  [shift-d] ~s search\\ pattern  Delete messages older than one month:  [shift-d] ~d >1m  Delete messages older than 14 days:  [shift-d] ~d > 14d",
            "title": "Message Deletion"
        },
        {
            "location": "/myrepos/",
            "text": "\"You have a lot of version control repositories. Sometimes you want to update them all at once. Or push out all your local changes. You use special command lines in some repositories to implement specific workflows. Myrepos provides a mr command, which is a tool to manage all your version control repositories.\" -- \nhttp://myrepos.branchable.com/\n\n\nUsage Examples\n\n\nRegister a bunch of repos\n\n\nfor repo in ~/code/* ; do\n  mr register \"$repo\"\ndone\n\n\n\n\nUpdate all of your registered repos\n\n\nmr up",
            "title": "Myrepos"
        },
        {
            "location": "/myrepos/#usage-examples",
            "text": "",
            "title": "Usage Examples"
        },
        {
            "location": "/myrepos/#register-a-bunch-of-repos",
            "text": "for repo in ~/code/* ; do\n  mr register \"$repo\"\ndone",
            "title": "Register a bunch of repos"
        },
        {
            "location": "/myrepos/#update-all-of-your-registered-repos",
            "text": "mr up",
            "title": "Update all of your registered repos"
        },
        {
            "location": "/mysql/",
            "text": "MySQL\n\n\n\"MySQL is an open-source relational database management system. Its name is a combination of \"My\", the name of co-founder Michael Widenius's daughter, and \"SQL\", the abbreviation for Structured Query Language. The MySQL development project has made its source code available under the terms of the GNU General Public License, as well as under a variety of proprietary agreements. MySQL was owned and sponsored by a single for-profit firm, the Swedish company MySQL AB, and is now owned by Oracle Corporation.\" - \nhttps://en.wikipedia.org/wiki/MySQL\n\n\nExamples\n\n\nShow variables of the running server\n\n\nmysqladmin variables\n\n\n\n\nEnable bin logging\n\n\nEdit /etc/my.cnf:\n\n\nlog-bin=/var/lib/mysql/mysql-bin\n\n\n\n\nShow how a table was created\n\n\nSHOW CREATE TABLE table_name \\G\n\n\n\n\nCreate a table\n\n\nCREATE TABLE photo_sizes (\n  `photo_id` char(32) NOT NULL,\n  `format` mediumtext,\n  `width` mediumtext,\n  `height` mediumtext,\n  `source` mediumtext,\n  `url` mediumtext,\n  PRIMARY KEY(`photo_id`)\n) ;\n\n\n\n\nCreate a table with multiple columns as the primary key\n\n\nCREATE TABLE `photo_sizes` (\n  `photo_id` char(32) NOT NULL,\n  `format` char(32) NOT NULL DEFAULT '',\n  `width` mediumtext,\n  `height` mediumtext,\n  `source` mediumtext,\n  `url` mediumtext,\n  PRIMARY KEY (`photo_id`,`format`)\n) ENGINE=MyISAM DEFAULT CHARSET=latin1\n\n\n\n\nShow what processes are running\n\n\nshow processlist;\n\n\n\n\nDump databases to sql files\n\n\nAll databases\n\n\nmysqldump -u root -phunter2 --all-databases | gzip -9 > ~/$(date +%F-%H%m).sql.gz\n\n\n\n\nOr just a single database\n\n\nmysqldump -u root -phunter2 my_favorite_db | gzip -9 > ~/my_favorite_db-$(date +%F-%H%m).sql.gz\n\n\n\n\nDuplicate a database\n\n\nsudo mysqldump -v mogilefs | sudo mysql -D mogilefs_sjc\n\n\n\n\nDump the schema of a database with no actual data\n\n\nsudo mysqldump --no-data dbname > schema.sql\n\n\n\n\nShow privileges\n\n\nshow GRANTS ;\n\n\n\n\nCreate a new user\n\n\nCREATE USER 'newuser'@'localhost' IDENTIFIED BY 'some_pass';\nGRANT ALL PRIVILEGES ON databasename.* TO 'newuser'@'localhost' WITH GRANT OPTION;\n\n\n\n\nDelete a user\n\n\nDROP USER 'user_name'@'localhost';\nDELETE from mysql.db where User = 'user_name';\n\n\n\n\nGrant Privileges\n\n\nGRANT ALL ON database.* TO 'newuser'@'localhost';\n\n\n\n\nChange root password\n\n\n/usr/bin/mysqladmin -u root password 'new-password'\n/usr/bin/mysqladmin -u root -h hostname password 'new-password'\n\n\n\n\nor...\n\n\nUPDATE mysql.user SET Password=PASSWORD('SomeNewPassword') WHERE User='user_name' AND Host='localhost';\n\n\n\n\nCreate statements\n\n\nCreate an index on table images for column rating_count\n\n\ncreate index rating_count on images (rating_count) ;\n\n\n\n\nDrop an index from a table\n\n\ndrop index rating_count on images ;\n\n\n\n\nTable Alters\n\n\nAdd a column\n\n\nalter table flixplor add o_width char(12);\n\n\n\n\nDrop a column\n\n\nalter table flixplor drop column o_width;\n\n\n\n\nChange the type of a column\n\n\nalter table flixplor modify o_height mediumint ;\n\n\n\n\nAdd a current timestamp column\n\n\nalter table images add last_updated timestamp not null default current_timestamp on update current_timestamp;\n\n\n\n\nChange the table engine to innodb\n\n\nALTER TABLE images ENGINE=INNODB;\n\n\n\n\nChange a table's encoding\n\n\nalter table raw_flickr_data CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci ;\n\n\n\n\nTable Inserts\n\n\nAdd a record\n\n\nTable Updates\n\n\nUpdate if key exists\n\n\n\n\nhttp://dev.mysql.com/doc/refman/5.0/en/insert-on-duplicate.html\n\n\n\n\nUpdate some fields in a record\n\n\nTable Selects\n\n\nSelect values and don't show duplicates\n\n\nSELECT col from servers group by col ;\n\n\n\n\nSelect photo_id and discard duplicates (uniq)\n\n\nSELECT photo_id from photo_sizes group by photo_id ;\n\n\n\n\nSelect and count unique pairs of columns\n\n\nSELECT model, unit, count(*) as n from servers group by model, unit having n > 1 order by model asc ;\n\n\n\n\nSelect the count of rows in a table\n\n\nSELECT count(*) from flixplor where o_height > 100 ;\n\n\n\n\nDo some math to create a new column during a select\n\n\nSELECT photo_id,last_retrieval,o_height,o_width,(o_height * o_width) as pixels from flixplor\nwhere last_reposted < from_unixtime('1384268667') or last_reposted is NULL\norder by (o_height * o_width) limit 10 ;\n\n\n\n\nTransform datetime into a date diff\n\n\nThis selects the number of hours since the given datestamp instead of the datestamp itself.\n\n\nSELECT TIMESTAMPDIFF(HOUR, date_taken, NOW()) from photos ;\n\n\n\n\nSee also DATEDIFF.\n\n\nStatement explanations\n\n\nThe EXPLAIN statement can give you additional info about how complex your statement is.\n\n\nExplain select\n\n\nmysql> explain SELECT *,(rating_sum / rating_count) as average from images where (rating_sum / rating_count) > 20 or rating_count=0 ORDER BY RAND() LIMIT 1 ;\n+----+-------------+--------+------+---------------+------+---------+------+--------+----------------------------------------------+\n| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra                                        |\n+----+-------------+--------+------+---------------+------+---------+------+--------+----------------------------------------------+\n|  1 | SIMPLE      | images | ALL  | rating_count  | NULL | NULL    | NULL | 301937 | Using where; Using temporary; Using filesort |\n+----+-------------+--------+------+---------------+------+---------+------+--------+----------------------------------------------+\n1 row in set (0.00 sec)\n\n\n\n\nMisc\n\n\n\n\nComplete statement with \\G for different output format\n\n\nERROR 1045 (28000)\n may be caused by invalid hostname in connect command.  Replace the --host token with the full hostname of the db server.  Or, restart mysql and try again.\n\n\n\n\nRecommended reading\n\n\n\n\nMySQL (5th Edition) (Developer's Library)\n\n\nHigh Performance MySQL: Optimization, Backups, Replication, and More\n\n\n\n\nSee Also\n\n\n\n\nhttp://www.sqlalchemy.org/\n - ORM, better for abstracting database in code\n\n\nhttp://www.mycli.net/\n - A better CLI for MySQL",
            "title": "MySQL"
        },
        {
            "location": "/mysql/#mysql",
            "text": "\"MySQL is an open-source relational database management system. Its name is a combination of \"My\", the name of co-founder Michael Widenius's daughter, and \"SQL\", the abbreviation for Structured Query Language. The MySQL development project has made its source code available under the terms of the GNU General Public License, as well as under a variety of proprietary agreements. MySQL was owned and sponsored by a single for-profit firm, the Swedish company MySQL AB, and is now owned by Oracle Corporation.\" -  https://en.wikipedia.org/wiki/MySQL",
            "title": "MySQL"
        },
        {
            "location": "/mysql/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/mysql/#show-variables-of-the-running-server",
            "text": "mysqladmin variables",
            "title": "Show variables of the running server"
        },
        {
            "location": "/mysql/#enable-bin-logging",
            "text": "Edit /etc/my.cnf:  log-bin=/var/lib/mysql/mysql-bin",
            "title": "Enable bin logging"
        },
        {
            "location": "/mysql/#show-how-a-table-was-created",
            "text": "SHOW CREATE TABLE table_name \\G",
            "title": "Show how a table was created"
        },
        {
            "location": "/mysql/#create-a-table",
            "text": "CREATE TABLE photo_sizes (\n  `photo_id` char(32) NOT NULL,\n  `format` mediumtext,\n  `width` mediumtext,\n  `height` mediumtext,\n  `source` mediumtext,\n  `url` mediumtext,\n  PRIMARY KEY(`photo_id`)\n) ;",
            "title": "Create a table"
        },
        {
            "location": "/mysql/#create-a-table-with-multiple-columns-as-the-primary-key",
            "text": "CREATE TABLE `photo_sizes` (\n  `photo_id` char(32) NOT NULL,\n  `format` char(32) NOT NULL DEFAULT '',\n  `width` mediumtext,\n  `height` mediumtext,\n  `source` mediumtext,\n  `url` mediumtext,\n  PRIMARY KEY (`photo_id`,`format`)\n) ENGINE=MyISAM DEFAULT CHARSET=latin1",
            "title": "Create a table with multiple columns as the primary key"
        },
        {
            "location": "/mysql/#show-what-processes-are-running",
            "text": "show processlist;",
            "title": "Show what processes are running"
        },
        {
            "location": "/mysql/#dump-databases-to-sql-files",
            "text": "All databases  mysqldump -u root -phunter2 --all-databases | gzip -9 > ~/$(date +%F-%H%m).sql.gz  Or just a single database  mysqldump -u root -phunter2 my_favorite_db | gzip -9 > ~/my_favorite_db-$(date +%F-%H%m).sql.gz",
            "title": "Dump databases to sql files"
        },
        {
            "location": "/mysql/#duplicate-a-database",
            "text": "sudo mysqldump -v mogilefs | sudo mysql -D mogilefs_sjc",
            "title": "Duplicate a database"
        },
        {
            "location": "/mysql/#dump-the-schema-of-a-database-with-no-actual-data",
            "text": "sudo mysqldump --no-data dbname > schema.sql",
            "title": "Dump the schema of a database with no actual data"
        },
        {
            "location": "/mysql/#show-privileges",
            "text": "show GRANTS ;",
            "title": "Show privileges"
        },
        {
            "location": "/mysql/#create-a-new-user",
            "text": "CREATE USER 'newuser'@'localhost' IDENTIFIED BY 'some_pass';\nGRANT ALL PRIVILEGES ON databasename.* TO 'newuser'@'localhost' WITH GRANT OPTION;",
            "title": "Create a new user"
        },
        {
            "location": "/mysql/#delete-a-user",
            "text": "DROP USER 'user_name'@'localhost';\nDELETE from mysql.db where User = 'user_name';",
            "title": "Delete a user"
        },
        {
            "location": "/mysql/#grant-privileges",
            "text": "GRANT ALL ON database.* TO 'newuser'@'localhost';",
            "title": "Grant Privileges"
        },
        {
            "location": "/mysql/#change-root-password",
            "text": "/usr/bin/mysqladmin -u root password 'new-password'\n/usr/bin/mysqladmin -u root -h hostname password 'new-password'  or...  UPDATE mysql.user SET Password=PASSWORD('SomeNewPassword') WHERE User='user_name' AND Host='localhost';",
            "title": "Change root password"
        },
        {
            "location": "/mysql/#create-statements",
            "text": "",
            "title": "Create statements"
        },
        {
            "location": "/mysql/#create-an-index-on-table-images-for-column-rating_count",
            "text": "create index rating_count on images (rating_count) ;",
            "title": "Create an index on table images for column rating_count"
        },
        {
            "location": "/mysql/#drop-an-index-from-a-table",
            "text": "drop index rating_count on images ;",
            "title": "Drop an index from a table"
        },
        {
            "location": "/mysql/#table-alters",
            "text": "",
            "title": "Table Alters"
        },
        {
            "location": "/mysql/#add-a-column",
            "text": "alter table flixplor add o_width char(12);",
            "title": "Add a column"
        },
        {
            "location": "/mysql/#drop-a-column",
            "text": "alter table flixplor drop column o_width;",
            "title": "Drop a column"
        },
        {
            "location": "/mysql/#change-the-type-of-a-column",
            "text": "alter table flixplor modify o_height mediumint ;",
            "title": "Change the type of a column"
        },
        {
            "location": "/mysql/#add-a-current-timestamp-column",
            "text": "alter table images add last_updated timestamp not null default current_timestamp on update current_timestamp;",
            "title": "Add a current timestamp column"
        },
        {
            "location": "/mysql/#change-the-table-engine-to-innodb",
            "text": "ALTER TABLE images ENGINE=INNODB;",
            "title": "Change the table engine to innodb"
        },
        {
            "location": "/mysql/#change-a-tables-encoding",
            "text": "alter table raw_flickr_data CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci ;",
            "title": "Change a table's encoding"
        },
        {
            "location": "/mysql/#table-inserts",
            "text": "",
            "title": "Table Inserts"
        },
        {
            "location": "/mysql/#add-a-record",
            "text": "",
            "title": "Add a record"
        },
        {
            "location": "/mysql/#table-updates",
            "text": "",
            "title": "Table Updates"
        },
        {
            "location": "/mysql/#update-if-key-exists",
            "text": "http://dev.mysql.com/doc/refman/5.0/en/insert-on-duplicate.html",
            "title": "Update if key exists"
        },
        {
            "location": "/mysql/#update-some-fields-in-a-record",
            "text": "",
            "title": "Update some fields in a record"
        },
        {
            "location": "/mysql/#table-selects",
            "text": "",
            "title": "Table Selects"
        },
        {
            "location": "/mysql/#select-values-and-dont-show-duplicates",
            "text": "SELECT col from servers group by col ;",
            "title": "Select values and don't show duplicates"
        },
        {
            "location": "/mysql/#select-photo_id-and-discard-duplicates-uniq",
            "text": "SELECT photo_id from photo_sizes group by photo_id ;",
            "title": "Select photo_id and discard duplicates (uniq)"
        },
        {
            "location": "/mysql/#select-and-count-unique-pairs-of-columns",
            "text": "SELECT model, unit, count(*) as n from servers group by model, unit having n > 1 order by model asc ;",
            "title": "Select and count unique pairs of columns"
        },
        {
            "location": "/mysql/#select-the-count-of-rows-in-a-table",
            "text": "SELECT count(*) from flixplor where o_height > 100 ;",
            "title": "Select the count of rows in a table"
        },
        {
            "location": "/mysql/#do-some-math-to-create-a-new-column-during-a-select",
            "text": "SELECT photo_id,last_retrieval,o_height,o_width,(o_height * o_width) as pixels from flixplor\nwhere last_reposted < from_unixtime('1384268667') or last_reposted is NULL\norder by (o_height * o_width) limit 10 ;",
            "title": "Do some math to create a new column during a select"
        },
        {
            "location": "/mysql/#transform-datetime-into-a-date-diff",
            "text": "This selects the number of hours since the given datestamp instead of the datestamp itself.  SELECT TIMESTAMPDIFF(HOUR, date_taken, NOW()) from photos ;  See also DATEDIFF.",
            "title": "Transform datetime into a date diff"
        },
        {
            "location": "/mysql/#statement-explanations",
            "text": "The EXPLAIN statement can give you additional info about how complex your statement is.",
            "title": "Statement explanations"
        },
        {
            "location": "/mysql/#explain-select",
            "text": "mysql> explain SELECT *,(rating_sum / rating_count) as average from images where (rating_sum / rating_count) > 20 or rating_count=0 ORDER BY RAND() LIMIT 1 ;\n+----+-------------+--------+------+---------------+------+---------+------+--------+----------------------------------------------+\n| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra                                        |\n+----+-------------+--------+------+---------------+------+---------+------+--------+----------------------------------------------+\n|  1 | SIMPLE      | images | ALL  | rating_count  | NULL | NULL    | NULL | 301937 | Using where; Using temporary; Using filesort |\n+----+-------------+--------+------+---------------+------+---------+------+--------+----------------------------------------------+\n1 row in set (0.00 sec)",
            "title": "Explain select"
        },
        {
            "location": "/mysql/#misc",
            "text": "Complete statement with \\G for different output format  ERROR 1045 (28000)  may be caused by invalid hostname in connect command.  Replace the --host token with the full hostname of the db server.  Or, restart mysql and try again.",
            "title": "Misc"
        },
        {
            "location": "/mysql/#recommended-reading",
            "text": "MySQL (5th Edition) (Developer's Library)  High Performance MySQL: Optimization, Backups, Replication, and More",
            "title": "Recommended reading"
        },
        {
            "location": "/mysql/#see-also",
            "text": "http://www.sqlalchemy.org/  - ORM, better for abstracting database in code  http://www.mycli.net/  - A better CLI for MySQL",
            "title": "See Also"
        },
        {
            "location": "/namei/",
            "text": "\"follow a pathname until a terminal point is found\" - \nman namei\n\n\nExamples\n\n\nSimple usage\n\n\n# namei /etc/systemd/system/multi-user.target.wants/ssh.service\nf: /etc/systemd/system/multi-user.target.wants/ssh.service\n d /\n d etc\n d systemd\n d system\n d multi-user.target.wants\n l ssh.service -> /lib/systemd/system/ssh.service\n   d /\n   d lib\n   d systemd\n   d system\n   - ssh.service\n\n\n\n\nShow permissions of all entries\n\n\n# namei -l /etc/systemd/system/multi-user.target.wants/ssh.service\nf: /etc/systemd/system/multi-user.target.wants/ssh.service\ndrwxr-xr-x root root /\ndrwxr-xr-x root root etc\ndrwxr-xr-x root root systemd\ndrwxr-xr-x root root system\ndrwxr-xr-x root root multi-user.target.wants\nlrwxrwxrwx root root ssh.service -> /lib/systemd/system/ssh.service\ndrwxr-xr-x root root   /\ndrwxr-xr-x root root   lib\ndrwxr-xr-x root root   systemd\ndrwxr-xr-x root root   system\n-rw-r--r-- root root   ssh.service",
            "title": "Namei"
        },
        {
            "location": "/namei/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/namei/#simple-usage",
            "text": "# namei /etc/systemd/system/multi-user.target.wants/ssh.service\nf: /etc/systemd/system/multi-user.target.wants/ssh.service\n d /\n d etc\n d systemd\n d system\n d multi-user.target.wants\n l ssh.service -> /lib/systemd/system/ssh.service\n   d /\n   d lib\n   d systemd\n   d system\n   - ssh.service",
            "title": "Simple usage"
        },
        {
            "location": "/namei/#show-permissions-of-all-entries",
            "text": "# namei -l /etc/systemd/system/multi-user.target.wants/ssh.service\nf: /etc/systemd/system/multi-user.target.wants/ssh.service\ndrwxr-xr-x root root /\ndrwxr-xr-x root root etc\ndrwxr-xr-x root root systemd\ndrwxr-xr-x root root system\ndrwxr-xr-x root root multi-user.target.wants\nlrwxrwxrwx root root ssh.service -> /lib/systemd/system/ssh.service\ndrwxr-xr-x root root   /\ndrwxr-xr-x root root   lib\ndrwxr-xr-x root root   systemd\ndrwxr-xr-x root root   system\n-rw-r--r-- root root   ssh.service",
            "title": "Show permissions of all entries"
        },
        {
            "location": "/netgear/",
            "text": "Netgear R7000\n\n\nDD-WRT\n\n\n\n\nhttps://www.myopenrouter.com/downloads/dd-wrt-r7000\n\n\nhttp://www.desipro.de/ddwrt/K3-AC-Arm/\n\n\n\n\nSee Also: \ndd-wrt\n\n\nNetgear GSS116E\n\n\n\n\nhttps://www.netgear.com/support/product/GSS116E",
            "title": "Netgear R7000"
        },
        {
            "location": "/netgear/#netgear-r7000",
            "text": "",
            "title": "Netgear R7000"
        },
        {
            "location": "/netgear/#dd-wrt",
            "text": "https://www.myopenrouter.com/downloads/dd-wrt-r7000  http://www.desipro.de/ddwrt/K3-AC-Arm/   See Also:  dd-wrt",
            "title": "DD-WRT"
        },
        {
            "location": "/netgear/#netgear-gss116e",
            "text": "https://www.netgear.com/support/product/GSS116E",
            "title": "Netgear GSS116E"
        },
        {
            "location": "/nethogs/",
            "text": "\"Linux 'net top' tool\" - \nhttps://github.com/raboof/nethogs\n\n\nNethogs shows you which PIDs used or are using how much bandwidth.\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Nethogs"
        },
        {
            "location": "/nethogs/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/networking/",
            "text": "Links\n\n\n\n\nhttps://en.wikipedia.org/wiki/Reserved_IP_addresses\n\n\n\n\nSee also\n\n\n\n\nbind\n - DNS server\n\n\niftop\n - interface top\n\n\nip\n command for linux\n\n\niperf\n - network performance testing\n\n\niptables\n - linux firewall\n\n\nlinksys\n - soho network hardware vendor\n\n\nnetgear\n - network hardware vendor\n\n\nnetworksetup\n - Mac OSX configuration tool for network settings in System Preferences\n\n\nntop\n - network top\n\n\nOSI model\n - The Open Systems Interconnection model (OSI model) is a conceptual model that characterizes and standardizes the communication functions of a telecommunication or computing system without regard to its underlying internal structure and technology.\n\n\npac\n - dynamic proxy configuration\n\n\nprocurve\n - HP managed networking",
            "title": "Links"
        },
        {
            "location": "/networking/#links",
            "text": "https://en.wikipedia.org/wiki/Reserved_IP_addresses",
            "title": "Links"
        },
        {
            "location": "/networking/#see-also",
            "text": "bind  - DNS server  iftop  - interface top  ip  command for linux  iperf  - network performance testing  iptables  - linux firewall  linksys  - soho network hardware vendor  netgear  - network hardware vendor  networksetup  - Mac OSX configuration tool for network settings in System Preferences  ntop  - network top  OSI model  - The Open Systems Interconnection model (OSI model) is a conceptual model that characterizes and standardizes the communication functions of a telecommunication or computing system without regard to its underlying internal structure and technology.  pac  - dynamic proxy configuration  procurve  - HP managed networking",
            "title": "See also"
        },
        {
            "location": "/networksetup/",
            "text": "\"networksetup -- configuration tool for network settings in System Preferences.\" - \nman networksetup\n\n\nnetworksetup\n is a standard tool on \nosx\n\n\nExamples\n\n\nshows the relevant info for the device named Wi-Fi\n\n\nnetworksetup -getinfo \"Wi-Fi\"\n\n\n\n\nshows all connected hardware ports\n\n\nnetworksetup -listallhardwareports\n\n\n\n\nShow all search domains\n\n\nnetworksetup -listallnetworkservices |\n  tail -n +2 |\n  xargs -I :: networksetup -getsearchdomains \"::\"\n\n\n\n\nCreate a bunch of VLAN interfaces\n\n\nfor X in {1..32} ; do\n  sudo networksetup -createVLAN \"vlan${X}\" en3 \"${X}\" ;\ndone ;\n\n\n\n\nDelete a bunch of VLAN interfaces\n\n\nfor X in {1..32} ; do\n  sudo networksetup -deleteVLAN \"vlan${X}\" en3 \"${X}\" ;\ndone ;",
            "title": "Networksetup"
        },
        {
            "location": "/networksetup/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/networksetup/#shows-the-relevant-info-for-the-device-named-wi-fi",
            "text": "networksetup -getinfo \"Wi-Fi\"",
            "title": "shows the relevant info for the device named Wi-Fi"
        },
        {
            "location": "/networksetup/#shows-all-connected-hardware-ports",
            "text": "networksetup -listallhardwareports",
            "title": "shows all connected hardware ports"
        },
        {
            "location": "/networksetup/#show-all-search-domains",
            "text": "networksetup -listallnetworkservices |\n  tail -n +2 |\n  xargs -I :: networksetup -getsearchdomains \"::\"",
            "title": "Show all search domains"
        },
        {
            "location": "/networksetup/#create-a-bunch-of-vlan-interfaces",
            "text": "for X in {1..32} ; do\n  sudo networksetup -createVLAN \"vlan${X}\" en3 \"${X}\" ;\ndone ;",
            "title": "Create a bunch of VLAN interfaces"
        },
        {
            "location": "/networksetup/#delete-a-bunch-of-vlan-interfaces",
            "text": "for X in {1..32} ; do\n  sudo networksetup -deleteVLAN \"vlan${X}\" en3 \"${X}\" ;\ndone ;",
            "title": "Delete a bunch of VLAN interfaces"
        },
        {
            "location": "/nfs/",
            "text": "nfs is the Network File System.\n- Configured in linux at /etc/exports\n- Great info here: \nhttp://nfs.sourceforge.net/\n\n\nTips and Tricks\n\n\nRegarding mount points within shares\n\n\nIf you have a mount point within an NFS share, you must have a separate entry in your exports file that sets the permissions of this mount point. Currently OS X has a problem with this, but officially this is the way to do it.\n\n\nShow hosts that are connected to this NFS server\n\n\nshowmount\n\n\nShow what hosts are using what exports\n\n\nshowmount -a\n\n\nShow exported directories\n\n\nshowmount\n-e\n\n\nShow directories in use by NFS\n\n\nshowmount -d\n\n\nAdd an NFS mount to fstab\n\n\nopal:/z4  /mnt/z4   nfs  rsize=8192,wsize=8192,timeo=14,intr\n\n\nLinux Tips and Tricks\n\n\nShow which versions of NFS your NFS server supports\n\n\nrpcinfo -p\n\n\nAllow an OS X client to mount nfs4 nested zfs data sets\n\n\nOS X has problems with the privileged port default requirement in nfs4, so the \ninsecure\n option is required.\n\n\nThe \nnohide\n option allows you to mount nested zfs datasets, instead of requiring a separate export for each dataset.\n\n\n/z4 *.local(rw,async,no_subtree_check,insecure,nohide)\n\n\n\n\nOS X Tips and Tricks\n\n\nCreate persistent NFS mount in OS X 10.8\n\n\nThis is not bulletproof. Modern OS X 10.9+ version are switching away from NFS to CIFS. The NFS client on OS X is pretty weak. For instance it might crash your machine if the share has 0 bytes free but is mounted RW. Use at your own risk.\n\n\nsudo mkdir /mnt # OS X doesn't like you playing with /Volumes, it may delete your dirs\nsudo dscl . -create /Mounts/z4\nsudo dscl . -create /Mounts/z4 VFSLinkDir /mnt/z4\nsudo dscl . -create /Mounts/z4 VFSOpts resvport rw nosuid\nsudo dscl . -create /Mounts/z4 VFSType nfs\nsudo dscl . -create /Mounts/z4 RecordName opal:/z4\nsudo dscl . -create /Mounts/iTunes\nsudo dscl . -create /Mounts/iTunes VFSLinkDir /mnt/z4/iTunes\nsudo dscl . -create /Mounts/iTunes VFSOpts resvport rw nosuid\nsudo dscl . -create /Mounts/iTunes VFSType nfs\nsudo dscl . -create /Mounts/iTunes RecordName opal:/z4/iTunes\nsudo dscl . -read /Mounts/opal:/z4\nsudo dscl . -read /Mounts/opal:/z4/iTunes\nsudo dscl . -list /Mounts\n\nsudo dscl . -delete /Mounts opal:/z4/iTunes",
            "title": "Nfs"
        },
        {
            "location": "/nfs/#tips-and-tricks",
            "text": "",
            "title": "Tips and Tricks"
        },
        {
            "location": "/nfs/#regarding-mount-points-within-shares",
            "text": "If you have a mount point within an NFS share, you must have a separate entry in your exports file that sets the permissions of this mount point. Currently OS X has a problem with this, but officially this is the way to do it.",
            "title": "Regarding mount points within shares"
        },
        {
            "location": "/nfs/#show-hosts-that-are-connected-to-this-nfs-server",
            "text": "showmount",
            "title": "Show hosts that are connected to this NFS server"
        },
        {
            "location": "/nfs/#show-what-hosts-are-using-what-exports",
            "text": "showmount -a",
            "title": "Show what hosts are using what exports"
        },
        {
            "location": "/nfs/#show-exported-directories",
            "text": "showmount -e",
            "title": "Show exported directories"
        },
        {
            "location": "/nfs/#show-directories-in-use-by-nfs",
            "text": "showmount -d",
            "title": "Show directories in use by NFS"
        },
        {
            "location": "/nfs/#add-an-nfs-mount-to-fstab",
            "text": "opal:/z4  /mnt/z4   nfs  rsize=8192,wsize=8192,timeo=14,intr",
            "title": "Add an NFS mount to fstab"
        },
        {
            "location": "/nfs/#linux-tips-and-tricks",
            "text": "",
            "title": "Linux Tips and Tricks"
        },
        {
            "location": "/nfs/#show-which-versions-of-nfs-your-nfs-server-supports",
            "text": "rpcinfo -p",
            "title": "Show which versions of NFS your NFS server supports"
        },
        {
            "location": "/nfs/#allow-an-os-x-client-to-mount-nfs4-nested-zfs-data-sets",
            "text": "OS X has problems with the privileged port default requirement in nfs4, so the  insecure  option is required.  The  nohide  option allows you to mount nested zfs datasets, instead of requiring a separate export for each dataset.  /z4 *.local(rw,async,no_subtree_check,insecure,nohide)",
            "title": "Allow an OS X client to mount nfs4 nested zfs data sets"
        },
        {
            "location": "/nfs/#os-x-tips-and-tricks",
            "text": "",
            "title": "OS X Tips and Tricks"
        },
        {
            "location": "/nfs/#create-persistent-nfs-mount-in-os-x-108",
            "text": "This is not bulletproof. Modern OS X 10.9+ version are switching away from NFS to CIFS. The NFS client on OS X is pretty weak. For instance it might crash your machine if the share has 0 bytes free but is mounted RW. Use at your own risk.  sudo mkdir /mnt # OS X doesn't like you playing with /Volumes, it may delete your dirs\nsudo dscl . -create /Mounts/z4\nsudo dscl . -create /Mounts/z4 VFSLinkDir /mnt/z4\nsudo dscl . -create /Mounts/z4 VFSOpts resvport rw nosuid\nsudo dscl . -create /Mounts/z4 VFSType nfs\nsudo dscl . -create /Mounts/z4 RecordName opal:/z4\nsudo dscl . -create /Mounts/iTunes\nsudo dscl . -create /Mounts/iTunes VFSLinkDir /mnt/z4/iTunes\nsudo dscl . -create /Mounts/iTunes VFSOpts resvport rw nosuid\nsudo dscl . -create /Mounts/iTunes VFSType nfs\nsudo dscl . -create /Mounts/iTunes RecordName opal:/z4/iTunes\nsudo dscl . -read /Mounts/opal:/z4\nsudo dscl . -read /Mounts/opal:/z4/iTunes\nsudo dscl . -list /Mounts\n\nsudo dscl . -delete /Mounts opal:/z4/iTunes",
            "title": "Create persistent NFS mount in OS X 10.8"
        },
        {
            "location": "/ntop/",
            "text": "\"High-speed web-based traffic analysis.\" - \nhttps://www.ntop.org/\n\n\nThis isn't a traditional \ntop\n style tool since it has a web interface. For network top in a TUI, see \niftop\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Ntop"
        },
        {
            "location": "/ntop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/openvpn/",
            "text": "\"Your private path to access network resources and services securely\" - \nhttps://openvpn.net/",
            "title": "Openvpn"
        },
        {
            "location": "/osquery/",
            "text": "\"SQL powered operating system instrumentation, monitoring, and analytics.\"\n\n\noquery runs locally and allows you to inspect your host using sql queries. Tables exist for a variety of useful data, such as file hashes, process list, last user login, etc..\n\n\nLinks\n\n\n\n\nhttps://github.com/facebook/osquery\n\n\nhttps://osquery.readthedocs.io\n\n\nhttps://osquery.io/schema/\n\n\nhttps://github.com/UtahDave/salt-vagrant-demo\n\n\nhttps://www.digitalocean.com/community/tutorials/how-to-monitor-your-system-security-with-osquery-on-ubuntu-16-04\n\n\nhttps://kolide.com/fleet\n - osquery fleet/cluster system",
            "title": "Osquery"
        },
        {
            "location": "/osquery/#links",
            "text": "https://github.com/facebook/osquery  https://osquery.readthedocs.io  https://osquery.io/schema/  https://github.com/UtahDave/salt-vagrant-demo  https://www.digitalocean.com/community/tutorials/how-to-monitor-your-system-security-with-osquery-on-ubuntu-16-04  https://kolide.com/fleet  - osquery fleet/cluster system",
            "title": "Links"
        },
        {
            "location": "/ostinato/",
            "text": "\"Ostinato is a packet crafter, network traffic generator and analyzer with a friendly GUI. Also a powerful Python API for network test automation. Craft and send packets of several streams with different protocols at different rates. Think of it as '\n in Reverse'.\" - \nhttp://ostinato.org/",
            "title": "Ostinato"
        },
        {
            "location": "/osx/",
            "text": "Apple's Unix desktop operating system.\n\n\nNifty Commands\n\n\n\n\nserverinfo\n\n\ncaffeinate\n\n\nsharing\n\n\ntccutil\n\n\nscutil\n\n\n\n\nFirewall - 10.11\n\n\nFrom \nhttp://krypted.com/mac-security/command-line-firewall-management-in-os-x-10-10/\n\n- /usr/libexec/ApplicationFirewall/socketfilterfw\n\n\nTricks\n\n\nShow hardware info\n\n\nsystem_profiler SPHardwareDataType\n\n\n\n\nInstall package from CLI\n\n\nsudo installer -pkg /Volumes/ExifTool-9.16/ExifTool-9.16.pkg -target /\n\n\n\n\nSee also: \nhttps://brew.sh/\n\n\nStart FTP server\n\n\nsudo -s launchctl load -w /System/Library/LaunchDaemons/ftp.plist\n\n\n\n\nCheck swap usage\n\n\nsysctl vm.swapusage\n\n\n\n\nDisable wifi disconnect when locking screen\n\n\nsudo /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources airport en1 prefs DisconnectOnLogout=NO\n\n\n\n\nShow some downloaded files\n\n\nThis shows a list of all the quarantine checked downloads:\n\n\nsqlite3 ~/Library/Preferences/com.apple.LaunchServices.QuarantineEventsV* 'select distinct LSQuarantineDataURLString from LSQuarantineEvent'\n\n\n\n\nSend Notifications from Terminal\n\n\nsudo gem install terminal-notifier\nterminal-notifier -message \"Hello, this is my message\" -title \"Message Title\"\n\n\n\n\nEnable verbose eap logging\n\n\nsudo defaults write /Library/Preferences/SystemConfiguration/com.apple.eapolclient LogFlags -int -1\n\n\n\n\nNetwork\n\n\n\n\ngif0 - Generic Tunnel Interface. See \nman gif\n.\n\n\nstf0 - Six To Four tunnel.\n\n\n\n\nMigration\n\n\nAfter migrating, check these files:\n- /etc/hosts (not transferred using Migration Assistant in 10.7)\n- crontabs (not transferred using Migration Assistant in 10.7)\n- /etc/apache2/httpd.conf (not transferred using Migration Assistant\n- in 10.7)",
            "title": "Osx"
        },
        {
            "location": "/osx/#nifty-commands",
            "text": "serverinfo  caffeinate  sharing  tccutil  scutil",
            "title": "Nifty Commands"
        },
        {
            "location": "/osx/#firewall-1011",
            "text": "From  http://krypted.com/mac-security/command-line-firewall-management-in-os-x-10-10/ \n- /usr/libexec/ApplicationFirewall/socketfilterfw",
            "title": "Firewall - 10.11"
        },
        {
            "location": "/osx/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/osx/#show-hardware-info",
            "text": "system_profiler SPHardwareDataType",
            "title": "Show hardware info"
        },
        {
            "location": "/osx/#install-package-from-cli",
            "text": "sudo installer -pkg /Volumes/ExifTool-9.16/ExifTool-9.16.pkg -target /  See also:  https://brew.sh/",
            "title": "Install package from CLI"
        },
        {
            "location": "/osx/#start-ftp-server",
            "text": "sudo -s launchctl load -w /System/Library/LaunchDaemons/ftp.plist",
            "title": "Start FTP server"
        },
        {
            "location": "/osx/#check-swap-usage",
            "text": "sysctl vm.swapusage",
            "title": "Check swap usage"
        },
        {
            "location": "/osx/#disable-wifi-disconnect-when-locking-screen",
            "text": "sudo /System/Library/PrivateFrameworks/Apple80211.framework/Versions/Current/Resources airport en1 prefs DisconnectOnLogout=NO",
            "title": "Disable wifi disconnect when locking screen"
        },
        {
            "location": "/osx/#show-some-downloaded-files",
            "text": "This shows a list of all the quarantine checked downloads:  sqlite3 ~/Library/Preferences/com.apple.LaunchServices.QuarantineEventsV* 'select distinct LSQuarantineDataURLString from LSQuarantineEvent'",
            "title": "Show some downloaded files"
        },
        {
            "location": "/osx/#send-notifications-from-terminal",
            "text": "sudo gem install terminal-notifier\nterminal-notifier -message \"Hello, this is my message\" -title \"Message Title\"",
            "title": "Send Notifications from Terminal"
        },
        {
            "location": "/osx/#enable-verbose-eap-logging",
            "text": "sudo defaults write /Library/Preferences/SystemConfiguration/com.apple.eapolclient LogFlags -int -1",
            "title": "Enable verbose eap logging"
        },
        {
            "location": "/osx/#network",
            "text": "gif0 - Generic Tunnel Interface. See  man gif .  stf0 - Six To Four tunnel.",
            "title": "Network"
        },
        {
            "location": "/osx/#migration",
            "text": "After migrating, check these files:\n- /etc/hosts (not transferred using Migration Assistant in 10.7)\n- crontabs (not transferred using Migration Assistant in 10.7)\n- /etc/apache2/httpd.conf (not transferred using Migration Assistant\n- in 10.7)",
            "title": "Migration"
        },
        {
            "location": "/pac/",
            "text": "Example pac file\n\n\nThe following pac file will\n\n\n\n\nRedirect all traffic destined to \n192.168.1.0/24\n to a proxy running on \nlocalhost:47000\n, but only if we do not have an ip address in that subnet\n\n\nRedirect all traffic destined to \n172.16.0.0/16\n to a proxy running on \nlocalhost:33001\n\n\nAll other traffic bypasses the proxy.\n\n\n\n\nfunction FindProxyForURL(url, host) {\n  if ((isInNet(host, \"192.168.1.0\", \"255.255.255.0\"))\n  && (! isInNet(myIpAddress(), \"192.168.1.0\", \"255.255.255.0\"))) {\n    return \"SOCKS5 localhost:47000\" ;\n  } else if (isInNet(host, \"172.16.0.0\", \"255.255.0.0\")) {\n    return \"SOCKS5 localhost:33001\" ;\n  } else {\n    return \"DIRECT\" ;\n  }\n}\n\n\n\n\nLinks\n\n\n\n\nhttp://findproxyforurl.com/official-toolset\n\n\nhttps://github.com/pacparser/pacparser",
            "title": "Example pac file"
        },
        {
            "location": "/pac/#example-pac-file",
            "text": "The following pac file will   Redirect all traffic destined to  192.168.1.0/24  to a proxy running on  localhost:47000 , but only if we do not have an ip address in that subnet  Redirect all traffic destined to  172.16.0.0/16  to a proxy running on  localhost:33001  All other traffic bypasses the proxy.   function FindProxyForURL(url, host) {\n  if ((isInNet(host, \"192.168.1.0\", \"255.255.255.0\"))\n  && (! isInNet(myIpAddress(), \"192.168.1.0\", \"255.255.255.0\"))) {\n    return \"SOCKS5 localhost:47000\" ;\n  } else if (isInNet(host, \"172.16.0.0\", \"255.255.0.0\")) {\n    return \"SOCKS5 localhost:33001\" ;\n  } else {\n    return \"DIRECT\" ;\n  }\n}",
            "title": "Example pac file"
        },
        {
            "location": "/pac/#links",
            "text": "http://findproxyforurl.com/official-toolset  https://github.com/pacparser/pacparser",
            "title": "Links"
        },
        {
            "location": "/pandoc/",
            "text": "Convert between document formats.\n\n\nhttp://pandoc.org/\n\n\nExamples\n\n\nConvert a doc from mediawiki to markdown\n\n\npandoc -f mediawiki -t markdown nfs.mediawiki > nfs.md",
            "title": "Pandoc"
        },
        {
            "location": "/pandoc/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/pandoc/#convert-a-doc-from-mediawiki-to-markdown",
            "text": "pandoc -f mediawiki -t markdown nfs.mediawiki > nfs.md",
            "title": "Convert a doc from mediawiki to markdown"
        },
        {
            "location": "/passwords/",
            "text": "\"A secret word or phrase that must be used to gain admission to something.\" - \nhttps://en.oxforddictionaries.com/definition/password\n\n\nGeneration\n\n\npwgen\n\n\n$ pwgen 12 3\nahZielooC4ei Ielui3ahh9su aiZoa7fioy1o\n\n\n\n\napg\n\n\nThis tool lets you show how to pronounce the random password\n\n\n$ apg -a 1 -m 6 -n 3 -l\nI[hM@}]t: India-LEFT_BRACKET-hotel-Mike-AT_SIGN-RIGHT_BRACE-RIGHT_BRACKET-tango-COLON\nWoqrJ}R+ps Whiskey-oscar-quebec-romeo-Juliett-RIGHT_BRACE-Romeo-PLUS_SIGN-papa-sierra\nzni6VC3 zulu-november-india-SIX-Victor-Charlie-THREE\n\n\n\n\nLinks\n\n\n\n\nhttps://nakedsecurity.sophos.com/2016/08/18/nists-new-password-rules-what-you-need-to-know/\n\n\nhttps://pages.nist.gov/800-63-3/sp800-63-3.html",
            "title": "Passwords"
        },
        {
            "location": "/passwords/#generation",
            "text": "",
            "title": "Generation"
        },
        {
            "location": "/passwords/#pwgen",
            "text": "$ pwgen 12 3\nahZielooC4ei Ielui3ahh9su aiZoa7fioy1o",
            "title": "pwgen"
        },
        {
            "location": "/passwords/#apg",
            "text": "This tool lets you show how to pronounce the random password  $ apg -a 1 -m 6 -n 3 -l\nI[hM@}]t: India-LEFT_BRACKET-hotel-Mike-AT_SIGN-RIGHT_BRACE-RIGHT_BRACKET-tango-COLON\nWoqrJ}R+ps Whiskey-oscar-quebec-romeo-Juliett-RIGHT_BRACE-Romeo-PLUS_SIGN-papa-sierra\nzni6VC3 zulu-november-india-SIX-Victor-Charlie-THREE",
            "title": "apg"
        },
        {
            "location": "/passwords/#links",
            "text": "https://nakedsecurity.sophos.com/2016/08/18/nists-new-password-rules-what-you-need-to-know/  https://pages.nist.gov/800-63-3/sp800-63-3.html",
            "title": "Links"
        },
        {
            "location": "/perl/",
            "text": "Practical Extraction and Reporting Language\n\n\nSpecial Variables\n\n\n\n\n\"That thing\": \n$_\n\n\nRecord Separator: \n$/\n\n\n\n\nTechniques\n\n\nAssign an array to some matches\n\n\n@array_of_matches = ($source_string =~ m/..pattern../g);\n\n\n\n\nAssign several variables to some matches\n\n\nmy ($num, $a, $t) = ($_ =~ m/([0-9]*)\\. (.*) - (.*)\\.mp3/) ;\n\n\n\n\nIterate a hash\n\n\nwhile(($key, $value) = each(%$_)){\n    print \"$value is $key\\n\" ;\n}\n\n\n\n\nPrint out a file with line numbers\n\n\ncat ~/.bash_history | perl -nle 'print \"$.\\t$_\";'\n\n\n\n\nThis should probably be done with \nnl -ba .bash_history\n instead.\n\n\nEdit a file in-place\n\n\nTo change all instances of \"foo\" to \"bar\":\n\n\nperl -i -pe 's/foo/bar/g' filename.txt\n\n\n\n\nRemove blank lines from a file\n\n\nperl -pi -e \"s/^\\n//\" file.txt\n\n\n\n\nRemove lines from a file that match a certain regex\n\n\nperl -i -pe 'if ($_ =~ m/string to remove/ ){$_ = \"\";}' filename.txt\n\n\n\n\nSort a line by spaces\n\n\nSee \nbash\n for a bash-only way\n\n\necho -n \"whiskey tango foxtrot \" \\\n| perl -e '\n  $/=\" \" ;\n  @foo = <STDIN> ;\n  print (sort(@foo)) ;\n  print \"\\n\" ;\n'\n\n\n\n\nSort records in a file that are separated by a blank line\n\n\n#!/usr/bin/perl\n$/ = \"\\n\\n\" ;\nmy @input = (<STDIN>) ;\n\nmy @sorted = sort { lc($a) cmp lc($b) } @input ;\n\nforeach (@sorted) {\n  if (length($_) > 10) { print \"$_\"; }\n}\n\n\n\n\nSubtract two from the last octet of a MAC address\n\n\nfor X in 24:b6:fd:ff:b7:f{{a..f},{0..9}} ; do\n  echo -n \"${X} - 2 = \" ;\n  echo ${X} \\\n  | perl -ne '\n    @foo = split(\":\",$_) ;\n    $foo[5] = sprintf(\"%02x\", (hex($foo[5]) - 2)) ;\n    $new = join(\":\",@foo) ;\n    print \"$new\\n\" ;\n  ' ;\ndone ;\n\n\n\n\nAdd one to the last octet of a MAC address\n\n\nfor X in 24:b6:fd:ff:b7:c{{a..f},{0..9}} ; do\n  echo ${X} \\\n  | perl -ne '\n    @foo = split(\":\",$_) ;\n    $foo[5] = sprintf(\"%02x\", (hex($foo[5]) + 1)) ;\n    $new = join(\":\",@foo) ;\n    print \"$new\\n\";\n  ' ;\ndone ;",
            "title": "Perl"
        },
        {
            "location": "/perl/#special-variables",
            "text": "\"That thing\":  $_  Record Separator:  $/",
            "title": "Special Variables"
        },
        {
            "location": "/perl/#techniques",
            "text": "",
            "title": "Techniques"
        },
        {
            "location": "/perl/#assign-an-array-to-some-matches",
            "text": "@array_of_matches = ($source_string =~ m/..pattern../g);",
            "title": "Assign an array to some matches"
        },
        {
            "location": "/perl/#assign-several-variables-to-some-matches",
            "text": "my ($num, $a, $t) = ($_ =~ m/([0-9]*)\\. (.*) - (.*)\\.mp3/) ;",
            "title": "Assign several variables to some matches"
        },
        {
            "location": "/perl/#iterate-a-hash",
            "text": "while(($key, $value) = each(%$_)){\n    print \"$value is $key\\n\" ;\n}",
            "title": "Iterate a hash"
        },
        {
            "location": "/perl/#print-out-a-file-with-line-numbers",
            "text": "cat ~/.bash_history | perl -nle 'print \"$.\\t$_\";'  This should probably be done with  nl -ba .bash_history  instead.",
            "title": "Print out a file with line numbers"
        },
        {
            "location": "/perl/#edit-a-file-in-place",
            "text": "To change all instances of \"foo\" to \"bar\":  perl -i -pe 's/foo/bar/g' filename.txt",
            "title": "Edit a file in-place"
        },
        {
            "location": "/perl/#remove-blank-lines-from-a-file",
            "text": "perl -pi -e \"s/^\\n//\" file.txt",
            "title": "Remove blank lines from a file"
        },
        {
            "location": "/perl/#remove-lines-from-a-file-that-match-a-certain-regex",
            "text": "perl -i -pe 'if ($_ =~ m/string to remove/ ){$_ = \"\";}' filename.txt",
            "title": "Remove lines from a file that match a certain regex"
        },
        {
            "location": "/perl/#sort-a-line-by-spaces",
            "text": "See  bash  for a bash-only way  echo -n \"whiskey tango foxtrot \" \\\n| perl -e '\n  $/=\" \" ;\n  @foo = <STDIN> ;\n  print (sort(@foo)) ;\n  print \"\\n\" ;\n'",
            "title": "Sort a line by spaces"
        },
        {
            "location": "/perl/#sort-records-in-a-file-that-are-separated-by-a-blank-line",
            "text": "#!/usr/bin/perl\n$/ = \"\\n\\n\" ;\nmy @input = (<STDIN>) ;\n\nmy @sorted = sort { lc($a) cmp lc($b) } @input ;\n\nforeach (@sorted) {\n  if (length($_) > 10) { print \"$_\"; }\n}",
            "title": "Sort records in a file that are separated by a blank line"
        },
        {
            "location": "/perl/#subtract-two-from-the-last-octet-of-a-mac-address",
            "text": "for X in 24:b6:fd:ff:b7:f{{a..f},{0..9}} ; do\n  echo -n \"${X} - 2 = \" ;\n  echo ${X} \\\n  | perl -ne '\n    @foo = split(\":\",$_) ;\n    $foo[5] = sprintf(\"%02x\", (hex($foo[5]) - 2)) ;\n    $new = join(\":\",@foo) ;\n    print \"$new\\n\" ;\n  ' ;\ndone ;",
            "title": "Subtract two from the last octet of a MAC address"
        },
        {
            "location": "/perl/#add-one-to-the-last-octet-of-a-mac-address",
            "text": "for X in 24:b6:fd:ff:b7:c{{a..f},{0..9}} ; do\n  echo ${X} \\\n  | perl -ne '\n    @foo = split(\":\",$_) ;\n    $foo[5] = sprintf(\"%02x\", (hex($foo[5]) + 1)) ;\n    $new = join(\":\",@foo) ;\n    print \"$new\\n\";\n  ' ;\ndone ;",
            "title": "Add one to the last octet of a MAC address"
        },
        {
            "location": "/pgp/",
            "text": "\"Pretty Good Privacy (PGP) is an encryption program that provides cryptographic privacy and authentication for data communication. PGP is often used for signing, encrypting, and decrypting texts, e-mails, files, directories, and whole disk partitions and to increase the security of e-mail communications. It was created by Phil Zimmermann in 1991.\" \u2013 \nhttps://en.wikipedia.org/wiki/Pretty_Good_Privacy\n\n\n\"GNU Privacy Guard (GnuPG or GPG) is a free software replacement for Symantec's PGP cryptographic software suite. GnuPG is compliant with RFC 4880, which is the IETF standards track specification of OpenPGP. Modern versions of PGP and Veridis' Filecrypt are interoperable with GnuPG and other OpenPGP-compliant systems.\" \u2013 \nhttps://en.wikipedia.org/wiki/GNU_Privacy_Guard\n\n\nLinks\n\n\nTechnology\n\n\n\n\nThe GNU Privacy Guard\n\n\nCreating a new GPG key\n\n\nHow to create a PGP/GPG-key free of SHA-1\n\n\n\n\nWeb of Trust\n\n\n\n\nA draft guide to organizing or participating in a PGP key signing party\n\n\nOpenPGP key paper slip generator\n\n\nPIUS: The PGP Individual UID Signer\n\n\n\n\nPhilosophy\n\n\n\n\nOp-ed: I'm throwing in the towel on PGP, and I work in security\n\n\nOp-ed: Why I'm not giving up on PGP",
            "title": "Pgp"
        },
        {
            "location": "/pgp/#links",
            "text": "",
            "title": "Links"
        },
        {
            "location": "/pgp/#technology",
            "text": "The GNU Privacy Guard  Creating a new GPG key  How to create a PGP/GPG-key free of SHA-1",
            "title": "Technology"
        },
        {
            "location": "/pgp/#web-of-trust",
            "text": "A draft guide to organizing or participating in a PGP key signing party  OpenPGP key paper slip generator  PIUS: The PGP Individual UID Signer",
            "title": "Web of Trust"
        },
        {
            "location": "/pgp/#philosophy",
            "text": "Op-ed: I'm throwing in the towel on PGP, and I work in security  Op-ed: Why I'm not giving up on PGP",
            "title": "Philosophy"
        },
        {
            "location": "/philips-hue/",
            "text": "\"Philips Hue is your personal wireless lighting system that lets you easily control your light and create the right ambiance for every moment.\" - \nhttps://www2.meethue.com\n\n\nSiri integration\n\n\nSiri knows the names of all of the \nX11 colors",
            "title": "Philips hue"
        },
        {
            "location": "/philips-hue/#siri-integration",
            "text": "Siri knows the names of all of the  X11 colors",
            "title": "Siri integration"
        },
        {
            "location": "/php/",
            "text": "The PHP scripting language.\n\n\nCode Guidelines\n\n\n\n\nThe PEAR code guidelines are pretty good - \nhttp://pear.activeventure.com/standards.html\n\n\nEven better coding standards - \nhttps://github.com/php-fig/fig-standards/blob/master/accepted/PSR-1-basic-coding-standard.md\n\n\n\n\nExamples\n\n\nConvert date formats\n\n\nThis converts mysql time to epoch unix timestamp and back \n$timestamp = strtotime($mysqltime); echo date(\"Y-m-d H:i:s\", $timestamp);\n\n\nRun code from CLI\n\n\nphp -r \"phpinfo();\"\n\n\n\n\nShow php CLI env vars\n\n\nThis shows the location of the ini file used for CLI. \nphp -i\n\n\nEnable Errors\n\n\nSet \ndisplay_errors = On\n in php.ini, or in a php file add:\n\n\nerror_reporting(E_ALL);\nini_set('display_errors', 1);\n\n\n\n\nDisable timeout\n\n\nset_time_limit(0);\nini_set ('max_execution_time', 0);\n\n\n\n\nRandom numbers\n\n\nrand() ; # random int\nrand(1,10) ; # random int between 1 and 10\nrand(100,1000)/100 ; # workaround for generating floats with 2 decimal points",
            "title": "Php"
        },
        {
            "location": "/php/#code-guidelines",
            "text": "The PEAR code guidelines are pretty good -  http://pear.activeventure.com/standards.html  Even better coding standards -  https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-1-basic-coding-standard.md",
            "title": "Code Guidelines"
        },
        {
            "location": "/php/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/php/#convert-date-formats",
            "text": "This converts mysql time to epoch unix timestamp and back  $timestamp = strtotime($mysqltime); echo date(\"Y-m-d H:i:s\", $timestamp);",
            "title": "Convert date formats"
        },
        {
            "location": "/php/#run-code-from-cli",
            "text": "php -r \"phpinfo();\"",
            "title": "Run code from CLI"
        },
        {
            "location": "/php/#show-php-cli-env-vars",
            "text": "This shows the location of the ini file used for CLI.  php -i",
            "title": "Show php CLI env vars"
        },
        {
            "location": "/php/#enable-errors",
            "text": "Set  display_errors = On  in php.ini, or in a php file add:  error_reporting(E_ALL);\nini_set('display_errors', 1);",
            "title": "Enable Errors"
        },
        {
            "location": "/php/#disable-timeout",
            "text": "set_time_limit(0);\nini_set ('max_execution_time', 0);",
            "title": "Disable timeout"
        },
        {
            "location": "/php/#random-numbers",
            "text": "rand() ; # random int\nrand(1,10) ; # random int between 1 and 10\nrand(100,1000)/100 ; # workaround for generating floats with 2 decimal points",
            "title": "Random numbers"
        },
        {
            "location": "/plex/",
            "text": "Plex\n is a media center system that runs on a \nvariety of platforms\n including Linux, Roku, macOS, iOS, tvOS, and a variety of smart TVs.\n\n\nLinks\n\n\n\n\nDeveloper Channel: A Beginner's Guide to v2.1\n\n\nDeveloper Channel: Using Chrome's Built-In Debugger for Channel Development",
            "title": "Plex"
        },
        {
            "location": "/plex/#links",
            "text": "Developer Channel: A Beginner's Guide to v2.1  Developer Channel: Using Chrome's Built-In Debugger for Channel Development",
            "title": "Links"
        },
        {
            "location": "/powershell/",
            "text": "PowerShell is a shell for Windows operating systems, and it was ported to Linux in 2016.\n\n\nhttps://github.com/PowerShell/PowerShell/\n\n\nProfile.ps1\n\n\nOn startup, powershell will run any .ps1 files it finds in the WindowsPowerShell directory under my documents. There is allegedly a Profile.ps1 file in there by default.\n\n\n$env:Path = \"c:\\Users\\dhoherd\\Dropbox\\GWOS\\Scripts;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\\"\n\n\n\n\nTricks\n\n\nRestart a remote computer\n\n\nRestart-Computer remotehostname -Force\n\n\nFind a command that matches a substring\n\n\nget-command *time*\n\n\nGet help on commands that match a substring\n\n\nget-help *time*\n\n\nShow ACLs of the current dir\n\n\nget-acl | format-list\n\n\nShow system BIOS information\n\n\nGet-WmiObject -ComputerName hostname win32_bios\n\n\nShow object methods\n\n\n$foo | Get-Member\n\n\nBrowse the registry\n\n\nSet-Location HKCU:\\Software\\Microsoft\\Windows\\\nGet-ChildItem\n\n\n\n\nShow top processes\n\n\nwhile (1) { ps | sort -desc cpu | select -first 30; sleep -seconds 1; cls }\n\n\nBrowse the Cert store\n\n\nSet-Location cert:\\CurrentUser\\\nGet-ChildItem\n\n\n\n\nGet a list of stopped services\n\n\nGet-Service | Where-Object { $_.Status -eq \"Stopped\" }\n\n\nCompare two objects\n\n\nThis will only show the lines that are not common:\n\n\nCompare-Object $(Get-VIPrivilege -role admin) $(Get-VIPrivilege -role member)\n\n\nSave object to a csv\n\n\nGet-Process | Export-Csv -Encoding unicode processes.csv\n\n\n\n\nLoad object from a csv and parse it\n\n\nImport-Csv ./processes.csv | Where-Object { $_.Name -like \"*systemd*\" } | Select-Object -last 10 | Format-Table\n\n\n\n\nReplacement for unix tail\n\n\ntail filename\n\n\nGet-Content [filename] | Select-Object -Last 10\n\n\ntail -f\n\n\nGet-Content -Path \"C:\\scripts\\test.txt\" -Wait\n\n\nReplacement for unix wc\n\n\nGet-Content test.csv | Measure-Object -line -word -character\n\n\nReplacement for unix time\n\n\nMeasure-Command { Sleep 5 }\n\n\nReplacement for unix grep -B2 -A1\n\n\nGet-Content test.csv | Select-String \"searchstring\" -Context 2,1 -CaseSensitive\n\n\nSee Also\n\n\n\n\nhttp://poshcode.org/\n - Great PSH site\n\n\nPowerCLI - VMware CLI\n\n\nbuilt on PSH\n\n\nhttp://support.microsoft.com/kb/968929\n - download link for\n\n\nPowerShell and extras\n\n\nAD integration through Active Directory Web Services (ADWS) -\n\n\nhttp://www.microsoft.com/en-us/download/details.aspx?id=2852\n\n\nSome PSH videos - \nhttp://www.blkmtn.org/TechEd-2012-Videos",
            "title": "Powershell"
        },
        {
            "location": "/powershell/#profileps1",
            "text": "On startup, powershell will run any .ps1 files it finds in the WindowsPowerShell directory under my documents. There is allegedly a Profile.ps1 file in there by default.  $env:Path = \"c:\\Users\\dhoherd\\Dropbox\\GWOS\\Scripts;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\\"",
            "title": "Profile.ps1"
        },
        {
            "location": "/powershell/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/powershell/#restart-a-remote-computer",
            "text": "Restart-Computer remotehostname -Force",
            "title": "Restart a remote computer"
        },
        {
            "location": "/powershell/#find-a-command-that-matches-a-substring",
            "text": "get-command *time*",
            "title": "Find a command that matches a substring"
        },
        {
            "location": "/powershell/#get-help-on-commands-that-match-a-substring",
            "text": "get-help *time*",
            "title": "Get help on commands that match a substring"
        },
        {
            "location": "/powershell/#show-acls-of-the-current-dir",
            "text": "get-acl | format-list",
            "title": "Show ACLs of the current dir"
        },
        {
            "location": "/powershell/#show-system-bios-information",
            "text": "Get-WmiObject -ComputerName hostname win32_bios",
            "title": "Show system BIOS information"
        },
        {
            "location": "/powershell/#show-object-methods",
            "text": "$foo | Get-Member",
            "title": "Show object methods"
        },
        {
            "location": "/powershell/#browse-the-registry",
            "text": "Set-Location HKCU:\\Software\\Microsoft\\Windows\\\nGet-ChildItem",
            "title": "Browse the registry"
        },
        {
            "location": "/powershell/#show-top-processes",
            "text": "while (1) { ps | sort -desc cpu | select -first 30; sleep -seconds 1; cls }",
            "title": "Show top processes"
        },
        {
            "location": "/powershell/#browse-the-cert-store",
            "text": "Set-Location cert:\\CurrentUser\\\nGet-ChildItem",
            "title": "Browse the Cert store"
        },
        {
            "location": "/powershell/#get-a-list-of-stopped-services",
            "text": "Get-Service | Where-Object { $_.Status -eq \"Stopped\" }",
            "title": "Get a list of stopped services"
        },
        {
            "location": "/powershell/#compare-two-objects",
            "text": "This will only show the lines that are not common:  Compare-Object $(Get-VIPrivilege -role admin) $(Get-VIPrivilege -role member)",
            "title": "Compare two objects"
        },
        {
            "location": "/powershell/#save-object-to-a-csv",
            "text": "Get-Process | Export-Csv -Encoding unicode processes.csv",
            "title": "Save object to a csv"
        },
        {
            "location": "/powershell/#load-object-from-a-csv-and-parse-it",
            "text": "Import-Csv ./processes.csv | Where-Object { $_.Name -like \"*systemd*\" } | Select-Object -last 10 | Format-Table",
            "title": "Load object from a csv and parse it"
        },
        {
            "location": "/powershell/#replacement-for-unix-tail",
            "text": "tail filename  Get-Content [filename] | Select-Object -Last 10  tail -f  Get-Content -Path \"C:\\scripts\\test.txt\" -Wait",
            "title": "Replacement for unix tail"
        },
        {
            "location": "/powershell/#replacement-for-unix-wc",
            "text": "Get-Content test.csv | Measure-Object -line -word -character",
            "title": "Replacement for unix wc"
        },
        {
            "location": "/powershell/#replacement-for-unix-time",
            "text": "Measure-Command { Sleep 5 }",
            "title": "Replacement for unix time"
        },
        {
            "location": "/powershell/#replacement-for-unix-grep-b2-a1",
            "text": "Get-Content test.csv | Select-String \"searchstring\" -Context 2,1 -CaseSensitive",
            "title": "Replacement for unix grep -B2 -A1"
        },
        {
            "location": "/powershell/#see-also",
            "text": "http://poshcode.org/  - Great PSH site  PowerCLI - VMware CLI  built on PSH  http://support.microsoft.com/kb/968929  - download link for  PowerShell and extras  AD integration through Active Directory Web Services (ADWS) -  http://www.microsoft.com/en-us/download/details.aspx?id=2852  Some PSH videos -  http://www.blkmtn.org/TechEd-2012-Videos",
            "title": "See Also"
        },
        {
            "location": "/powertop/",
            "text": "\"PowerTOP is a Linux tool to diagnose issues with power consumption and power management.\" - \nhttps://01.org/powertop/\n\n\nExamples\n\n\nGenerate an html power report\n\n\npowertop\u00a0--html=powertop.html\n\n\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Powertop"
        },
        {
            "location": "/powertop/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/powertop/#generate-an-html-power-report",
            "text": "powertop\u00a0--html=powertop.html",
            "title": "Generate an html power report"
        },
        {
            "location": "/powertop/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/procurve/",
            "text": "Procurve\n switches from \nHP\n offer cheap layer 2 and layer 3 switching.\n\n\nCopy config files\n\n\nscp\u00a0user@switch:cfg/startup-config\u00a0./\n\n\nscp\u00a0user@switch:cfg/running-config\u00a0./\n\n\nFirmware update\n\n\n\n\nVia ssh: \nlinuxclient$ scp /path/to/image user@switch-hostname:/os/primary\n\n\nVia tftp: \nswitch# copy tftp flash 172.28.115.151 flashfilename.swi primary\n \nThis doesn't always work, try scp if it fails.\n\n\n\n\nThen on the switch...\n\n\nsystem\u00a0boot\u00a0flash\u00a0primary\n\n\nConfig Examples\n\n\nSet an IP# for the default VLAN\n\n\ninterface\u00a0vlan\u00a01\u00a0ip\u00a0address\u00a0172.28.115.234\u00a0255.255.255.0\nip\u00a0default-gateway\u00a0172.28.115.1\n\n\n\n\nSet up additional VLANs\n\n\nvlan\u00a0100\u00a0untagged\u00a02  \nvlan\u00a0100\u00a0ip\u00a0address\u00a0172.28.100.1  \nvlan\u00a0102\u00a0untagged\u00a03  \nvlan\u00a0102\u00a0ip\u00a0address\u00a0172.28.102.1\n\n\n\n\nEnable routing between connected networks\n\n\nip\u00a0routing\n\n\nSet up SNTP clock\n\n\nsntp\u00a0server\u00a0172.28.111.16\u00a0  \ntimesync\u00a0sntp\u00a0  \nsntp\u00a0120  \nsntp\u00a0unicast\n\n\n\n\nAlter DST settings\n\n\ntime\u00a0daylight-time-rule\u00a0User-defined\u00a0begin-date\u00a03/8\u00a0end-date\u00a011/1\n\n\nEnable SSH\n\n\ncrypto\u00a0key\u00a0generate\u00a0ssh  \nip\u00a0ssh  \nip\u00a0ssh\u00a0version\u00a02  \nip\u00a0ssh\u00a0filetransfer\n\n\n\n\nDisable telnet\n\n\nno\u00a0telnet-server\n\n\nSet up snmp\n\n\nsnmp-server\u00a0community\u00a0\"foobar\"\u00a0Operator\n\n\nSet up a VLAN 112 port group\n\n\nvlan\u00a0112\u00a0untagged\u00a06-12\n\n\nSet two groups of ports as a trunks (eg: to use with VMware in static LACP)\n\n\ntrunk\u00a01-4\u00a0trk1\u00a0trunk  \ntrunk\u00a05-8\u00a0trk2\u00a0trunk\n\n\n\n\nSet up VLAN multiplexing\n\n\nvlan\u00a0114\u00a0tagged\u00a024  \nvlan\u00a0115\u00a0tagged\u00a024  \nvlan\u00a0114\u00a0tagged\u00a0Trk1  \nvlan\u00a0115\u00a0tagged\u00a0Trk1\n\n\n\n\nSee Also\n\n\n\n\nPlenty of config examples: \nhttps://www.cs.uwaterloo.ca\n\n\n\n\nExample Config\n\n\nhostname \"HP-CORE-0\"\nsnmp-server location \"Cup1-Closet1\"\nmax-vlans 64\ntime timezone -480\ntime daylight-time-rule User-defined begin-date 3/8 end-date 11/1\nconsole inactivity-timer 5\nno web-management\nweb-management ssl\nno telnet-server\ninterface 2\n   name \"Load Test Cluster\"\nexit\ninterface 5\n   name \"hq-vm-1\"\nexit\ninterface 6\n   name \"hq-vm-1\"\nexit\ninterface 8\n   name \"beast\"\nexit\ninterface 10\n   name \"Winserv\"\nexit\ninterface 12\n   name \"IT\"\nexit\ninterface 13\n   name \"Services\"\nexit\ninterface 14\n   name \"IT\"\nexit\ninterface 15\n   name \"IT\"\nexit\ninterface 16\n   name \"IT\"\nexit\ninterface 17\n   name \"beast\"\nexit\ninterface 18\n   name \"VPN\"\nexit\ninterface 19\n   name \"IT\"\nexit\ninterface 20\n   name \"IT\"\nexit\ninterface 21\n   name \"Radio Station\"\nexit\ninterface 22\n   name \"AT&T Network\"\nexit\ninterface 23\n   name \"HP-CORE trunk\"\nexit\ninterface 24\n   name \"Jun1-trunk\"\nexit\nip default-gateway 10.8.100.1\nsntp server 10.8.5.220\nip routing\ntimesync sntp\nsntp unicast\nsnmp-server community \"public\" Unrestricted\nsnmp-server host 10.8.5.189 \"public\"\nvlan 1\n   name \"DEFAULT_VLAN\"\n   untagged 4,14\n   no ip address\n   tagged 23\n   no untagged 1-3,5-13,15-22,24\n   exit\nvlan 101\n   name \"Services\"\n   untagged 3,8,10,15,19\n   ip address 10.8.1.1 255.255.255.0\n   ip helper-address 10.8.5.220\n   tagged 2,5-6,23-24\n   exit\nvlan 102\n   name \"LoadTest\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 2,5-6,15,23-24\n   exit\nvlan 103\n   name \"QATest\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23\n   exit\nvlan 104\n   name \"PS\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 105\n   name \"IT\"\n   untagged 1,5-6,9,12-13,16,20\n   ip address 10.8.5.1 255.255.255.0\n   ip helper-address 10.8.5.220\n   tagged 2,15,23-24\n   exit\nvlan 110\n   name \"Wireless\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 111\n   name \"Eng\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 113\n   name \"SW2\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 23\n   exit\nvlan 112\n   name \"SW1\"\n   untagged 21\n   ip address 10.8.12.1 255.255.255.0\n   ip helper-address 10.8.5.220\n   tagged 23\n   exit\nvlan 100\n   name \"Backbone\"\n   ip address 10.8.100.100 255.255.255.0\n   tagged 23-24\n   exit\nvlan 114\n   name \"Upstairs\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 23-24\n   exit\nvlan 106\n   name \"VPN\"\n   untagged 18\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 188\n   name \"OldNet\"\n   untagged 11,17\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 23-24\n   exit\nvlan 42\n   name \"ATT\"\n   untagged 22\n   tagged 23-24\n   exit\nvlan 107\n   name \"DMZ\"\n   untagged 7\n   ip helper-address 10.8.5.220\n   tagged 15,24\n   exit\nvlan 109\n   name \"Jail\"\n   tagged 23-24\n   exit\ndhcp-relay option 82 keep\nip route 0.0.0.0 0.0.0.0 10.8.100.1\nip route 10.8.11.0 255.255.255.0 10.8.100.101\nip route 10.8.3.0 255.255.255.0 10.8.100.101\nip route 10.172.188.0 255.255.255.0 10.8.100.1\nip route 10.8.13.0 255.255.255.0 10.8.100.101\nip route 10.8.2.0 255.255.255.0 10.8.100.1\nip route 10.8.10.0 255.255.255.0 10.8.100.1\nip route 10.8.7.0 255.255.255.0 10.8.100.1\nip route 10.8.4.0 255.255.255.0 10.8.100.1\nip route 10.8.14.0 255.255.255.0 10.8.100.102\nip route 10.8.9.0 255.255.255.0 10.8.100.1\nstack commander \"HP-CORE\"\nstack auto-grab\nstack member 1 mac-address 0016b90b4ea0\nstack member 2 mac-address 0016b968df40\nspanning-tree\nip ssh\nip ssh filetransfer\nno tftp client\nno tftp server\npassword manager\npassword operator",
            "title": "Procurve"
        },
        {
            "location": "/procurve/#copy-config-files",
            "text": "scp\u00a0user@switch:cfg/startup-config\u00a0./  scp\u00a0user@switch:cfg/running-config\u00a0./",
            "title": "Copy config files"
        },
        {
            "location": "/procurve/#firmware-update",
            "text": "Via ssh:  linuxclient$ scp /path/to/image user@switch-hostname:/os/primary  Via tftp:  switch# copy tftp flash 172.28.115.151 flashfilename.swi primary   This doesn't always work, try scp if it fails.   Then on the switch...  system\u00a0boot\u00a0flash\u00a0primary",
            "title": "Firmware update"
        },
        {
            "location": "/procurve/#config-examples",
            "text": "",
            "title": "Config Examples"
        },
        {
            "location": "/procurve/#set-an-ip-for-the-default-vlan",
            "text": "interface\u00a0vlan\u00a01\u00a0ip\u00a0address\u00a0172.28.115.234\u00a0255.255.255.0\nip\u00a0default-gateway\u00a0172.28.115.1",
            "title": "Set an IP# for the default VLAN"
        },
        {
            "location": "/procurve/#set-up-additional-vlans",
            "text": "vlan\u00a0100\u00a0untagged\u00a02  \nvlan\u00a0100\u00a0ip\u00a0address\u00a0172.28.100.1  \nvlan\u00a0102\u00a0untagged\u00a03  \nvlan\u00a0102\u00a0ip\u00a0address\u00a0172.28.102.1",
            "title": "Set up additional VLANs"
        },
        {
            "location": "/procurve/#enable-routing-between-connected-networks",
            "text": "ip\u00a0routing",
            "title": "Enable routing between connected networks"
        },
        {
            "location": "/procurve/#set-up-sntp-clock",
            "text": "sntp\u00a0server\u00a0172.28.111.16\u00a0  \ntimesync\u00a0sntp\u00a0  \nsntp\u00a0120  \nsntp\u00a0unicast",
            "title": "Set up SNTP clock"
        },
        {
            "location": "/procurve/#alter-dst-settings",
            "text": "time\u00a0daylight-time-rule\u00a0User-defined\u00a0begin-date\u00a03/8\u00a0end-date\u00a011/1",
            "title": "Alter DST settings"
        },
        {
            "location": "/procurve/#enable-ssh",
            "text": "crypto\u00a0key\u00a0generate\u00a0ssh  \nip\u00a0ssh  \nip\u00a0ssh\u00a0version\u00a02  \nip\u00a0ssh\u00a0filetransfer",
            "title": "Enable SSH"
        },
        {
            "location": "/procurve/#disable-telnet",
            "text": "no\u00a0telnet-server",
            "title": "Disable telnet"
        },
        {
            "location": "/procurve/#set-up-snmp",
            "text": "snmp-server\u00a0community\u00a0\"foobar\"\u00a0Operator",
            "title": "Set up snmp"
        },
        {
            "location": "/procurve/#set-up-a-vlan-112-port-group",
            "text": "vlan\u00a0112\u00a0untagged\u00a06-12",
            "title": "Set up a VLAN 112 port group"
        },
        {
            "location": "/procurve/#set-two-groups-of-ports-as-a-trunks-eg-to-use-with-vmware-in-static-lacp",
            "text": "trunk\u00a01-4\u00a0trk1\u00a0trunk  \ntrunk\u00a05-8\u00a0trk2\u00a0trunk",
            "title": "Set two groups of ports as a trunks (eg: to use with VMware in static LACP)"
        },
        {
            "location": "/procurve/#set-up-vlan-multiplexing",
            "text": "vlan\u00a0114\u00a0tagged\u00a024  \nvlan\u00a0115\u00a0tagged\u00a024  \nvlan\u00a0114\u00a0tagged\u00a0Trk1  \nvlan\u00a0115\u00a0tagged\u00a0Trk1",
            "title": "Set up VLAN multiplexing"
        },
        {
            "location": "/procurve/#see-also",
            "text": "Plenty of config examples:  https://www.cs.uwaterloo.ca",
            "title": "See Also"
        },
        {
            "location": "/procurve/#example-config",
            "text": "hostname \"HP-CORE-0\"\nsnmp-server location \"Cup1-Closet1\"\nmax-vlans 64\ntime timezone -480\ntime daylight-time-rule User-defined begin-date 3/8 end-date 11/1\nconsole inactivity-timer 5\nno web-management\nweb-management ssl\nno telnet-server\ninterface 2\n   name \"Load Test Cluster\"\nexit\ninterface 5\n   name \"hq-vm-1\"\nexit\ninterface 6\n   name \"hq-vm-1\"\nexit\ninterface 8\n   name \"beast\"\nexit\ninterface 10\n   name \"Winserv\"\nexit\ninterface 12\n   name \"IT\"\nexit\ninterface 13\n   name \"Services\"\nexit\ninterface 14\n   name \"IT\"\nexit\ninterface 15\n   name \"IT\"\nexit\ninterface 16\n   name \"IT\"\nexit\ninterface 17\n   name \"beast\"\nexit\ninterface 18\n   name \"VPN\"\nexit\ninterface 19\n   name \"IT\"\nexit\ninterface 20\n   name \"IT\"\nexit\ninterface 21\n   name \"Radio Station\"\nexit\ninterface 22\n   name \"AT&T Network\"\nexit\ninterface 23\n   name \"HP-CORE trunk\"\nexit\ninterface 24\n   name \"Jun1-trunk\"\nexit\nip default-gateway 10.8.100.1\nsntp server 10.8.5.220\nip routing\ntimesync sntp\nsntp unicast\nsnmp-server community \"public\" Unrestricted\nsnmp-server host 10.8.5.189 \"public\"\nvlan 1\n   name \"DEFAULT_VLAN\"\n   untagged 4,14\n   no ip address\n   tagged 23\n   no untagged 1-3,5-13,15-22,24\n   exit\nvlan 101\n   name \"Services\"\n   untagged 3,8,10,15,19\n   ip address 10.8.1.1 255.255.255.0\n   ip helper-address 10.8.5.220\n   tagged 2,5-6,23-24\n   exit\nvlan 102\n   name \"LoadTest\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 2,5-6,15,23-24\n   exit\nvlan 103\n   name \"QATest\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23\n   exit\nvlan 104\n   name \"PS\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 105\n   name \"IT\"\n   untagged 1,5-6,9,12-13,16,20\n   ip address 10.8.5.1 255.255.255.0\n   ip helper-address 10.8.5.220\n   tagged 2,15,23-24\n   exit\nvlan 110\n   name \"Wireless\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 111\n   name \"Eng\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 113\n   name \"SW2\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 23\n   exit\nvlan 112\n   name \"SW1\"\n   untagged 21\n   ip address 10.8.12.1 255.255.255.0\n   ip helper-address 10.8.5.220\n   tagged 23\n   exit\nvlan 100\n   name \"Backbone\"\n   ip address 10.8.100.100 255.255.255.0\n   tagged 23-24\n   exit\nvlan 114\n   name \"Upstairs\"\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 23-24\n   exit\nvlan 106\n   name \"VPN\"\n   untagged 18\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 15,23-24\n   exit\nvlan 188\n   name \"OldNet\"\n   untagged 11,17\n   no ip address\n   ip helper-address 10.8.5.220\n   tagged 23-24\n   exit\nvlan 42\n   name \"ATT\"\n   untagged 22\n   tagged 23-24\n   exit\nvlan 107\n   name \"DMZ\"\n   untagged 7\n   ip helper-address 10.8.5.220\n   tagged 15,24\n   exit\nvlan 109\n   name \"Jail\"\n   tagged 23-24\n   exit\ndhcp-relay option 82 keep\nip route 0.0.0.0 0.0.0.0 10.8.100.1\nip route 10.8.11.0 255.255.255.0 10.8.100.101\nip route 10.8.3.0 255.255.255.0 10.8.100.101\nip route 10.172.188.0 255.255.255.0 10.8.100.1\nip route 10.8.13.0 255.255.255.0 10.8.100.101\nip route 10.8.2.0 255.255.255.0 10.8.100.1\nip route 10.8.10.0 255.255.255.0 10.8.100.1\nip route 10.8.7.0 255.255.255.0 10.8.100.1\nip route 10.8.4.0 255.255.255.0 10.8.100.1\nip route 10.8.14.0 255.255.255.0 10.8.100.102\nip route 10.8.9.0 255.255.255.0 10.8.100.1\nstack commander \"HP-CORE\"\nstack auto-grab\nstack member 1 mac-address 0016b90b4ea0\nstack member 2 mac-address 0016b968df40\nspanning-tree\nip ssh\nip ssh filetransfer\nno tftp client\nno tftp server\npassword manager\npassword operator",
            "title": "Example Config"
        },
        {
            "location": "/protobuf/",
            "text": "\"Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data\" - \nhttps://developers.google.com/protocol-buffers/\n\n\n\"Google's data interchange format\" - \nhttps://github.com/google/protobuf",
            "title": "Protobuf"
        },
        {
            "location": "/ps/",
            "text": "ps\n shows a list of processes in a *nix system.\n\n\nExamples\n\n\nshow the exact command used to start all process\n\n\nps axwwo command\n\n\n\n\nshow a process tree view\n\n\nps auxf\n\n\n\n\nshow only all running processes\n\n\nThis excludes sleeping processes and threads.\n\n\nps auxr\n\n\n\n\nShow process list sorted by process start time\n\n\nps hax -o lstart,pid,args |\n  while read -r a b c d e f g ; do\n    echo \"$(date -d \"$a $b $c $d $e\" \"+%F %T%z\") $f $g\" ;\n  done |\n  sort",
            "title": "Ps"
        },
        {
            "location": "/ps/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/ps/#show-the-exact-command-used-to-start-all-process",
            "text": "ps axwwo command",
            "title": "show the exact command used to start all process"
        },
        {
            "location": "/ps/#show-a-process-tree-view",
            "text": "ps auxf",
            "title": "show a process tree view"
        },
        {
            "location": "/ps/#show-only-all-running-processes",
            "text": "This excludes sleeping processes and threads.  ps auxr",
            "title": "show only all running processes"
        },
        {
            "location": "/ps/#show-process-list-sorted-by-process-start-time",
            "text": "ps hax -o lstart,pid,args |\n  while read -r a b c d e f g ; do\n    echo \"$(date -d \"$a $b $c $d $e\" \"+%F %T%z\") $f $g\" ;\n  done |\n  sort",
            "title": "Show process list sorted by process start time"
        },
        {
            "location": "/ps_mem/",
            "text": "\"A utility to accurately report the in core memory usage for a program.\" - \nhttps://github.com/pixelb/ps_mem\n\n\nUsage examples\n\n\nSimple usage\n\n\n$ sudo ps_mem\n Private  +   Shared  =  RAM used    Program\n\n144.0 KiB +  12.5 KiB = 156.5 KiB    acpid\n144.0 KiB +  31.5 KiB = 175.5 KiB    hald-addon-acpi\n160.0 KiB +  56.5 KiB = 216.5 KiB    hald-addon-input\n...snip...\n 17.9 MiB + 101.0 KiB =  18.0 MiB    mysqld [updated]\n 25.5 MiB + 516.5 KiB =  26.0 MiB    salt-minion\n 31.6 MiB + 730.0 KiB =  32.3 MiB    python (2)\n 41.0 MiB + 309.5 KiB =  41.3 MiB    ruby\n 45.5 MiB +  36.0 KiB =  45.6 MiB    init\n 48.9 MiB +   4.1 MiB =  53.0 MiB    ssh (48)\n 57.3 MiB +   2.5 MiB =  59.7 MiB    bash (114)\n115.0 MiB +  86.0 KiB = 115.1 MiB    named\n148.3 MiB + 132.5 KiB = 148.4 MiB    java\n  1.4 GiB + 449.5 KiB =   1.4 GiB    screen (15)\n---------------------------------\n                          2.0 GiB\n=================================",
            "title": "Ps mem"
        },
        {
            "location": "/ps_mem/#usage-examples",
            "text": "",
            "title": "Usage examples"
        },
        {
            "location": "/ps_mem/#simple-usage",
            "text": "$ sudo ps_mem\n Private  +   Shared  =  RAM used    Program\n\n144.0 KiB +  12.5 KiB = 156.5 KiB    acpid\n144.0 KiB +  31.5 KiB = 175.5 KiB    hald-addon-acpi\n160.0 KiB +  56.5 KiB = 216.5 KiB    hald-addon-input\n...snip...\n 17.9 MiB + 101.0 KiB =  18.0 MiB    mysqld [updated]\n 25.5 MiB + 516.5 KiB =  26.0 MiB    salt-minion\n 31.6 MiB + 730.0 KiB =  32.3 MiB    python (2)\n 41.0 MiB + 309.5 KiB =  41.3 MiB    ruby\n 45.5 MiB +  36.0 KiB =  45.6 MiB    init\n 48.9 MiB +   4.1 MiB =  53.0 MiB    ssh (48)\n 57.3 MiB +   2.5 MiB =  59.7 MiB    bash (114)\n115.0 MiB +  86.0 KiB = 115.1 MiB    named\n148.3 MiB + 132.5 KiB = 148.4 MiB    java\n  1.4 GiB + 449.5 KiB =   1.4 GiB    screen (15)\n---------------------------------\n                          2.0 GiB\n=================================",
            "title": "Simple usage"
        },
        {
            "location": "/psp/",
            "text": "Playstation Portable\n\n\nLinks\n\n\n\n\nCustom firmware and homebrew",
            "title": "Psp"
        },
        {
            "location": "/psp/#links",
            "text": "Custom firmware and homebrew",
            "title": "Links"
        },
        {
            "location": "/pssh/",
            "text": "Parallel \nSSH\n tools for running commands on multiple system simultaneously.\n\n\n\n\nhttp://www.theether.org/pssh/\n\n\n\n\nExamples\n\n\nRun a command on hosts contained in a file, showing stdin and stdout\n\n\npssh -h hostnames.txt -i some_command some_arg\n\n\n\n\nRun commands and view results on many hosts\n\n\no=$(date +%F-%T)\npssh -o \"$o\" -h hosts.txt uname -a\ngrep -r . $o\n\n\n\n\nRun two commands on many hosts using bash expansion for host list\n\n\no=$(date +pssh-%T)\npssh -p 50 -t 60 {-H\\ sea-z-app00{1..9},} -o $o 'whoami ; hostname ;'\ngrep -r . $o\n\n\n\n\nInstall a package on many hosts\n\n\nfping < hosts.txt | awk '$3 == \"alive\" {print $1}' > alive.txt\npssh \\\n  -h alive.txt \\\n  -o out_dir \\\n  -l root \\\n  yum -y localinstall ~danielh/rpms/cfengine-community-3.6.2-1.x86_64.rpm\n\n\n\n\nor directly from a db query and fping...\n\n\npssh \\\n  -h <(\n    invdb -d sjc-z-01opsdbw 'select hostname from servers where colo = \"sjc\";' |\n    sort -u |\n    egrep '[0-9]+6[^0-9]' |\n    fping 2> /dev/null |\n    awk '$3 == \"alive\" {print $1}'\n  ) \\\n  -o out_dir \\\n  -l root \\\n  yum -y localinstall ~danielh/rpms/cfengine-community-3.6.2-1.x86_64.rpm\n\n\n\n\nor from mco...\n\n\no=$(date +pssh-%T) ; pssh -O GlobalKnownHostsFile=/dev/null -O UserKnownHostsFile=/dev/null -O StrictHostKeyChecking=no -t300 -p10 -h <(mco find -C role::devbox) -o \"$o\" 'sudo apt-get install -y silversearcher-ag' ; grep -r . \"$o\" ;",
            "title": "Pssh"
        },
        {
            "location": "/pssh/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/pssh/#run-a-command-on-hosts-contained-in-a-file-showing-stdin-and-stdout",
            "text": "pssh -h hostnames.txt -i some_command some_arg",
            "title": "Run a command on hosts contained in a file, showing stdin and stdout"
        },
        {
            "location": "/pssh/#run-commands-and-view-results-on-many-hosts",
            "text": "o=$(date +%F-%T)\npssh -o \"$o\" -h hosts.txt uname -a\ngrep -r . $o",
            "title": "Run commands and view results on many hosts"
        },
        {
            "location": "/pssh/#run-two-commands-on-many-hosts-using-bash-expansion-for-host-list",
            "text": "o=$(date +pssh-%T)\npssh -p 50 -t 60 {-H\\ sea-z-app00{1..9},} -o $o 'whoami ; hostname ;'\ngrep -r . $o",
            "title": "Run two commands on many hosts using bash expansion for host list"
        },
        {
            "location": "/pssh/#install-a-package-on-many-hosts",
            "text": "fping < hosts.txt | awk '$3 == \"alive\" {print $1}' > alive.txt\npssh \\\n  -h alive.txt \\\n  -o out_dir \\\n  -l root \\\n  yum -y localinstall ~danielh/rpms/cfengine-community-3.6.2-1.x86_64.rpm  or directly from a db query and fping...  pssh \\\n  -h <(\n    invdb -d sjc-z-01opsdbw 'select hostname from servers where colo = \"sjc\";' |\n    sort -u |\n    egrep '[0-9]+6[^0-9]' |\n    fping 2> /dev/null |\n    awk '$3 == \"alive\" {print $1}'\n  ) \\\n  -o out_dir \\\n  -l root \\\n  yum -y localinstall ~danielh/rpms/cfengine-community-3.6.2-1.x86_64.rpm  or from mco...  o=$(date +pssh-%T) ; pssh -O GlobalKnownHostsFile=/dev/null -O UserKnownHostsFile=/dev/null -O StrictHostKeyChecking=no -t300 -p10 -h <(mco find -C role::devbox) -o \"$o\" 'sudo apt-get install -y silversearcher-ag' ; grep -r . \"$o\" ;",
            "title": "Install a package on many hosts"
        },
        {
            "location": "/puppet/",
            "text": "Puppet\n\n\n\"Puppet is an open-source configuration management tool. It runs on many Unix-like systems as well as on Microsoft Windows, and includes its own declarative language to describe system configuration.\" - \nhttps://en.wikipedia.org/wiki/Puppet_(software)\n\n\nVideos and links\n\n\n\n\nOverview of Puppet's architecture\n\n\nPuppet Documentation Index\n\n\nIntroduction to Puppet\n\n\nFunction Reference\n\n\nstdlib\n is another good function reference.\n\n\nLanguage: Basics\n\n\nInclude-like vs. resource-like class instantiation\n\n\nStyle Guide\n\n\nVagrant Docs - Puppet Apply Provisioner\n\n\nDownloads\n\n\nPuppetConf 2015\n\n\nDesigning Puppet: Roles/Profiles Pattern\n - based on the blog post \nDesigning Puppet \u2013 Roles and Profiles\n\n\nBuilding a Functional Puppet Workflow Part 2: Roles and Profiles\n\n\nConfiguration Management as Legos\n\n\n\n\nExamples\n\n\nStandalone mode\n\n\n\n\npuppet apply /path/to/manifests\n works, or you can specify a .pp file\n\n\n\n\nShow variables about the host that puppet knows (facts)\n\n\nfacter\n\n\n\n\nShow how puppet interacts with a resource\n\n\npuppet describe cron\n\n\n\n\nShow available puppet types\n\n\npuppet resource --types\n\n\n\n\nShow the puppet code that will create a resource\n\n\n$ puppet resource file /etc/hosts\nfile { '/etc/hosts':\n  ensure  => 'file',\n  content => '{md5}9ffbd726fd5b15de760cc0150d607628',\n  ctime   => 'Wed Apr 01 17:05:59 -0700 2015',\n  group   => '0',\n  mode    => '644',\n  mtime   => 'Wed Apr 01 17:05:59 -0700 2015',\n  owner   => '0',\n  type    => 'file',\n}\n\n\n\n\nTests\n\n\n\n\nhttp://rspec-puppet.com/matchers/\n\n\n\n\nMarionette Collective\n\n\n\"The Marionette Collective, also known as MCollective, is a framework for building server orchestration or parallel job-execution systems. Most users programmatically execute administrative tasks on clusters of servers.\" - \nhttp://docs.puppetlabs.com/mcollective/\n\n\n\n\nOverview of MCollective Components and Configuration\n\n\nInvoking MCollective actions\n\n\nCheatsheet: \nhttps://coderwall.com/p/ig9mxa/mcollective-mco-cheat-sheet\n\n\nVagrant demo: \nhttps://github.com/ripienaar/mcollective-vagrant\n\n\n\n\nmco\n\n\nShow some puppet cluster stats\n\n\nmco puppet summary\nmco puppet count\nmco puppet status\n\n\n\n\nFind a random node in the cluster\n\n\nmco find -1\n\n\n\n\nPing all nodes in the puppet cluster\n\n\nmco ping\n\n\n\n\nShow if a file exists on each host in the cluster\n\n\nmco filemgr -f /srv/nginx status\n\n\n\n\nUse fstat and md5 to detect files needing repair\n\n\nmco find -S \"fstat('/srv/somedir/somefile').md5=/af6db18c6dfa81c294895003e13a2eef/\" > files_needing_attention.txt\npssh -h files_needing_attention.txt) 'do_something_to_the_file'\n\n\n\n\nUse fstat to find hosts where a directory has not been modified recently\n\n\nmco find -S \"fstat('/srv').mtime_seconds<$(date +%s -d '-8 hours')\"\n\n\n\n\nShow stats about which OSes you have\n\n\nmco facts lsbdistdescription\n\n\n\n\nShow all ip addreses on all hosts where a configured IP address matches a regex\n\n\nmco facts all_ipaddresses -F 'all_ipaddresses=~10\\.(56|29)\\.'\n\n\n\n\nShow a report about uptimes over a year\n\n\nmco facts uptime -F 'uptime_days>365' |\nawk '$2 == \"days\" {print}' |\nsort -n -k1 |\ncolumn -t\n\n\n\n\nFind machines where a fact is true\n\n\nmco find is_ec2\n\n\n\n\nWhich is the same as\n\n\nmco find -W is_ec2=true\n\n\n\n\nFind machines that have a certain fact value\n\n\nmco find --with-fact lsbdistcodename=lucid\n\n\n\n\nShow a fact on machines that have a specific fact value\n\n\nmco facts role --with-fact lsbdistcodename=lucid -v\n\n\n\n\nFind ec2 hosts with low uptime\n\n\nmco find -W 'is_ec2=true uptime_seconds<7200'\n\n\n\n\nShow detailed info about a node\n\n\nmco inventory fqdn.example.com\n\n\n\n\nFind nodes that match a config management class\n\n\nmco find -C role::awsadmin\n\n\n\n\nShow the classes for a given host\n\n\nsort /var/lib/puppet/state/classes.txt\n\n\n\n\nKick off a puppet run on all hosts of a certain class\n\n\nThe following two syntaxes are essentially the same, using the same \npuppet\n agent of \nmco\n. The only differences are the use of \nrunall\n vs \nrunonce\n, and the method that performs parallel execution. I'm not sure what difference there is in the code path.\n\n\nmco rpc    -C \"class_boolean\" -F \"fact_name=fact_value\" --batch 10 --agent puppet --action runonce\nmco puppet -C \"class_boolean\" -F \"fact_name=fact_value\" runall 10\n\n\n\n\nShow the status and puppet policy about a package on all hosts\n\n\nmco rpc package status package=openssh-client --discovery-timeout 60 --json\n\n\n\n\nUpgrade an installed package on 10 random web hosts\n\n\nThis upgrades, but does not install if the package is not already present.\n\n\nmco package update 'nginx' -I '/web/' --limit=10\n\n\n\n\nShow breakdown of hosts by OS version by role\n\n\nmco facts -v --wc role::mon lsbdistdescription\n\n\n\n\nUse mco to find packages of a certain version on a certain OS\n\n\nmco rpc package status package=apt -j -F lsbdistcodename=trusty > cache.json\njq -c '.[] | select(.data.ensure == \"1.0.1ubuntu2\") | { version: .data.ensure, hostname: .sender }' cache.json\n\n\n\n\nHiera\n\n\n\"Hiera is a key/value lookup tool for configuration data, built to make Puppet better and let you set node-specific data without repeating yourself.\" - \nhttp://docs.puppetlabs.com/hiera/latest/\n\n\n\n\nhttps://github.com/puppetlabs/hiera\n\n\nhttp://www.craigdunn.org/2011/10/puppet-configuration-variables-and-hiera/\n\n\n\n\nr10k\n\n\nThe suggested workflow for puppet is to use r10k on a control repo to manage the modules on your puppetmaster and the environments it provides. The general idea is that each module is represented by a puppetforge module name or a git repo listed inside of the ambiguously named \nPuppetfile\n. When \nr10k puppetfile install -v\n is run, all modules listed in this file are installed according to their definitions, and all modules that are not in this file are purged. Also, r10k will set up environments based on the git branches of the control repo. This workflow is described in detail at \nManaging and deploying Puppet code\n. It assumes you are not using a \npuppet apply\n type setup, which makes this difficult to follow for people who are playing with this at home in a non-puppetmaster scenario, such as in vagrant or on raspberry pi's.",
            "title": "Puppet"
        },
        {
            "location": "/puppet/#puppet",
            "text": "\"Puppet is an open-source configuration management tool. It runs on many Unix-like systems as well as on Microsoft Windows, and includes its own declarative language to describe system configuration.\" -  https://en.wikipedia.org/wiki/Puppet_(software)",
            "title": "Puppet"
        },
        {
            "location": "/puppet/#videos-and-links",
            "text": "Overview of Puppet's architecture  Puppet Documentation Index  Introduction to Puppet  Function Reference  stdlib  is another good function reference.  Language: Basics  Include-like vs. resource-like class instantiation  Style Guide  Vagrant Docs - Puppet Apply Provisioner  Downloads  PuppetConf 2015  Designing Puppet: Roles/Profiles Pattern  - based on the blog post  Designing Puppet \u2013 Roles and Profiles  Building a Functional Puppet Workflow Part 2: Roles and Profiles  Configuration Management as Legos",
            "title": "Videos and links"
        },
        {
            "location": "/puppet/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/puppet/#standalone-mode",
            "text": "puppet apply /path/to/manifests  works, or you can specify a .pp file",
            "title": "Standalone mode"
        },
        {
            "location": "/puppet/#show-variables-about-the-host-that-puppet-knows-facts",
            "text": "facter",
            "title": "Show variables about the host that puppet knows (facts)"
        },
        {
            "location": "/puppet/#show-how-puppet-interacts-with-a-resource",
            "text": "puppet describe cron",
            "title": "Show how puppet interacts with a resource"
        },
        {
            "location": "/puppet/#show-available-puppet-types",
            "text": "puppet resource --types",
            "title": "Show available puppet types"
        },
        {
            "location": "/puppet/#show-the-puppet-code-that-will-create-a-resource",
            "text": "$ puppet resource file /etc/hosts\nfile { '/etc/hosts':\n  ensure  => 'file',\n  content => '{md5}9ffbd726fd5b15de760cc0150d607628',\n  ctime   => 'Wed Apr 01 17:05:59 -0700 2015',\n  group   => '0',\n  mode    => '644',\n  mtime   => 'Wed Apr 01 17:05:59 -0700 2015',\n  owner   => '0',\n  type    => 'file',\n}",
            "title": "Show the puppet code that will create a resource"
        },
        {
            "location": "/puppet/#tests",
            "text": "http://rspec-puppet.com/matchers/",
            "title": "Tests"
        },
        {
            "location": "/puppet/#marionette-collective",
            "text": "\"The Marionette Collective, also known as MCollective, is a framework for building server orchestration or parallel job-execution systems. Most users programmatically execute administrative tasks on clusters of servers.\" -  http://docs.puppetlabs.com/mcollective/   Overview of MCollective Components and Configuration  Invoking MCollective actions  Cheatsheet:  https://coderwall.com/p/ig9mxa/mcollective-mco-cheat-sheet  Vagrant demo:  https://github.com/ripienaar/mcollective-vagrant",
            "title": "Marionette Collective"
        },
        {
            "location": "/puppet/#mco",
            "text": "",
            "title": "mco"
        },
        {
            "location": "/puppet/#show-some-puppet-cluster-stats",
            "text": "mco puppet summary\nmco puppet count\nmco puppet status",
            "title": "Show some puppet cluster stats"
        },
        {
            "location": "/puppet/#find-a-random-node-in-the-cluster",
            "text": "mco find -1",
            "title": "Find a random node in the cluster"
        },
        {
            "location": "/puppet/#ping-all-nodes-in-the-puppet-cluster",
            "text": "mco ping",
            "title": "Ping all nodes in the puppet cluster"
        },
        {
            "location": "/puppet/#show-if-a-file-exists-on-each-host-in-the-cluster",
            "text": "mco filemgr -f /srv/nginx status",
            "title": "Show if a file exists on each host in the cluster"
        },
        {
            "location": "/puppet/#use-fstat-and-md5-to-detect-files-needing-repair",
            "text": "mco find -S \"fstat('/srv/somedir/somefile').md5=/af6db18c6dfa81c294895003e13a2eef/\" > files_needing_attention.txt\npssh -h files_needing_attention.txt) 'do_something_to_the_file'",
            "title": "Use fstat and md5 to detect files needing repair"
        },
        {
            "location": "/puppet/#use-fstat-to-find-hosts-where-a-directory-has-not-been-modified-recently",
            "text": "mco find -S \"fstat('/srv').mtime_seconds<$(date +%s -d '-8 hours')\"",
            "title": "Use fstat to find hosts where a directory has not been modified recently"
        },
        {
            "location": "/puppet/#show-stats-about-which-oses-you-have",
            "text": "mco facts lsbdistdescription",
            "title": "Show stats about which OSes you have"
        },
        {
            "location": "/puppet/#show-all-ip-addreses-on-all-hosts-where-a-configured-ip-address-matches-a-regex",
            "text": "mco facts all_ipaddresses -F 'all_ipaddresses=~10\\.(56|29)\\.'",
            "title": "Show all ip addreses on all hosts where a configured IP address matches a regex"
        },
        {
            "location": "/puppet/#show-a-report-about-uptimes-over-a-year",
            "text": "mco facts uptime -F 'uptime_days>365' |\nawk '$2 == \"days\" {print}' |\nsort -n -k1 |\ncolumn -t",
            "title": "Show a report about uptimes over a year"
        },
        {
            "location": "/puppet/#find-machines-where-a-fact-is-true",
            "text": "mco find is_ec2  Which is the same as  mco find -W is_ec2=true",
            "title": "Find machines where a fact is true"
        },
        {
            "location": "/puppet/#find-machines-that-have-a-certain-fact-value",
            "text": "mco find --with-fact lsbdistcodename=lucid",
            "title": "Find machines that have a certain fact value"
        },
        {
            "location": "/puppet/#show-a-fact-on-machines-that-have-a-specific-fact-value",
            "text": "mco facts role --with-fact lsbdistcodename=lucid -v",
            "title": "Show a fact on machines that have a specific fact value"
        },
        {
            "location": "/puppet/#find-ec2-hosts-with-low-uptime",
            "text": "mco find -W 'is_ec2=true uptime_seconds<7200'",
            "title": "Find ec2 hosts with low uptime"
        },
        {
            "location": "/puppet/#show-detailed-info-about-a-node",
            "text": "mco inventory fqdn.example.com",
            "title": "Show detailed info about a node"
        },
        {
            "location": "/puppet/#find-nodes-that-match-a-config-management-class",
            "text": "mco find -C role::awsadmin",
            "title": "Find nodes that match a config management class"
        },
        {
            "location": "/puppet/#show-the-classes-for-a-given-host",
            "text": "sort /var/lib/puppet/state/classes.txt",
            "title": "Show the classes for a given host"
        },
        {
            "location": "/puppet/#kick-off-a-puppet-run-on-all-hosts-of-a-certain-class",
            "text": "The following two syntaxes are essentially the same, using the same  puppet  agent of  mco . The only differences are the use of  runall  vs  runonce , and the method that performs parallel execution. I'm not sure what difference there is in the code path.  mco rpc    -C \"class_boolean\" -F \"fact_name=fact_value\" --batch 10 --agent puppet --action runonce\nmco puppet -C \"class_boolean\" -F \"fact_name=fact_value\" runall 10",
            "title": "Kick off a puppet run on all hosts of a certain class"
        },
        {
            "location": "/puppet/#show-the-status-and-puppet-policy-about-a-package-on-all-hosts",
            "text": "mco rpc package status package=openssh-client --discovery-timeout 60 --json",
            "title": "Show the status and puppet policy about a package on all hosts"
        },
        {
            "location": "/puppet/#upgrade-an-installed-package-on-10-random-web-hosts",
            "text": "This upgrades, but does not install if the package is not already present.  mco package update 'nginx' -I '/web/' --limit=10",
            "title": "Upgrade an installed package on 10 random web hosts"
        },
        {
            "location": "/puppet/#show-breakdown-of-hosts-by-os-version-by-role",
            "text": "mco facts -v --wc role::mon lsbdistdescription",
            "title": "Show breakdown of hosts by OS version by role"
        },
        {
            "location": "/puppet/#use-mco-to-find-packages-of-a-certain-version-on-a-certain-os",
            "text": "mco rpc package status package=apt -j -F lsbdistcodename=trusty > cache.json\njq -c '.[] | select(.data.ensure == \"1.0.1ubuntu2\") | { version: .data.ensure, hostname: .sender }' cache.json",
            "title": "Use mco to find packages of a certain version on a certain OS"
        },
        {
            "location": "/puppet/#hiera",
            "text": "\"Hiera is a key/value lookup tool for configuration data, built to make Puppet better and let you set node-specific data without repeating yourself.\" -  http://docs.puppetlabs.com/hiera/latest/   https://github.com/puppetlabs/hiera  http://www.craigdunn.org/2011/10/puppet-configuration-variables-and-hiera/",
            "title": "Hiera"
        },
        {
            "location": "/puppet/#r10k",
            "text": "The suggested workflow for puppet is to use r10k on a control repo to manage the modules on your puppetmaster and the environments it provides. The general idea is that each module is represented by a puppetforge module name or a git repo listed inside of the ambiguously named  Puppetfile . When  r10k puppetfile install -v  is run, all modules listed in this file are installed according to their definitions, and all modules that are not in this file are purged. Also, r10k will set up environments based on the git branches of the control repo. This workflow is described in detail at  Managing and deploying Puppet code . It assumes you are not using a  puppet apply  type setup, which makes this difficult to follow for people who are playing with this at home in a non-puppetmaster scenario, such as in vagrant or on raspberry pi's.",
            "title": "r10k"
        },
        {
            "location": "/pv/",
            "text": "pv\n - monitor the progress of data through a pipe\n\n\nThis can be used in place of \ndd\n or \ndcfldd\n in some cases, such as copying disks or files. It's also useful for including with \nnc\n so you can see stats about the flow of that pipe.\n\n\nExamples\n\n\nShow the average growth rate of logs\n\n\nxtail /nail/scribe/buffer/some_service_gnerated | pv -a > /dev/null\n\n\n\n\nWrite a disk image to usb\n\n\nThis can be used in place of \ndd if=file of=/dev/disk\n\n\n# As root\npv ~hoherd/Downloads/ubuntu-16.04.1-desktop-amd64.iso > /dev/rdisk4\n\n\n\n\nSee Also\n\n\n\n\ndcfldd\n\n\ndd\n\n\nddrescue",
            "title": "Pv"
        },
        {
            "location": "/pv/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/pv/#show-the-average-growth-rate-of-logs",
            "text": "xtail /nail/scribe/buffer/some_service_gnerated | pv -a > /dev/null",
            "title": "Show the average growth rate of logs"
        },
        {
            "location": "/pv/#write-a-disk-image-to-usb",
            "text": "This can be used in place of  dd if=file of=/dev/disk  # As root\npv ~hoherd/Downloads/ubuntu-16.04.1-desktop-amd64.iso > /dev/rdisk4",
            "title": "Write a disk image to usb"
        },
        {
            "location": "/pv/#see-also",
            "text": "dcfldd  dd  ddrescue",
            "title": "See Also"
        },
        {
            "location": "/python/",
            "text": "\"Python is a programming language that lets you work more quickly and integrate your systems more effectively.\" - \nhttps://www.python.org/\n\n\nTips and techniques\n\n\n\n\nDon't use \nassert\n statements for regular validation. \nassert\n statements can be disabled at the interpreter level, which would vastly change the flow of your code if they were used widespread.\n\n\n\n\nVariable names\n\n\n\n\n_varname\n - Semi-private. Basically a convention that developers use to indicate that the scope of a variable is local, but this locality is not enforced by the interpreter.\n\n\n__varname\n - Private variable in name, but not in logic or security. The interpreter mangles the name of the var to make it globally unique, but it is still globally accessible.\n\n\nvar_\n - Used to get around shadowing built-in variable names. EG: \nlist_\n won't conflict with \nlist()\n\n\n__magic_method__\n - See \nhttp://www.diveintopython3.net/special-method-names.html\n\n\n\n\nVirtual Environments\n\n\nVirtual environments isolate your project away from the system's python interpreter and modules, so you can have full control over what code is available to your project. This makes it easy to develop, debug, and deploy to a new system. It's basically always a good idea to use a virtual environment. You will thank yourself later by learning this one up front.\n\n\nVirtual environments using venv\n\n\nCreating a venv\n\n\necho \"venv\" >> .gitignore\nvirtualenv venv\n. venv/bin/activate\npip install requests\npip freeze > requirements.txt\n# write code, interact with it, whatever\ndeactivate\n\n\n\n\nRecreating a venv\n\n\nvirtualenv venv\n. venv/bin/activate\npip install -r requirements.txt\n# write code, interact with it, whatever\ndeactivate\n\n\n\n\nUse venv to work around missing pip\n\n\nThis is mostly useful for installing for your user, since if you can't install pip you won't be able to install into system-wide locations.\n\n\nvirtualenv venv --system-site-packages && venv/bin/pip install --user $PACKAGENAME && rm -rf venv\n\n\n\n\nVirtual environments with pipenv\n\n\n\"Pipenv \u2014 the officially recommended Python packaging tool from Python.org, free (as in freedom). Pipenv is a tool that aims to bring the best of all packaging worlds (bundler, composer, npm, cargo, yarn, etc.) to the Python world. Windows is a first\u2013class citizen, in our world.\" - \nhttps://docs.pipenv.org\n\n\npipenv\n is the new-school 2017 way of doing virtual environments. pipenv creates a file called \nPipfile\n whenever you install packages using the \npipenv\n command. Once you have created a pipenv for the CWD, any subdirs will use that pipenv and not create new environments when you issue pipenv commands. This is a more robust system, but as of 2017 is not widely used.\n\n\nWhen using pipenv, any packages using \npip install\n are not included in the virtual environment. You must use \npipenv install\n.\n\n\nCreating a virtual environment using pipenv\n\n\ncd project_dir\npipenv --three  # to create a python 3 virtual environment\npipenv install bpython boto3\npipenv shell  # this spawns a subshell with the new python environment\n# interact with your python environment\nexit\n\n\n\n\nRecreate a pipenv\n\n\ncd project_dir\npipenv shell  # This automatically enforces the environment described in Pipfile\n# interact with your python environment\nexit\n\n\n\n\nImport module from absolute path\n\n\nsys.path.append('/Users/username/code/somedir')\nimport module # from somedir\n\n\n\n\nDebugging\n\n\nVerbose environment var\n\n\nhttps://docs.python.org/3/using/cmdline.html#envvar-PYTHONVERBOSE\n\n\nexport PYTHONVERBOSE=1\n# or...\npython -v pip search beets\n\n\n\n\nFollow the flow of a python script\n\n\nThis is equivalent to \nbash -x\n / \nbash -o xtrace\n, but is probably even more useful because it prefixes the name of the file and the line number to what is actually being executed, which aids in debugging large projects.\n\n\npython -m trace --trace foo.py\n\n\n\n\nEnter an interactive prompt after script ends\n\n\nhttps://docs.python.org/3/using/cmdline.html#envvar-PYTHONINSPECT\n\n\nThis works when your code causes an exception, but none of your code will actually be executed, you will simply be dropped into a shell, which is not very useful.\n\n\nexport PYTHONINSPECT=1\n# or...\nsudo python -i ./ps_mem.py\n\n\n\n\nEnter a python terminal arbitrarily\n\n\nhttps://docs.python.org/3/library/pdb.html\n\n\nimport pdb; pdb.set_trace()\n\n\n\n\nAfter inspecting...\n\n\ncontinue\n\n\n\n\nPrint variables from the local scope\n\n\nfor var in dir():\n    print \"Debug: {0} = {1}\".format(var,eval(var))\n\n\n\n\nInspect things\n\n\n>>> import inspect\n>>> inspect.getargspec(inspect.getargspec)\nArgSpec(args=['func'], varargs=None, keywords=None, defaults=None)\n\n\n\n\nVarious links\n\n\n\n\nA gallery of interesting Jupyter and IPython Notebooks\n\n\nDrag'n'drop Pivot Tables and Charts in Jupyter\n\n\nCode Like a Pythonista: Idiomatic Python\n\n\nDive Into Python 3\n\n\nGoogle's Python Class\n\n\nGoogle Python Style Guide\n\n\nHow to Think Like a Computer Scientist\n - iPython notebook on python data science\n\n\nIntermediate and Advanced Software Carpentry in Python\n\n\nLearn Python dot org\n\n\nPython Cheatsheets\n\n\nThe Flask Mega-Tutorial\n\n\nThe Python IAQ: Infrequently Answered Questions\n\n\nWhy I use py.test and you probably should too\n\n\nPyCon 2017 videos\n\n\n\n\nDecorator links\n\n\n\n\nhttps://wiki.python.org/moin/PythonDecoratorLibrary\n\n\nhttp://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python/1594484#1594484\n\n\nhttp://ains.co/blog/things-which-arent-magic-flask-part-1.html\n\n\n\n\nModules\n\n\n\n\nhttps://github.com/jonathanslenders/ptpython\n - improved python REPL\n\n\nhttps://docs.python.org/3/library/sched.html\n - cross-platform cron-like scheduler\n\n\nhttps://pypi.python.org/pypi/colorama\n - cross-platform colorized terminal output\n\n\nhttps://pypi.python.org/pypi/begins/\n - Simplified CLI arguments\n\n\nhttps://pypi.python.org/pypi/watchdog\n - cross-platform filesystem events API\n\n\nhttps://github.com/giampaolo/psutil/\n - system information\n\n\nhttps://github.com/timothycrosley/hug\n - simplified web API creation\n\n\nhttp://python-future.org\n - \"python-future is the missing compatibility layer between Python 2 and Python 3. It allows you to use a single, clean Python 3.x-compatible codebase to support both Python 2 and Python 3 with minimal overhead.\"",
            "title": "Python"
        },
        {
            "location": "/python/#tips-and-techniques",
            "text": "Don't use  assert  statements for regular validation.  assert  statements can be disabled at the interpreter level, which would vastly change the flow of your code if they were used widespread.",
            "title": "Tips and techniques"
        },
        {
            "location": "/python/#variable-names",
            "text": "_varname  - Semi-private. Basically a convention that developers use to indicate that the scope of a variable is local, but this locality is not enforced by the interpreter.  __varname  - Private variable in name, but not in logic or security. The interpreter mangles the name of the var to make it globally unique, but it is still globally accessible.  var_  - Used to get around shadowing built-in variable names. EG:  list_  won't conflict with  list()  __magic_method__  - See  http://www.diveintopython3.net/special-method-names.html",
            "title": "Variable names"
        },
        {
            "location": "/python/#virtual-environments",
            "text": "Virtual environments isolate your project away from the system's python interpreter and modules, so you can have full control over what code is available to your project. This makes it easy to develop, debug, and deploy to a new system. It's basically always a good idea to use a virtual environment. You will thank yourself later by learning this one up front.",
            "title": "Virtual Environments"
        },
        {
            "location": "/python/#virtual-environments-using-venv",
            "text": "",
            "title": "Virtual environments using venv"
        },
        {
            "location": "/python/#creating-a-venv",
            "text": "echo \"venv\" >> .gitignore\nvirtualenv venv\n. venv/bin/activate\npip install requests\npip freeze > requirements.txt\n# write code, interact with it, whatever\ndeactivate",
            "title": "Creating a venv"
        },
        {
            "location": "/python/#recreating-a-venv",
            "text": "virtualenv venv\n. venv/bin/activate\npip install -r requirements.txt\n# write code, interact with it, whatever\ndeactivate",
            "title": "Recreating a venv"
        },
        {
            "location": "/python/#use-venv-to-work-around-missing-pip",
            "text": "This is mostly useful for installing for your user, since if you can't install pip you won't be able to install into system-wide locations.  virtualenv venv --system-site-packages && venv/bin/pip install --user $PACKAGENAME && rm -rf venv",
            "title": "Use venv to work around missing pip"
        },
        {
            "location": "/python/#virtual-environments-with-pipenv",
            "text": "\"Pipenv \u2014 the officially recommended Python packaging tool from Python.org, free (as in freedom). Pipenv is a tool that aims to bring the best of all packaging worlds (bundler, composer, npm, cargo, yarn, etc.) to the Python world. Windows is a first\u2013class citizen, in our world.\" -  https://docs.pipenv.org  pipenv  is the new-school 2017 way of doing virtual environments. pipenv creates a file called  Pipfile  whenever you install packages using the  pipenv  command. Once you have created a pipenv for the CWD, any subdirs will use that pipenv and not create new environments when you issue pipenv commands. This is a more robust system, but as of 2017 is not widely used.  When using pipenv, any packages using  pip install  are not included in the virtual environment. You must use  pipenv install .",
            "title": "Virtual environments with pipenv"
        },
        {
            "location": "/python/#creating-a-virtual-environment-using-pipenv",
            "text": "cd project_dir\npipenv --three  # to create a python 3 virtual environment\npipenv install bpython boto3\npipenv shell  # this spawns a subshell with the new python environment\n# interact with your python environment\nexit",
            "title": "Creating a virtual environment using pipenv"
        },
        {
            "location": "/python/#recreate-a-pipenv",
            "text": "cd project_dir\npipenv shell  # This automatically enforces the environment described in Pipfile\n# interact with your python environment\nexit",
            "title": "Recreate a pipenv"
        },
        {
            "location": "/python/#import-module-from-absolute-path",
            "text": "sys.path.append('/Users/username/code/somedir')\nimport module # from somedir",
            "title": "Import module from absolute path"
        },
        {
            "location": "/python/#debugging",
            "text": "",
            "title": "Debugging"
        },
        {
            "location": "/python/#verbose-environment-var",
            "text": "https://docs.python.org/3/using/cmdline.html#envvar-PYTHONVERBOSE  export PYTHONVERBOSE=1\n# or...\npython -v pip search beets",
            "title": "Verbose environment var"
        },
        {
            "location": "/python/#follow-the-flow-of-a-python-script",
            "text": "This is equivalent to  bash -x  /  bash -o xtrace , but is probably even more useful because it prefixes the name of the file and the line number to what is actually being executed, which aids in debugging large projects.  python -m trace --trace foo.py",
            "title": "Follow the flow of a python script"
        },
        {
            "location": "/python/#enter-an-interactive-prompt-after-script-ends",
            "text": "https://docs.python.org/3/using/cmdline.html#envvar-PYTHONINSPECT  This works when your code causes an exception, but none of your code will actually be executed, you will simply be dropped into a shell, which is not very useful.  export PYTHONINSPECT=1\n# or...\nsudo python -i ./ps_mem.py",
            "title": "Enter an interactive prompt after script ends"
        },
        {
            "location": "/python/#enter-a-python-terminal-arbitrarily",
            "text": "https://docs.python.org/3/library/pdb.html  import pdb; pdb.set_trace()  After inspecting...  continue",
            "title": "Enter a python terminal arbitrarily"
        },
        {
            "location": "/python/#print-variables-from-the-local-scope",
            "text": "for var in dir():\n    print \"Debug: {0} = {1}\".format(var,eval(var))",
            "title": "Print variables from the local scope"
        },
        {
            "location": "/python/#inspect-things",
            "text": ">>> import inspect\n>>> inspect.getargspec(inspect.getargspec)\nArgSpec(args=['func'], varargs=None, keywords=None, defaults=None)",
            "title": "Inspect things"
        },
        {
            "location": "/python/#various-links",
            "text": "A gallery of interesting Jupyter and IPython Notebooks  Drag'n'drop Pivot Tables and Charts in Jupyter  Code Like a Pythonista: Idiomatic Python  Dive Into Python 3  Google's Python Class  Google Python Style Guide  How to Think Like a Computer Scientist  - iPython notebook on python data science  Intermediate and Advanced Software Carpentry in Python  Learn Python dot org  Python Cheatsheets  The Flask Mega-Tutorial  The Python IAQ: Infrequently Answered Questions  Why I use py.test and you probably should too  PyCon 2017 videos",
            "title": "Various links"
        },
        {
            "location": "/python/#decorator-links",
            "text": "https://wiki.python.org/moin/PythonDecoratorLibrary  http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python/1594484#1594484  http://ains.co/blog/things-which-arent-magic-flask-part-1.html",
            "title": "Decorator links"
        },
        {
            "location": "/python/#modules",
            "text": "https://github.com/jonathanslenders/ptpython  - improved python REPL  https://docs.python.org/3/library/sched.html  - cross-platform cron-like scheduler  https://pypi.python.org/pypi/colorama  - cross-platform colorized terminal output  https://pypi.python.org/pypi/begins/  - Simplified CLI arguments  https://pypi.python.org/pypi/watchdog  - cross-platform filesystem events API  https://github.com/giampaolo/psutil/  - system information  https://github.com/timothycrosley/hug  - simplified web API creation  http://python-future.org  - \"python-future is the missing compatibility layer between Python 2 and Python 3. It allows you to use a single, clean Python 3.x-compatible codebase to support both Python 2 and Python 3 with minimal overhead.\"",
            "title": "Modules"
        },
        {
            "location": "/q/",
            "text": "\"q - Text as Data\" - \nhttp://harelba.github.io/q/\n\n\nExamples\n\n\nFormat the Pagerduty incidents.csv to be more readable\n\n\n# -d, = comma delimited input\n# -H  = use the headings found in the input csv files\n# -T  = tab delimited output\n# -f  = python 2 format strings to be applied to 1-indexed output fields\n$ q -d, -H -T -f '1=https://pagerduty.com/incidents/%s,2=alerted at %s,3=Description: %s' 'select id,created_on,description from incidents.csv order by created_on asc limit 5'\nhttps://pagerduty.com/incidents/P66XNLT    alerted at 2017-12-04T00:04:07-08:00    Description: proxy0302: 200 Status Code Proxy Log Watcher: Matches found in last run met or dropped below 0.0, dropping to 0.0 for 10 minutes at 12:00AM https://server.pingdom.com/a/3103869181\nhttps://pagerduty.com/incidents/PLUG344    alerted at 2017-12-04T04:14:05-08:00    Description: sandbox-apigateway00: API Gateway Error Watcher: Occurrences met or exceeded 10.00 /min, increasing to 15.82 /min for 10 minutes at 04:10AM https://server.pingdom.com/a/3104379391\nhttps://pagerduty.com/incidents/PT13M2B    alerted at 2017-12-04T06:48:14-08:00    Description: hadoop-r21: Hadoop Resource Monitor: Lostnodes met or exceeded 4.0, increasing to 4.0 at 06:47AM https://server.pingdom.com/a/3104686551\nhttps://pagerduty.com/incidents/P3RLOTT    alerted at 2017-12-04T08:56:07-08:00    Description: hadoop-c05: /srv Disk Usage: Disk Capacity met or exceeded 90%, increasing to 90% for 10 minutes at 08:50AM https://server.pingdom.com/a/3104929931\nhttps://pagerduty.com/incidents/PNOJZKC    alerted at 2017-12-04T09:02:21-08:00    Description: sjc-http2: HTTP 500 error Watcher: Occurrences met or exceeded 10.00 /min, increasing to 31.91 /min for 10 minutes at 09:00AM https://server.pingdom.com/a/3104941911\n\n\n\n\nFormat pagerduty events as HTML for pasting into confluence for issue response tracking\n\n\npagerduty-csv-download\n opens your browser and downloads the csv file for the last week of events. You'll have to change companyname to whatever your company URL is.\n\n\npagerduty-csv-to-html\n uses \nq\n to reformat the csv into HTML lists you can paste into the source editor of your HTML friendly CMS like Confluence.\n\n\nThis uses BSD relative date syntax, you'll have to change it for linux.\n\n\npagerduty-csv-download() {\n  rm -f incidents.csv\n  TZ=America/Los_Angeles\n  past=\"$(date -v-7d \"+%FT00:00:00\")\"\n  present=\"$(date \"+%FT00:00:00\")\"\n  open \"$(date \"+https://companyname.pagerduty.com/api/v1/reports/raw/incidents.csv?since=${past}&until=${present}&time_zone=${TZ}\")\"\n}\npagerduty-csv-to-html() {\n  q \\\n    -H \\\n    -d',' \\\n    -D' ' \\\n    -f '1=<li>%s,2=<a href \\\"https://companyname.pagerduty.com/incidents/%s\\\">,3=%s</a>,4=%s<ul><li>...</li></ul></li>' \\\n    'select substr(created_on,12,5),id,id,description from incidents.csv order by created_on asc' | tail -n 50 | sed 's/href /href=/;s/> />/'\n}\n\n\n\n\nSelect count of daily alerts by date from PagerDuty incidents.csv\n\n\nq -H --delimiter=',' -O --output-delimiter=',' 'select substr(created_on,0,11) as date,count(substr(created_on,0,11)) as count from incidents.csv group by date'",
            "title": "Q"
        },
        {
            "location": "/q/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/q/#format-the-pagerduty-incidentscsv-to-be-more-readable",
            "text": "# -d, = comma delimited input\n# -H  = use the headings found in the input csv files\n# -T  = tab delimited output\n# -f  = python 2 format strings to be applied to 1-indexed output fields\n$ q -d, -H -T -f '1=https://pagerduty.com/incidents/%s,2=alerted at %s,3=Description: %s' 'select id,created_on,description from incidents.csv order by created_on asc limit 5'\nhttps://pagerduty.com/incidents/P66XNLT    alerted at 2017-12-04T00:04:07-08:00    Description: proxy0302: 200 Status Code Proxy Log Watcher: Matches found in last run met or dropped below 0.0, dropping to 0.0 for 10 minutes at 12:00AM https://server.pingdom.com/a/3103869181\nhttps://pagerduty.com/incidents/PLUG344    alerted at 2017-12-04T04:14:05-08:00    Description: sandbox-apigateway00: API Gateway Error Watcher: Occurrences met or exceeded 10.00 /min, increasing to 15.82 /min for 10 minutes at 04:10AM https://server.pingdom.com/a/3104379391\nhttps://pagerduty.com/incidents/PT13M2B    alerted at 2017-12-04T06:48:14-08:00    Description: hadoop-r21: Hadoop Resource Monitor: Lostnodes met or exceeded 4.0, increasing to 4.0 at 06:47AM https://server.pingdom.com/a/3104686551\nhttps://pagerduty.com/incidents/P3RLOTT    alerted at 2017-12-04T08:56:07-08:00    Description: hadoop-c05: /srv Disk Usage: Disk Capacity met or exceeded 90%, increasing to 90% for 10 minutes at 08:50AM https://server.pingdom.com/a/3104929931\nhttps://pagerduty.com/incidents/PNOJZKC    alerted at 2017-12-04T09:02:21-08:00    Description: sjc-http2: HTTP 500 error Watcher: Occurrences met or exceeded 10.00 /min, increasing to 31.91 /min for 10 minutes at 09:00AM https://server.pingdom.com/a/3104941911",
            "title": "Format the Pagerduty incidents.csv to be more readable"
        },
        {
            "location": "/q/#format-pagerduty-events-as-html-for-pasting-into-confluence-for-issue-response-tracking",
            "text": "pagerduty-csv-download  opens your browser and downloads the csv file for the last week of events. You'll have to change companyname to whatever your company URL is.  pagerduty-csv-to-html  uses  q  to reformat the csv into HTML lists you can paste into the source editor of your HTML friendly CMS like Confluence.  This uses BSD relative date syntax, you'll have to change it for linux.  pagerduty-csv-download() {\n  rm -f incidents.csv\n  TZ=America/Los_Angeles\n  past=\"$(date -v-7d \"+%FT00:00:00\")\"\n  present=\"$(date \"+%FT00:00:00\")\"\n  open \"$(date \"+https://companyname.pagerduty.com/api/v1/reports/raw/incidents.csv?since=${past}&until=${present}&time_zone=${TZ}\")\"\n}\npagerduty-csv-to-html() {\n  q \\\n    -H \\\n    -d',' \\\n    -D' ' \\\n    -f '1=<li>%s,2=<a href \\\"https://companyname.pagerduty.com/incidents/%s\\\">,3=%s</a>,4=%s<ul><li>...</li></ul></li>' \\\n    'select substr(created_on,12,5),id,id,description from incidents.csv order by created_on asc' | tail -n 50 | sed 's/href /href=/;s/> />/'\n}",
            "title": "Format pagerduty events as HTML for pasting into confluence for issue response tracking"
        },
        {
            "location": "/q/#select-count-of-daily-alerts-by-date-from-pagerduty-incidentscsv",
            "text": "q -H --delimiter=',' -O --output-delimiter=',' 'select substr(created_on,0,11) as date,count(substr(created_on,0,11)) as count from incidents.csv group by date'",
            "title": "Select count of daily alerts by date from PagerDuty incidents.csv"
        },
        {
            "location": "/raspberry-pi/",
            "text": "A small computer, good for running linux.\n\n\n\n\nhttp://www.raspberrypi.org\n\n\nFedora Remix for Pi - \nhttp://www.raspberrypi.org/archives/805\n\n\n\n\nSoftware\n\n\nRaspbian\n\n\ndpkg-reconfigure\u00a0locales\n\n\nHass.io\n\n\n\"Hass.io turns your Raspberry Pi (or another device) into the ultimate home automation hub powered by Home Assistant. With Hass.io you can focus on integrating your devices and writing automations.\" - \nhttps://home-assistant.io/hassio/\n\n\nSpillPassPi\n\n\nV1\n\n\nRetired.\n\n\n'A Simple Homebrew Plug and Play 3DS HomePass Relay and Fake \"Nintendo Zone\" Hotspot' - \nhttp://www.spillmonkey.com/?page_id=5\n\n\nV2\n\n\n'A Simple Homebrew Plug and Play 2DS/3DS/N3DS StreetPass Relay and Fake \"Nintendo Zone\" Hotspot' - \nhttp://www.spillmonkey.com/?page_id=169\n\n\nHomepass\n\n\n\"Nintendo 3DS homepass resources and software.\" - \nhttps://github.com/danielhoherd/homepass/tree/master/RaspberryPi",
            "title": "Raspberry pi"
        },
        {
            "location": "/raspberry-pi/#software",
            "text": "",
            "title": "Software"
        },
        {
            "location": "/raspberry-pi/#raspbian",
            "text": "dpkg-reconfigure\u00a0locales",
            "title": "Raspbian"
        },
        {
            "location": "/raspberry-pi/#hassio",
            "text": "\"Hass.io turns your Raspberry Pi (or another device) into the ultimate home automation hub powered by Home Assistant. With Hass.io you can focus on integrating your devices and writing automations.\" -  https://home-assistant.io/hassio/",
            "title": "Hass.io"
        },
        {
            "location": "/raspberry-pi/#spillpasspi",
            "text": "",
            "title": "SpillPassPi"
        },
        {
            "location": "/raspberry-pi/#v1",
            "text": "Retired.  'A Simple Homebrew Plug and Play 3DS HomePass Relay and Fake \"Nintendo Zone\" Hotspot' -  http://www.spillmonkey.com/?page_id=5",
            "title": "V1"
        },
        {
            "location": "/raspberry-pi/#v2",
            "text": "'A Simple Homebrew Plug and Play 2DS/3DS/N3DS StreetPass Relay and Fake \"Nintendo Zone\" Hotspot' -  http://www.spillmonkey.com/?page_id=169",
            "title": "V2"
        },
        {
            "location": "/raspberry-pi/#homepass",
            "text": "\"Nintendo 3DS homepass resources and software.\" -  https://github.com/danielhoherd/homepass/tree/master/RaspberryPi",
            "title": "Homepass"
        },
        {
            "location": "/redis/",
            "text": "\"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.\" - \nhttps://redis.io\n\n\nTips and Examples\n\n\nSolve memory allocation problems\n\n\nErrors like this can cause the disk to fill up over long periods of time:\n\n\n[2535] 02 Jan 19:58:52.376 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 19:58:52.376 # Can't rewrite append only file in background: fork: Cannot allocate memory\n\n\n\n\nThis problem can be solved without restarting anything:\n\n\n# df -h .\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvdf       250G  135G  116G  54% /srv\n# cat /proc/sys/vm/overcommit_memory\n0\n# echo 1 > /proc/sys/vm/overcommit_memory\n# tail  redis.log\n[2535] 02 Jan 22:03:23.707 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 22:03:23.707 # Can't rewrite append only file in background: fork: Cannot allocate memory\n[2535] 02 Jan 22:03:23.807 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 22:03:23.807 # Can't rewrite append only file in background: fork: Cannot allocate memory\n[2535] 02 Jan 22:03:23.907 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 22:03:23.926 * Background append only file rewriting started by pid 27302\n[27302] 02 Jan 22:04:05.337 * SYNC append only file rewrite performed\n[27302] 02 Jan 22:04:05.379 * AOF rewrite: 36 MB of memory used by copy-on-write\n[2535] 02 Jan 22:04:05.406 * Background AOF rewrite terminated with success\n[2535] 02 Jan 22:04:05.406 * Parent diff successfully flushed to the rewritten AOF (42 bytes)\n[2535] 02 Jan 22:04:05.406 * Background AOF rewrite finished successfully\n# df -h .\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvdf       250G  4.5G  246G   2% /srv\n\n\n\n\nFind what is using the most memory\n\n\nredis-cli --bigkeys\n\n\n\n\nLinks\n\n\n\n\nhttps://redis.io/topics/faq\n\n\nhttps://redis.io/commands",
            "title": "Redis"
        },
        {
            "location": "/redis/#tips-and-examples",
            "text": "",
            "title": "Tips and Examples"
        },
        {
            "location": "/redis/#solve-memory-allocation-problems",
            "text": "Errors like this can cause the disk to fill up over long periods of time:  [2535] 02 Jan 19:58:52.376 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 19:58:52.376 # Can't rewrite append only file in background: fork: Cannot allocate memory  This problem can be solved without restarting anything:  # df -h .\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvdf       250G  135G  116G  54% /srv\n# cat /proc/sys/vm/overcommit_memory\n0\n# echo 1 > /proc/sys/vm/overcommit_memory\n# tail  redis.log\n[2535] 02 Jan 22:03:23.707 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 22:03:23.707 # Can't rewrite append only file in background: fork: Cannot allocate memory\n[2535] 02 Jan 22:03:23.807 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 22:03:23.807 # Can't rewrite append only file in background: fork: Cannot allocate memory\n[2535] 02 Jan 22:03:23.907 * Starting automatic rewriting of AOF on 7885% growth\n[2535] 02 Jan 22:03:23.926 * Background append only file rewriting started by pid 27302\n[27302] 02 Jan 22:04:05.337 * SYNC append only file rewrite performed\n[27302] 02 Jan 22:04:05.379 * AOF rewrite: 36 MB of memory used by copy-on-write\n[2535] 02 Jan 22:04:05.406 * Background AOF rewrite terminated with success\n[2535] 02 Jan 22:04:05.406 * Parent diff successfully flushed to the rewritten AOF (42 bytes)\n[2535] 02 Jan 22:04:05.406 * Background AOF rewrite finished successfully\n# df -h .\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvdf       250G  4.5G  246G   2% /srv",
            "title": "Solve memory allocation problems"
        },
        {
            "location": "/redis/#find-what-is-using-the-most-memory",
            "text": "redis-cli --bigkeys",
            "title": "Find what is using the most memory"
        },
        {
            "location": "/redis/#links",
            "text": "https://redis.io/topics/faq  https://redis.io/commands",
            "title": "Links"
        },
        {
            "location": "/rhel/",
            "text": "\"Red Hat, Inc. is an American multinational software company providing open-source software products to the enterprise community.\" - \nhttps://en.wikipedia.org/wiki/Red_Hat\n\n\nSee Also\n\n\n\n\nCentOS\n is now owned by RedHat\n\n\nInline with Upstream Stable Community Project",
            "title": "Rhel"
        },
        {
            "location": "/rhel/#see-also",
            "text": "CentOS  is now owned by RedHat  Inline with Upstream Stable Community Project",
            "title": "See Also"
        },
        {
            "location": "/robotics/",
            "text": "Links\n\n\n\n\nhttp://botbench.com\n\n\nhttp://www.andymark.com\n\n\nhttp://www.vexrobotics.com\n\n\nhttps://www.adafruit.com\n\n\nhttps://www.reddit.com/r/robotics/wiki/index\n\n\nhttps://www.sparkfun.com/\n\n\n\n\nSee also\n\n\n\n\nLego Mindstorms",
            "title": "Links"
        },
        {
            "location": "/robotics/#links",
            "text": "http://botbench.com  http://www.andymark.com  http://www.vexrobotics.com  https://www.adafruit.com  https://www.reddit.com/r/robotics/wiki/index  https://www.sparkfun.com/",
            "title": "Links"
        },
        {
            "location": "/robotics/#see-also",
            "text": "Lego Mindstorms",
            "title": "See also"
        },
        {
            "location": "/rook/",
            "text": "\"File, Block, and Object Storage Services for your Cloud-Native Environments\" - \nhttps://rook.io/\n\n\nRook is based on ceph.",
            "title": "Rook"
        },
        {
            "location": "/ros/",
            "text": "\"The Robot Operating System (ROS) is a set of software libraries and tools that help you build robot applications. From drivers to state-of-the-art algorithms, and with powerful developer tools, ROS has what you need for your next robotics project. And it's all open source.\" - \nhttp://www.ros.org\n\n\nLinks\n\n\n\n\nROS tutorials - \nhttp://wiki.ros.org/ROS/Tutorials\n\n\nROS Turtle Example - \nhttp://wiki.ros.org/turtlesim/Tutorials\n\n\nAutoware built on top of ROS for Self-driving cars - \nhttps://github.com/CPFL/Autoware\n\n\nRobot Operating System for ev3 - \nhttp://wiki.ros.org/Robots/EV3",
            "title": "Ros"
        },
        {
            "location": "/ros/#links",
            "text": "ROS tutorials -  http://wiki.ros.org/ROS/Tutorials  ROS Turtle Example -  http://wiki.ros.org/turtlesim/Tutorials  Autoware built on top of ROS for Self-driving cars -  https://github.com/CPFL/Autoware  Robot Operating System for ev3 -  http://wiki.ros.org/Robots/EV3",
            "title": "Links"
        },
        {
            "location": "/rpm/",
            "text": "Redhat Package Manager. \"rpm is a powerful Package Manager, which can be used to build, install, query, verify, update, and erase individual software packages.\" - \nman rpm\n\n\nTricks\n\n\nShow installed keys\n\n\nrpm -qa gpg-pubkey\n\n\n\n\nShow extended info about all keys\n\n\nrpm -qa gpg-pubkey | xargs -n1 -P1 rpm -qi\n\n\n\n\nShow information about an rpm file\n\n\nrpm -qpi\n\n\n\n\nShow all installed packages and when they were installed\n\n\nrpm -qa --last\n\n\n\n\nShow information about the installed wget package\n\n\nrpm -qi wget\n\n\n\n\nOutput formatted information about packages\n\n\nrpm -qa --queryformat \"%{NAME} %{PACKAGER} %{URL}\\n\" tomcat7\n\n\n\n\nMore info on queryformat: \nhttp://www.rpm.org/max-rpm/ch-queryformat-tags.html\n\n\nShow which package installed a file\n\n\nrpm -qf /usr/bin/wget\n\n\n\n\nShow all files that were installed by package wget\n\n\nrpm -ql wget\n\n\n\n\nShow all files in a package that is not yet installed\n\n\nrpm -qpl ~/downloads/wget-1.10.2-78.i586.rpm\n\n\n\n\nShow which documentation files get installed with a package\n\n\nrpm -qd wget\n\n\n\n\nShow what has changed on the system since installing a package\n\n\nThis will verify file integrity and show you what has changed for each file.\n\n\nrpm -V openssl\n\n\n\n\nShow installation and uninstallation scripts\n\n\nrpm -qp --scripts foo.rpm\n\n\n\n\nCheck the integrity of an RPM\n\n\nrpm -K ~/downloads/filename.rpm\n\n\n\n\nShow which packages are hogging all the space\n\n\nrpm -qa --queryformat \"%{SIZE} %{NAME}\\n\" |sort -rn |head -n50 | column -t\n\n\n\n\nShow a table about RPM files versions and creators in a directory\n\n\nrpm -qp --queryformat \"%{NAME},%{VERSION},%{PACKAGER}\\n\" * | column -s, -t\n\n\n\n\nShow what files were installed into /var/log\n\n\nrpm -qa --filesbypkg | grep \" /var/log\" # space before /var is necessary to weed out things like /usr/var\n\n\n\n\nRebuild a corrupt rpm db\n\n\nrm -rf /var/lib/rpm/__db*\nrpm --rebuilddb\n\n\n\n\nSee Also\n\n\n\n\nHow to create RPMs - \nhttp://fedoraproject.org/wiki/How_to_create_an_RPM_package\n\n\nyum - supplement to rpm command",
            "title": "Rpm"
        },
        {
            "location": "/rpm/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/rpm/#show-installed-keys",
            "text": "rpm -qa gpg-pubkey",
            "title": "Show installed keys"
        },
        {
            "location": "/rpm/#show-extended-info-about-all-keys",
            "text": "rpm -qa gpg-pubkey | xargs -n1 -P1 rpm -qi",
            "title": "Show extended info about all keys"
        },
        {
            "location": "/rpm/#show-information-about-an-rpm-file",
            "text": "rpm -qpi",
            "title": "Show information about an rpm file"
        },
        {
            "location": "/rpm/#show-all-installed-packages-and-when-they-were-installed",
            "text": "rpm -qa --last",
            "title": "Show all installed packages and when they were installed"
        },
        {
            "location": "/rpm/#show-information-about-the-installed-wget-package",
            "text": "rpm -qi wget",
            "title": "Show information about the installed wget package"
        },
        {
            "location": "/rpm/#output-formatted-information-about-packages",
            "text": "rpm -qa --queryformat \"%{NAME} %{PACKAGER} %{URL}\\n\" tomcat7  More info on queryformat:  http://www.rpm.org/max-rpm/ch-queryformat-tags.html",
            "title": "Output formatted information about packages"
        },
        {
            "location": "/rpm/#show-which-package-installed-a-file",
            "text": "rpm -qf /usr/bin/wget",
            "title": "Show which package installed a file"
        },
        {
            "location": "/rpm/#show-all-files-that-were-installed-by-package-wget",
            "text": "rpm -ql wget",
            "title": "Show all files that were installed by package wget"
        },
        {
            "location": "/rpm/#show-all-files-in-a-package-that-is-not-yet-installed",
            "text": "rpm -qpl ~/downloads/wget-1.10.2-78.i586.rpm",
            "title": "Show all files in a package that is not yet installed"
        },
        {
            "location": "/rpm/#show-which-documentation-files-get-installed-with-a-package",
            "text": "rpm -qd wget",
            "title": "Show which documentation files get installed with a package"
        },
        {
            "location": "/rpm/#show-what-has-changed-on-the-system-since-installing-a-package",
            "text": "This will verify file integrity and show you what has changed for each file.  rpm -V openssl",
            "title": "Show what has changed on the system since installing a package"
        },
        {
            "location": "/rpm/#show-installation-and-uninstallation-scripts",
            "text": "rpm -qp --scripts foo.rpm",
            "title": "Show installation and uninstallation scripts"
        },
        {
            "location": "/rpm/#check-the-integrity-of-an-rpm",
            "text": "rpm -K ~/downloads/filename.rpm",
            "title": "Check the integrity of an RPM"
        },
        {
            "location": "/rpm/#show-which-packages-are-hogging-all-the-space",
            "text": "rpm -qa --queryformat \"%{SIZE} %{NAME}\\n\" |sort -rn |head -n50 | column -t",
            "title": "Show which packages are hogging all the space"
        },
        {
            "location": "/rpm/#show-a-table-about-rpm-files-versions-and-creators-in-a-directory",
            "text": "rpm -qp --queryformat \"%{NAME},%{VERSION},%{PACKAGER}\\n\" * | column -s, -t",
            "title": "Show a table about RPM files versions and creators in a directory"
        },
        {
            "location": "/rpm/#show-what-files-were-installed-into-varlog",
            "text": "rpm -qa --filesbypkg | grep \" /var/log\" # space before /var is necessary to weed out things like /usr/var",
            "title": "Show what files were installed into /var/log"
        },
        {
            "location": "/rpm/#rebuild-a-corrupt-rpm-db",
            "text": "rm -rf /var/lib/rpm/__db*\nrpm --rebuilddb",
            "title": "Rebuild a corrupt rpm db"
        },
        {
            "location": "/rpm/#see-also",
            "text": "How to create RPMs -  http://fedoraproject.org/wiki/How_to_create_an_RPM_package  yum - supplement to rpm command",
            "title": "See Also"
        },
        {
            "location": "/rrd/",
            "text": "\"RRDtool is the OpenSource industry standard, high performance data logging and graphing system for time series data. RRDtool can be easily integrated in shell scripts, perl, python, ruby, lua or tcl applications.\" - \nhttps://oss.oetiker.ch/rrdtool/index.en.html\n\n\nAcronyms\n\n\n\n\ncs = consolidation function\n\n\nds = data source\n\n\ndst = data source type\n\n\nrra = round robin archive\n\n\n\n\nExamples\n\n\nReconfigure the X-axis precision of an RRD\n\n\nAssuming the first value (eg: 5856) is the value you want and 244 is the value you currently have, reconfigure data index 0,1,2:\n\n\nsudo rrdtool tune coral/pkts_in.rrd \"RRA#0:+$((5856-244))\" \"RRA#1:+$((20160-244))\" \"RRA#2:+$((52704-244))\"\n\n\n\n\nLinks\n\n\n\n\nhttps://oss.oetiker.ch/rrdtool/tut/rrd-beginners.en.html",
            "title": "Rrd"
        },
        {
            "location": "/rrd/#acronyms",
            "text": "cs = consolidation function  ds = data source  dst = data source type  rra = round robin archive",
            "title": "Acronyms"
        },
        {
            "location": "/rrd/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/rrd/#reconfigure-the-x-axis-precision-of-an-rrd",
            "text": "Assuming the first value (eg: 5856) is the value you want and 244 is the value you currently have, reconfigure data index 0,1,2:  sudo rrdtool tune coral/pkts_in.rrd \"RRA#0:+$((5856-244))\" \"RRA#1:+$((20160-244))\" \"RRA#2:+$((52704-244))\"",
            "title": "Reconfigure the X-axis precision of an RRD"
        },
        {
            "location": "/rrd/#links",
            "text": "https://oss.oetiker.ch/rrdtool/tut/rrd-beginners.en.html",
            "title": "Links"
        },
        {
            "location": "/rsync/",
            "text": "Great way to sync one location to another, local or remote.  Note that this does not mean full synchronization, two commands with reversed source and destinations are required to accomplish that.\n\n\nSyntax Examples\n\n\nGiving additional ssh options\n\n\nrsync -e 'ssh -o ConnectTimeout=10 -o PasswordAuthentication=no' -Rai /home target:/\n\n\n\n\nExclude Filters\n\n\nExclude filters are kinda weird.\n- They're case sensitive and there's no way to be case insensitive.\n- They are relative to the root of the source URI. EG, \nrsync --exclude=\"Desktop/\" ~/ remotehost:~/\n\n\nHere is an example of what to use in --exclude-from=file.txt\n\n\n**Cache\n**Caches\n**cache\n**caches\n**/.dropbox\n**Previews.lrdata\n**/Library/Application\\ Support/Google/Chrome\n\n\n\n\nLong and Partial Transfers\n\n\nIf you're doing transfers which you'd like to monitor and risk being cut off, use this syntax:\n\n\nrsync -e ssh -az --partial --progress ./foo remotehost:~/bar/\n\n\nThis will resume broken file transfers where they were left off, and give you completion statistics with transfer rate, percent complete and estimated time left.\n\n\nRecursively link src to dst\n\n\nrsync can be used to create a hard linked local copy of a whole tree. This is useful if you don't have GNU cp where the same could be done with simply \ncp -lrp\n. On OS X with \nhomebrew\n, GNU cp can be installed via \nbrew install coreutils\n and accessed via \ngcp\n. See also \nls -la /usr/local/opt/coreutils/bin/\n.\n\n\nSlashes are really really important here; this won't work if you get them wrong. Absolute paths must be given, thus ${PWD} and ${HOME} vs ~\n\n\nrsync -aP --link-dest=\"${PWD}/src\" ./src/ dst #recursively hard link ./src to dst\n\n\n\n\nFor example:\n\n\nrsync -aivv --link-dest=\"${HOME}/Dropbox\" ${HOME}/Dropbox/some_dir ${HOME}/temp/\n\n\n\n\nThis will create the directory \n${HOME}/temp/some_dir\n and hard link all the files from the source into the destination.  It should only take a few seconds.  Lines with 'hf' indicate a hard linked file.  Lines with 'cd' indicate 'created directory'.\n\n\nrsync can copy not only data, but also filesystem attributes, and if these differ between the link-dest and the src, a hard link may not be created but instead a copy of the file from the local filesystem is made and correct metadata is applied from the source.\n\n\nMove files to another server in small batches\n\n\nThis is useful if you want to gradually clear up disk space rather than waiting until the end of a transfer of a large number of files to clear up disk space in one large operation.\n\n\nwhile date ;\nfiles=$(find /srv/backups/scribe/./ -type f -mtime +400 | head -n 500) ;\necho md5 of files ${#files} is $(echo ${files} | md5sum) ;\n[ ! -z \"${files}\" ] ; do\n  sudo rsync --bwlimit 20000 -RaPi --remove-source-files ${files} root@10.2.17.7:/srv/backups/scribe-sea/ ; echo sleeping ;\n  sleep 10 ;\ndone ;\n\n\n\n\nMove all datestamped files older than the beginning of the previous month, excluding symlinks\n\n\nThis relies on gnu date, so use gdate if used on OS X.\n\n\nrsync -aPiv \\\n  --remove-source-files \\\n  --bwlimit 20000 \\\n  --exclude=\"**$(date -d \"1 month ago\" \"+%Y-%m\")**\" \\\n  --exclude=\"**$(date \"+%Y-%m\")**\" \\\n  --no-links \\\n  /srv/backups/scribe/* \\\n  root@10.2.17.7:/srv/backups/scribe-sea/\n\n\n\n\nReduce time precision during comparison\n\n\nThis is useful for rsyncing to FAT filesystems where time precision is 2 seconds.\n\n\nrsync --modify-window=1 # allow 1 second of difference in timestamps\n\n\n\n\nSee Also\n\n\n\n\nprsync\n\n\npssh\n\n\npscp",
            "title": "Rsync"
        },
        {
            "location": "/rsync/#syntax-examples",
            "text": "",
            "title": "Syntax Examples"
        },
        {
            "location": "/rsync/#giving-additional-ssh-options",
            "text": "rsync -e 'ssh -o ConnectTimeout=10 -o PasswordAuthentication=no' -Rai /home target:/",
            "title": "Giving additional ssh options"
        },
        {
            "location": "/rsync/#exclude-filters",
            "text": "Exclude filters are kinda weird.\n- They're case sensitive and there's no way to be case insensitive.\n- They are relative to the root of the source URI. EG,  rsync --exclude=\"Desktop/\" ~/ remotehost:~/  Here is an example of what to use in --exclude-from=file.txt  **Cache\n**Caches\n**cache\n**caches\n**/.dropbox\n**Previews.lrdata\n**/Library/Application\\ Support/Google/Chrome",
            "title": "Exclude Filters"
        },
        {
            "location": "/rsync/#long-and-partial-transfers",
            "text": "If you're doing transfers which you'd like to monitor and risk being cut off, use this syntax:  rsync -e ssh -az --partial --progress ./foo remotehost:~/bar/  This will resume broken file transfers where they were left off, and give you completion statistics with transfer rate, percent complete and estimated time left.",
            "title": "Long and Partial Transfers"
        },
        {
            "location": "/rsync/#recursively-link-src-to-dst",
            "text": "rsync can be used to create a hard linked local copy of a whole tree. This is useful if you don't have GNU cp where the same could be done with simply  cp -lrp . On OS X with  homebrew , GNU cp can be installed via  brew install coreutils  and accessed via  gcp . See also  ls -la /usr/local/opt/coreutils/bin/ .  Slashes are really really important here; this won't work if you get them wrong. Absolute paths must be given, thus ${PWD} and ${HOME} vs ~  rsync -aP --link-dest=\"${PWD}/src\" ./src/ dst #recursively hard link ./src to dst  For example:  rsync -aivv --link-dest=\"${HOME}/Dropbox\" ${HOME}/Dropbox/some_dir ${HOME}/temp/  This will create the directory  ${HOME}/temp/some_dir  and hard link all the files from the source into the destination.  It should only take a few seconds.  Lines with 'hf' indicate a hard linked file.  Lines with 'cd' indicate 'created directory'.  rsync can copy not only data, but also filesystem attributes, and if these differ between the link-dest and the src, a hard link may not be created but instead a copy of the file from the local filesystem is made and correct metadata is applied from the source.",
            "title": "Recursively link src to dst"
        },
        {
            "location": "/rsync/#move-files-to-another-server-in-small-batches",
            "text": "This is useful if you want to gradually clear up disk space rather than waiting until the end of a transfer of a large number of files to clear up disk space in one large operation.  while date ;\nfiles=$(find /srv/backups/scribe/./ -type f -mtime +400 | head -n 500) ;\necho md5 of files ${#files} is $(echo ${files} | md5sum) ;\n[ ! -z \"${files}\" ] ; do\n  sudo rsync --bwlimit 20000 -RaPi --remove-source-files ${files} root@10.2.17.7:/srv/backups/scribe-sea/ ; echo sleeping ;\n  sleep 10 ;\ndone ;",
            "title": "Move files to another server in small batches"
        },
        {
            "location": "/rsync/#move-all-datestamped-files-older-than-the-beginning-of-the-previous-month-excluding-symlinks",
            "text": "This relies on gnu date, so use gdate if used on OS X.  rsync -aPiv \\\n  --remove-source-files \\\n  --bwlimit 20000 \\\n  --exclude=\"**$(date -d \"1 month ago\" \"+%Y-%m\")**\" \\\n  --exclude=\"**$(date \"+%Y-%m\")**\" \\\n  --no-links \\\n  /srv/backups/scribe/* \\\n  root@10.2.17.7:/srv/backups/scribe-sea/",
            "title": "Move all datestamped files older than the beginning of the previous month, excluding symlinks"
        },
        {
            "location": "/rsync/#reduce-time-precision-during-comparison",
            "text": "This is useful for rsyncing to FAT filesystems where time precision is 2 seconds.  rsync --modify-window=1 # allow 1 second of difference in timestamps",
            "title": "Reduce time precision during comparison"
        },
        {
            "location": "/rsync/#see-also",
            "text": "prsync  pssh  pscp",
            "title": "See Also"
        },
        {
            "location": "/saltstack/",
            "text": "\"Software to automate the management and configuration of any infrastructure or application at scale.\" - \nhttp://github.com/saltstack/salt\n\n\n\n\nhttps://github.com/saltstack/salt\n\n\nhttps://docs.saltstack.com/en/latest/topics/tutorials\n\n\nhttps://docs.saltstack.com/en/latest/topics/development/index.html\n\n\n\n\nDesign characteristics\n\n\n\n\nGlossary: \nhttps://docs.saltstack.com/en/latest/glossary.html\n\n\n\n\nCommon commands\n\n\nAll \nsalt*\n commands require root access, so use sudo or log in as root.\n\n\n\n\nsalt\n: Salt allows for commands to be executed across a swath of remote systems in parallel. This means that remote systems can be both controlled and queried with ease.\n\n\nsalt-call\n: The salt-call  command is used to run module functions locally on a minion instead of executing them from the master. Salt-call is used to run a Standalone Minion, and was originally created for troubleshooting.\n\n\nsalt-cloud\n: Salt Cloud is the system used to provision virtual machines on various public clouds via a cleanly controlled profile and mapping system.\n\n\nsalt-cp\n: Salt copy copies a local file out to all of the Salt minions matched by the given target.\n\n\nsalt-key\n: Salt-key executes simple management of Salt server public keys used for authentication.\n\n\nsalt-minion\n: The Salt minion daemon, receives commands from a remote Salt master.\n\n\nsalt-run\n: salt-run is the frontend command for executing Salt Runners.  Salt runners are simple modules used to execute convenience functions on the master.\n\n\nsalt-ssh\n: Salt SSH allows for salt routines to be executed using only SSH for transport.\n\n\n\n\nState files\n\n\nThese are \ndesired\n state files, not the view of the current state. These are where you describe how you want the system to be\n\n\nGrains\n\n\nFacts about a system. Similar to facter in puppet land.\n\n\nPillar\n\n\nHierarchical data to be interpolated into variables in state files. Similar to hiera in puppet land.\n\n\nExamples\n\n\nConfigure output options\n\n\nUnfortunately this only applies to the \nsalt\n command, not \nsalt-run\n, \nsalt-key\n, etc..\n\n\n$ cat ~/.saltrc\noutput: yaml\n\n\n\n\nView salt versions\n\n\nFor simple salt version:\n\n\nsalt --version\n\n\n\n\nFor more specific versions:\n\n\nsalt --versions\n\n\n\n\nShow all minions\n\n\nShow all responding minions\n\n\nsalt-run manage.up\n\n\n\n\nShow all minions, listed by hostst that are up and hosts that are down\n\n\nsalt-run manage.status\n\n\n\n\nExample output:\n\n\ndown:\n    - hadoop4.chn1.example\nup:\n    - appserver1.chn1.example\n    - backups1.chn1.example\n\n\n\n\nShow any host that has had salt applied at some point\n\n\nThis shows only accepted keys. Without the \njq\n part, rejected and denied keys would also show up in this list.\n\n\nsalt-key --out json | jq '.minions[]'\n\n\n\n\nAccept a key that has not yet been accepted\n\n\nAfter finding the hostname in the Unaccepted list returned by \nsalt-key\n:\n\n\nsalt-key -a hostname.example.com\n\n\n\n\nShow the version of an installed package on all hosts\n\n\nsalt '*' pkg.version bash\n\n\n\n\nTargeting hosts\n\n\n\n\nhttps://docs.saltstack.com/en/latest/topics/targeting/#advanced-targeting-methods\n\n\n\n\nTarget using globs\n\n\nsalt '*dev*' pkg.install pre-commit\n\n\n\n\nTarget using regular expressions\n\n\nsalt -b1 -E 'miner..-aws' cmd.run 'service miner restart'\n\n\n\n\nTarget an IP subnet\n\n\nsalt -t 15 -S '172.21.5.0/24' cmd.run 'dpkg -l linux-image'\n\n\n\n\nTarget a specific OS\n\n\nhttps://docs.saltstack.com/en/latest/topics/targeting/compound.html\n\n\nsalt -C 'G@lsb_distrib_codename:trusty' pkg.install cmatrix\n\n\n\n\nRun a command on a subset of hosts\n\n\nCheck ntp stats on hadoop hosts.\n\n\nsalt \"*hadoop*\" cmd.run \"ntpq -p\"\n\n\n\n\nMany more complicated examples of remote command execution: \nhttps://docs.saltstack.com/en/latest/topics/execution/remote_execution.html\n\n\nShow IP addresses\n\n\nhttps://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.network.html\n\n\nsalt '*itni*' network.ip_addrs\n\n\n\n\nShow available grains\n\n\nThis just lists the grain keys, not the values\n\n\nsalt '*minecraft*' grains.ls\n\n\n\n\nShow grain data for a subset of hosts\n\n\nThis lists the keys and values\n\n\nsalt '*dorks*' grains.items\n\n\n\n\nShow one grain for a subset of hosts\n\n\nsalt '*elk*' grains.fetch lsb_distrib_release\n\n\n\n\nor...\n\n\nsalt '*elk*' grains.item os\n\n\n\n\nLook up grain data while logged into a minion\n\n\nWhile logged into a minion, you can view what pillar data would be applied:\n\n\nsalt-call pillar.get users\n\n\n\n\nAppend a username to the accounts grain and apply the users saltstate\n\n\nsalt '*searchstring*' grains.append accounts user-to-add\nsalt '*searchstring*' state.sls users\nsalt '*searchstring*' user.list_users --out yaml > list_users.yaml\n\n\n\n\nOr as a function to run locally\n\n\nadd_user_via_salt_grains() {\n  new_user=$1\n  id \"${new_user}\" && return 0\n  salt-call grains.append accounts \"$new_user\" && \\\n  salt-call state.sls users\n  id \"$new_user\"\n}",
            "title": "Saltstack"
        },
        {
            "location": "/saltstack/#design-characteristics",
            "text": "Glossary:  https://docs.saltstack.com/en/latest/glossary.html",
            "title": "Design characteristics"
        },
        {
            "location": "/saltstack/#common-commands",
            "text": "All  salt*  commands require root access, so use sudo or log in as root.   salt : Salt allows for commands to be executed across a swath of remote systems in parallel. This means that remote systems can be both controlled and queried with ease.  salt-call : The salt-call  command is used to run module functions locally on a minion instead of executing them from the master. Salt-call is used to run a Standalone Minion, and was originally created for troubleshooting.  salt-cloud : Salt Cloud is the system used to provision virtual machines on various public clouds via a cleanly controlled profile and mapping system.  salt-cp : Salt copy copies a local file out to all of the Salt minions matched by the given target.  salt-key : Salt-key executes simple management of Salt server public keys used for authentication.  salt-minion : The Salt minion daemon, receives commands from a remote Salt master.  salt-run : salt-run is the frontend command for executing Salt Runners.  Salt runners are simple modules used to execute convenience functions on the master.  salt-ssh : Salt SSH allows for salt routines to be executed using only SSH for transport.",
            "title": "Common commands"
        },
        {
            "location": "/saltstack/#state-files",
            "text": "These are  desired  state files, not the view of the current state. These are where you describe how you want the system to be",
            "title": "State files"
        },
        {
            "location": "/saltstack/#grains",
            "text": "Facts about a system. Similar to facter in puppet land.",
            "title": "Grains"
        },
        {
            "location": "/saltstack/#pillar",
            "text": "Hierarchical data to be interpolated into variables in state files. Similar to hiera in puppet land.",
            "title": "Pillar"
        },
        {
            "location": "/saltstack/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/saltstack/#configure-output-options",
            "text": "Unfortunately this only applies to the  salt  command, not  salt-run ,  salt-key , etc..  $ cat ~/.saltrc\noutput: yaml",
            "title": "Configure output options"
        },
        {
            "location": "/saltstack/#view-salt-versions",
            "text": "For simple salt version:  salt --version  For more specific versions:  salt --versions",
            "title": "View salt versions"
        },
        {
            "location": "/saltstack/#show-all-minions",
            "text": "",
            "title": "Show all minions"
        },
        {
            "location": "/saltstack/#show-all-responding-minions",
            "text": "salt-run manage.up",
            "title": "Show all responding minions"
        },
        {
            "location": "/saltstack/#show-all-minions-listed-by-hostst-that-are-up-and-hosts-that-are-down",
            "text": "salt-run manage.status  Example output:  down:\n    - hadoop4.chn1.example\nup:\n    - appserver1.chn1.example\n    - backups1.chn1.example",
            "title": "Show all minions, listed by hostst that are up and hosts that are down"
        },
        {
            "location": "/saltstack/#show-any-host-that-has-had-salt-applied-at-some-point",
            "text": "This shows only accepted keys. Without the  jq  part, rejected and denied keys would also show up in this list.  salt-key --out json | jq '.minions[]'",
            "title": "Show any host that has had salt applied at some point"
        },
        {
            "location": "/saltstack/#accept-a-key-that-has-not-yet-been-accepted",
            "text": "After finding the hostname in the Unaccepted list returned by  salt-key :  salt-key -a hostname.example.com",
            "title": "Accept a key that has not yet been accepted"
        },
        {
            "location": "/saltstack/#show-the-version-of-an-installed-package-on-all-hosts",
            "text": "salt '*' pkg.version bash",
            "title": "Show the version of an installed package on all hosts"
        },
        {
            "location": "/saltstack/#targeting-hosts",
            "text": "https://docs.saltstack.com/en/latest/topics/targeting/#advanced-targeting-methods",
            "title": "Targeting hosts"
        },
        {
            "location": "/saltstack/#target-using-globs",
            "text": "salt '*dev*' pkg.install pre-commit",
            "title": "Target using globs"
        },
        {
            "location": "/saltstack/#target-using-regular-expressions",
            "text": "salt -b1 -E 'miner..-aws' cmd.run 'service miner restart'",
            "title": "Target using regular expressions"
        },
        {
            "location": "/saltstack/#target-an-ip-subnet",
            "text": "salt -t 15 -S '172.21.5.0/24' cmd.run 'dpkg -l linux-image'",
            "title": "Target an IP subnet"
        },
        {
            "location": "/saltstack/#target-a-specific-os",
            "text": "https://docs.saltstack.com/en/latest/topics/targeting/compound.html  salt -C 'G@lsb_distrib_codename:trusty' pkg.install cmatrix",
            "title": "Target a specific OS"
        },
        {
            "location": "/saltstack/#run-a-command-on-a-subset-of-hosts",
            "text": "Check ntp stats on hadoop hosts.  salt \"*hadoop*\" cmd.run \"ntpq -p\"  Many more complicated examples of remote command execution:  https://docs.saltstack.com/en/latest/topics/execution/remote_execution.html",
            "title": "Run a command on a subset of hosts"
        },
        {
            "location": "/saltstack/#show-ip-addresses",
            "text": "https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.network.html  salt '*itni*' network.ip_addrs",
            "title": "Show IP addresses"
        },
        {
            "location": "/saltstack/#show-available-grains",
            "text": "This just lists the grain keys, not the values  salt '*minecraft*' grains.ls",
            "title": "Show available grains"
        },
        {
            "location": "/saltstack/#show-grain-data-for-a-subset-of-hosts",
            "text": "This lists the keys and values  salt '*dorks*' grains.items",
            "title": "Show grain data for a subset of hosts"
        },
        {
            "location": "/saltstack/#show-one-grain-for-a-subset-of-hosts",
            "text": "salt '*elk*' grains.fetch lsb_distrib_release  or...  salt '*elk*' grains.item os",
            "title": "Show one grain for a subset of hosts"
        },
        {
            "location": "/saltstack/#look-up-grain-data-while-logged-into-a-minion",
            "text": "While logged into a minion, you can view what pillar data would be applied:  salt-call pillar.get users",
            "title": "Look up grain data while logged into a minion"
        },
        {
            "location": "/saltstack/#append-a-username-to-the-accounts-grain-and-apply-the-users-saltstate",
            "text": "salt '*searchstring*' grains.append accounts user-to-add\nsalt '*searchstring*' state.sls users\nsalt '*searchstring*' user.list_users --out yaml > list_users.yaml  Or as a function to run locally  add_user_via_salt_grains() {\n  new_user=$1\n  id \"${new_user}\" && return 0\n  salt-call grains.append accounts \"$new_user\" && \\\n  salt-call state.sls users\n  id \"$new_user\"\n}",
            "title": "Append a username to the accounts grain and apply the users saltstate"
        },
        {
            "location": "/samsung/",
            "text": "Android links relevant to Samsung\n\n\n\n\nhttp://www.sammobile.com/firmwares/database/SM-T700/\n\n\nhttps://samsung-firmware.org/all/\n\n\nhttps://en.wikipedia.org/wiki/Android_version_history\n\n\nhttps://en.wikipedia.org/wiki/Samsung_Galaxy_Tab_S_8.4\n\n\nhttps://www.kingoapp.com/help/samsung-knox-counter.htm\n\n\n\n\nTV links\n\n\n\n\nUN55D6000 specs\n\n\nUN65KS8000 specs",
            "title": "Android links relevant to Samsung"
        },
        {
            "location": "/samsung/#android-links-relevant-to-samsung",
            "text": "http://www.sammobile.com/firmwares/database/SM-T700/  https://samsung-firmware.org/all/  https://en.wikipedia.org/wiki/Android_version_history  https://en.wikipedia.org/wiki/Samsung_Galaxy_Tab_S_8.4  https://www.kingoapp.com/help/samsung-knox-counter.htm",
            "title": "Android links relevant to Samsung"
        },
        {
            "location": "/samsung/#tv-links",
            "text": "UN55D6000 specs  UN65KS8000 specs",
            "title": "TV links"
        },
        {
            "location": "/screenshot/",
            "text": "Linux\n\n\nGrab all vt screenshots\n\n\nfor X in {0..10} ; do\n  sudo DISPLAY=:0 fbgrab -c${X} fbgrab_vt${X}_screenshot.png ;\ndone ;\n\n\n\n\nScreenshot X using scrot\n\n\nsudo DISPLAY=:0 scrot -b -d 5 'scrot_%F-%T.png'\n\n\n\n\nScreenshot X using imagemagick\n\n\nsudo DISPLAY=:0 import -window root imagemagick_screenshot.png\n\n\n\n\nmacOS\n\n\nscreencapture screenshot.png\n\n\n\n\nThere are a lot of command line args for this tool.",
            "title": "Linux"
        },
        {
            "location": "/screenshot/#linux",
            "text": "",
            "title": "Linux"
        },
        {
            "location": "/screenshot/#grab-all-vt-screenshots",
            "text": "for X in {0..10} ; do\n  sudo DISPLAY=:0 fbgrab -c${X} fbgrab_vt${X}_screenshot.png ;\ndone ;",
            "title": "Grab all vt screenshots"
        },
        {
            "location": "/screenshot/#screenshot-x-using-scrot",
            "text": "sudo DISPLAY=:0 scrot -b -d 5 'scrot_%F-%T.png'",
            "title": "Screenshot X using scrot"
        },
        {
            "location": "/screenshot/#screenshot-x-using-imagemagick",
            "text": "sudo DISPLAY=:0 import -window root imagemagick_screenshot.png",
            "title": "Screenshot X using imagemagick"
        },
        {
            "location": "/screenshot/#macos",
            "text": "screencapture screenshot.png  There are a lot of command line args for this tool.",
            "title": "macOS"
        },
        {
            "location": "/sdr/",
            "text": "Software Defined Radio\n\n\nOverview\n\n\nSDR is dominated by windows software, so this is going to leave all that out and deal with Linux and Mac OS software.\n\n\nLinks\n\n\n\n\nNOAA weather by state - \nhttp://www.nws.noaa.gov/nwr/coverage/ccov.php\n\n\nGood scanning software - \nhttp://gqrx.dk/\n\n\nhttps://www.radioreference.com/\n\n\nhttp://www.sigidwiki.com/\n\n\nBaudline\n - \"Baudline is a time-frequency browser designed for scientific visualization of the spectral domain.\"\n\n\nGNU Radio\n - \"GNU Radio is a free & open-source software development toolkit that provides signal processing blocks to implement software radios.\"\n\n\nInspectrum\n - \"inspectrum is a tool for analysing captured signals, primarily from software-defined radio receivers.\"",
            "title": "Sdr"
        },
        {
            "location": "/sdr/#overview",
            "text": "SDR is dominated by windows software, so this is going to leave all that out and deal with Linux and Mac OS software.",
            "title": "Overview"
        },
        {
            "location": "/sdr/#links",
            "text": "NOAA weather by state -  http://www.nws.noaa.gov/nwr/coverage/ccov.php  Good scanning software -  http://gqrx.dk/  https://www.radioreference.com/  http://www.sigidwiki.com/  Baudline  - \"Baudline is a time-frequency browser designed for scientific visualization of the spectral domain.\"  GNU Radio  - \"GNU Radio is a free & open-source software development toolkit that provides signal processing blocks to implement software radios.\"  Inspectrum  - \"inspectrum is a tool for analysing captured signals, primarily from software-defined radio receivers.\"",
            "title": "Links"
        },
        {
            "location": "/sed/",
            "text": "sed is the stream editor.\n\n\nTips\n\n\nOSX Pitfalls\n\n\nBeware that BSD sed -i requires a mandatory flag for the backup file. You can use -i '' to have no backup file.\n\n\nAlso, OS X sed doesn't support case insensitivity! WTF?! We have to use \nperl -pe 's/foo/bar/i' foo.txt\n or homebrew's \ngsed\n.\n\n\nOnly print a specific line\n\n\nThis will print only the second line of the file\n\n\nsed -n ' 2{p;q;}' foo.txt\n\n\nOnly print if match\n\n\nThis will perform a replacement and print the result. Use \n-i\n (with caution!) to edit the file at the same time.\n\n\nsed -n 's/\\(127.[0-9]\\{1,3\\}.[0-9]\\{1,3\\}.[0-9]\\{1,3\\}\\)/\\1 localhost localhost4/p' /etc/hosts\n\n\n\n\nAdd a new line with content after a match\n\n\nSince sed can't insert things like \\n, this has to take place on multiple lines, so it's a bit funky looking but still functional.\n\n\nsed -i \"\" -e '/respawn/a\\\nrespawn limit 10 5' zoosk_worker_*.conf\n\n\n\n\nUncomment a line that matches a regex\n\n\nThis removes the comment and adds wheel to the \nsudoers\n list\n\n\n/bin/sed -i '/^#\\s\\+%wheel\\s\\+ALL=(ALL)\\s\\+ALL$/s/^#\\s*//' /etc/sudoers\n\n\nDelete lines containing a string\n\n\nsed -i -e '/root/d' asdf.txt\n\n\nDelete lines not containing a string\n\n\nsed -i '/foo/!d' wy.txt\n\n\nOr not containing a MAC address:\n\n\nsed -i '' -E '/[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}/!d' *\n\n\nDo a replacement on all files in a dir\n\n\nsed -i \"s/foo/bar/g\" /etc/apache2/sites-available/*\n\n\nSwitch all github urls from http to ssh\n\n\nsed '/url = /s%https?://github.com/\\([^/]*/[^/]*\\)%git@github.com:\\1%' ~/code/*/.git/config\n\n\nWord boundaries\n\n\nNormally, word boundaries look like this:\n\n\n/\\bMyWord\\b/\n\n\nor\n\n\n/\\<myword\\>/\n\n\n\n\nBut in OS X, you have to do them like this:\n\n\n/[[:<:]]MyWord[[:>:]]/\n\n\n\n\nWhich is just ridiculous, so use homebrew's \ngsed\n if you can.\n\n\nAdd a bell to \ntail\n -f\n\n\ntail -n 0 -f /var/log/messages | sed 's/$/\\a'\n\n\nSee Also\n\n\n\n\nSome great sed tips - \nhttp://www-rohan.sdsu.edu/doc/sed.html",
            "title": "Sed"
        },
        {
            "location": "/sed/#tips",
            "text": "",
            "title": "Tips"
        },
        {
            "location": "/sed/#osx-pitfalls",
            "text": "Beware that BSD sed -i requires a mandatory flag for the backup file. You can use -i '' to have no backup file.  Also, OS X sed doesn't support case insensitivity! WTF?! We have to use  perl -pe 's/foo/bar/i' foo.txt  or homebrew's  gsed .",
            "title": "OSX Pitfalls"
        },
        {
            "location": "/sed/#only-print-a-specific-line",
            "text": "This will print only the second line of the file  sed -n ' 2{p;q;}' foo.txt",
            "title": "Only print a specific line"
        },
        {
            "location": "/sed/#only-print-if-match",
            "text": "This will perform a replacement and print the result. Use  -i  (with caution!) to edit the file at the same time.  sed -n 's/\\(127.[0-9]\\{1,3\\}.[0-9]\\{1,3\\}.[0-9]\\{1,3\\}\\)/\\1 localhost localhost4/p' /etc/hosts",
            "title": "Only print if match"
        },
        {
            "location": "/sed/#add-a-new-line-with-content-after-a-match",
            "text": "Since sed can't insert things like \\n, this has to take place on multiple lines, so it's a bit funky looking but still functional.  sed -i \"\" -e '/respawn/a\\\nrespawn limit 10 5' zoosk_worker_*.conf",
            "title": "Add a new line with content after a match"
        },
        {
            "location": "/sed/#uncomment-a-line-that-matches-a-regex",
            "text": "This removes the comment and adds wheel to the  sudoers  list  /bin/sed -i '/^#\\s\\+%wheel\\s\\+ALL=(ALL)\\s\\+ALL$/s/^#\\s*//' /etc/sudoers",
            "title": "Uncomment a line that matches a regex"
        },
        {
            "location": "/sed/#delete-lines-containing-a-string",
            "text": "sed -i -e '/root/d' asdf.txt",
            "title": "Delete lines containing a string"
        },
        {
            "location": "/sed/#delete-lines-not-containing-a-string",
            "text": "sed -i '/foo/!d' wy.txt  Or not containing a MAC address:  sed -i '' -E '/[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}/!d' *",
            "title": "Delete lines not containing a string"
        },
        {
            "location": "/sed/#do-a-replacement-on-all-files-in-a-dir",
            "text": "sed -i \"s/foo/bar/g\" /etc/apache2/sites-available/*",
            "title": "Do a replacement on all files in a dir"
        },
        {
            "location": "/sed/#switch-all-github-urls-from-http-to-ssh",
            "text": "sed '/url = /s%https?://github.com/\\([^/]*/[^/]*\\)%git@github.com:\\1%' ~/code/*/.git/config",
            "title": "Switch all github urls from http to ssh"
        },
        {
            "location": "/sed/#word-boundaries",
            "text": "Normally, word boundaries look like this:  /\\bMyWord\\b/  or  /\\<myword\\>/  But in OS X, you have to do them like this:  /[[:<:]]MyWord[[:>:]]/  Which is just ridiculous, so use homebrew's  gsed  if you can.",
            "title": "Word boundaries"
        },
        {
            "location": "/sed/#add-a-bell-to-tail-f",
            "text": "tail -n 0 -f /var/log/messages | sed 's/$/\\a'",
            "title": "Add a bell to tail -f"
        },
        {
            "location": "/sed/#see-also",
            "text": "Some great sed tips -  http://www-rohan.sdsu.edu/doc/sed.html",
            "title": "See Also"
        },
        {
            "location": "/selinux/",
            "text": "Security Enhanced Linux\n\n\nNotes\n\n\n\n\nTutorial Video: \nhttps://www.youtube.com/watch?v=MxjenQ31b70\n\n\nCentOS HowTo: \nhttp://wiki.centos.org/HowTos/SELinux\n\n\nLabels are in user:role:type:level(optional)\n\n\nLogs go in /var/log/audit/audit.log and /var/log/messages\n\n\n\n\nAdditional tools:\n\n\n\n\n\n\nsemanage and more are included in CentOS package \npolicycoreutils\n\n\n\n\nsetroubleshoot\n has a bunch of tools included. Lots of prerequisites\n\n\nsetroubleshoot-server\n has a bunch of tools included. Lots of prerequisites\n\n\n\n\nExamples\n\n\nShow status of selinux\n\n\nsestatus\ngetenforce\n\n\n\n\nDisable without rebooting\n\n\necho 0 >/selinux/enforce\n\n\n\n\nor...\n\n\nsetenforce 0\n\n\n\n\nList selinux contexts for processes\n\n\nps auxZ\n\n\n\n\nList selinux contexts for processes that have open sockets\n\n\nlsof -i -Z # See `man lsof` for more specific selinux syntaxes\n\n\n\n\nList selinux contexts for the current user\n\n\nid -Z\n\n\n\n\nList selinux contexts for files\n\n\nls -lZ\n\n\n\n\nRecursively set a context type\n\n\nchcon -R -t httpd_sys_content_t sole\n\n\n\n\nCopy the selinux context from another file or directory\n\n\nchcon --reference /file/or/dir/to/reference /target/file\n\n\n\n\nRestore default contexts\n\n\nThis command restores the contexts as referenced in /etc/selinux/targeted/contexts/files/file_contexts\n\n\nrestorecon /path/to/broken/file\nrestorecon -vR /path/to/broken/dir\n\n\n\n\nRestore defaults context automatically at system reboot\n\n\nThis should take roughly the same amount of time as a fsck would.\n\n\ntouch /.autorelabel\n\n\n\n\nDefine a default context for a directory\n\n\nsemanage fcontext -a /z5/sole\n\n\n\n\nDefine a default context for a directory, using a reference from the original policy\n\n\nsemanage fcontext -a -e /var/www /z5/sole\ncat /etc/selinux/targeted/contexts/files/file_contexts.subs # view the result\n\n\n\n\nList policies\n\n\nsemanage port -l\nsemanage user -l\n\n\n\n\nShow selinux booleans\n\n\ngetsebool -a\n\n\n\n\nPermanetnly set an selinux boolean\n\n\nsetsebool -P booleanname 1",
            "title": "Selinux"
        },
        {
            "location": "/selinux/#notes",
            "text": "Tutorial Video:  https://www.youtube.com/watch?v=MxjenQ31b70  CentOS HowTo:  http://wiki.centos.org/HowTos/SELinux  Labels are in user:role:type:level(optional)  Logs go in /var/log/audit/audit.log and /var/log/messages   Additional tools:    semanage and more are included in CentOS package  policycoreutils   setroubleshoot  has a bunch of tools included. Lots of prerequisites  setroubleshoot-server  has a bunch of tools included. Lots of prerequisites",
            "title": "Notes"
        },
        {
            "location": "/selinux/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/selinux/#show-status-of-selinux",
            "text": "sestatus\ngetenforce",
            "title": "Show status of selinux"
        },
        {
            "location": "/selinux/#disable-without-rebooting",
            "text": "echo 0 >/selinux/enforce  or...  setenforce 0",
            "title": "Disable without rebooting"
        },
        {
            "location": "/selinux/#list-selinux-contexts-for-processes",
            "text": "ps auxZ",
            "title": "List selinux contexts for processes"
        },
        {
            "location": "/selinux/#list-selinux-contexts-for-processes-that-have-open-sockets",
            "text": "lsof -i -Z # See `man lsof` for more specific selinux syntaxes",
            "title": "List selinux contexts for processes that have open sockets"
        },
        {
            "location": "/selinux/#list-selinux-contexts-for-the-current-user",
            "text": "id -Z",
            "title": "List selinux contexts for the current user"
        },
        {
            "location": "/selinux/#list-selinux-contexts-for-files",
            "text": "ls -lZ",
            "title": "List selinux contexts for files"
        },
        {
            "location": "/selinux/#recursively-set-a-context-type",
            "text": "chcon -R -t httpd_sys_content_t sole",
            "title": "Recursively set a context type"
        },
        {
            "location": "/selinux/#copy-the-selinux-context-from-another-file-or-directory",
            "text": "chcon --reference /file/or/dir/to/reference /target/file",
            "title": "Copy the selinux context from another file or directory"
        },
        {
            "location": "/selinux/#restore-default-contexts",
            "text": "This command restores the contexts as referenced in /etc/selinux/targeted/contexts/files/file_contexts  restorecon /path/to/broken/file\nrestorecon -vR /path/to/broken/dir",
            "title": "Restore default contexts"
        },
        {
            "location": "/selinux/#restore-defaults-context-automatically-at-system-reboot",
            "text": "This should take roughly the same amount of time as a fsck would.  touch /.autorelabel",
            "title": "Restore defaults context automatically at system reboot"
        },
        {
            "location": "/selinux/#define-a-default-context-for-a-directory",
            "text": "semanage fcontext -a /z5/sole",
            "title": "Define a default context for a directory"
        },
        {
            "location": "/selinux/#define-a-default-context-for-a-directory-using-a-reference-from-the-original-policy",
            "text": "semanage fcontext -a -e /var/www /z5/sole\ncat /etc/selinux/targeted/contexts/files/file_contexts.subs # view the result",
            "title": "Define a default context for a directory, using a reference from the original policy"
        },
        {
            "location": "/selinux/#list-policies",
            "text": "semanage port -l\nsemanage user -l",
            "title": "List policies"
        },
        {
            "location": "/selinux/#show-selinux-booleans",
            "text": "getsebool -a",
            "title": "Show selinux booleans"
        },
        {
            "location": "/selinux/#permanetnly-set-an-selinux-boolean",
            "text": "setsebool -P booleanname 1",
            "title": "Permanetnly set an selinux boolean"
        },
        {
            "location": "/semver/",
            "text": "Semantic Versioning",
            "title": "Semver"
        },
        {
            "location": "/sensu/",
            "text": "\"Monitor servers, services, application health, and business KPIs. Get notified about failures before your users do. Collect and analyze custom metrics. Give your business the competitive advantage it deserves.\" - \nhttps://sensuapp.org\n\n\nOverview\n\n\n\n\nChecks\n - used to monitor services or measure resources\n\n\nHandlers\n - for taking action on Sensu events, which are produced by checks\n\n\nFilters\n - for filtering (removing) events destined for one or more event handlers\n\n\nMutators\n - transform event data for handlers\n\n\n\n\nChecks\n\n\n\n\nstandalone checks are scheduled to run periodically on the client (eg: all hosts need to check disks every 15 minutes)\n\n\nsubscription checks are requested by the server to hosts with a given tag (eg: all web hosts need to run check_http)\n\n\n\n\nSee Also\n\n\n\n\nUchiwa - Open source dashboard for Sensu.\n\n\nPuppet + Sensu = Love; Infrastructure as Code and Monitoring, Sharing the Same Development Workflow\n\n\nSF DevOps Meetup: Kyle Anderson, Sensu @ Yelp \nPart 1\n, \nPart 2",
            "title": "Sensu"
        },
        {
            "location": "/sensu/#overview",
            "text": "Checks  - used to monitor services or measure resources  Handlers  - for taking action on Sensu events, which are produced by checks  Filters  - for filtering (removing) events destined for one or more event handlers  Mutators  - transform event data for handlers",
            "title": "Overview"
        },
        {
            "location": "/sensu/#checks",
            "text": "standalone checks are scheduled to run periodically on the client (eg: all hosts need to check disks every 15 minutes)  subscription checks are requested by the server to hosts with a given tag (eg: all web hosts need to run check_http)",
            "title": "Checks"
        },
        {
            "location": "/sensu/#see-also",
            "text": "Uchiwa - Open source dashboard for Sensu.  Puppet + Sensu = Love; Infrastructure as Code and Monitoring, Sharing the Same Development Workflow  SF DevOps Meetup: Kyle Anderson, Sensu @ Yelp  Part 1 ,  Part 2",
            "title": "See Also"
        },
        {
            "location": "/sgdisk/",
            "text": "\"sgdisk - Command-line GUID partition table (GPT) manipulator for Linux and Unix\" - man sgdisk\n\n\nExamples\n\n\nRandomize GUIDs to ensure uniqueness after cloning\n\n\nsgdisk --randomize-guids /dev/sdz\n\n\n\n\nPrint info about partitions on a disk\n\n\nsgdisk -p /dev/sdz\n\n\n\n\nPrint last block number of the largest available section of the disk\n\n\nsgdisk -E /dev/sdz\n\n\n\n\nCreate a new partition\n\n\nThe syntax is partitionNumber:firstBlock:lastBlock\n\n\nsgdisk -n 1:2048:732566636 /dev/sdz\n\n\n\n\nPrint extended info about the first partition on /dev/sda\n\n\nsgdisk -i 1 /dev/sdz\n\n\n\n\nBackup a GUID partition table\n\n\nsgdisk -b ~/sdz_partition_backup /dev/sdz\n\n\n\n\nRestore a GUID partition table\n\n\nsgdisk -l ~/sdz_partition_backup /dev/sdz\n\n\n\n\nCreate a new partition\n\n\nThis creates a 4th partition that is 50G using the default starting point (0 is default)\n\n\nsgdisk /dev/sdz --new=4:0:+50G\n\n\n\n\nDelete the 4th partition\n\n\nsgdisk /dev/sdz -d 4\n\n\n\n\nCreate a new partition number 4 that fills the biggest available section of the disk\n\n\nsgdisk /dev/sdz -N 4\n\n\n\n\nGrab the name of a partition\n\n\n# sloppy, doesn't handle spaces or single quotes\nsgdisk /dev/sdk -i 1 | grep '^Partition name' | awk '{print $NF}' | sed \"s/'//g\"",
            "title": "Sgdisk"
        },
        {
            "location": "/sgdisk/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/sgdisk/#randomize-guids-to-ensure-uniqueness-after-cloning",
            "text": "sgdisk --randomize-guids /dev/sdz",
            "title": "Randomize GUIDs to ensure uniqueness after cloning"
        },
        {
            "location": "/sgdisk/#print-info-about-partitions-on-a-disk",
            "text": "sgdisk -p /dev/sdz",
            "title": "Print info about partitions on a disk"
        },
        {
            "location": "/sgdisk/#print-last-block-number-of-the-largest-available-section-of-the-disk",
            "text": "sgdisk -E /dev/sdz",
            "title": "Print last block number of the largest available section of the disk"
        },
        {
            "location": "/sgdisk/#create-a-new-partition",
            "text": "The syntax is partitionNumber:firstBlock:lastBlock  sgdisk -n 1:2048:732566636 /dev/sdz",
            "title": "Create a new partition"
        },
        {
            "location": "/sgdisk/#print-extended-info-about-the-first-partition-on-devsda",
            "text": "sgdisk -i 1 /dev/sdz",
            "title": "Print extended info about the first partition on /dev/sda"
        },
        {
            "location": "/sgdisk/#backup-a-guid-partition-table",
            "text": "sgdisk -b ~/sdz_partition_backup /dev/sdz",
            "title": "Backup a GUID partition table"
        },
        {
            "location": "/sgdisk/#restore-a-guid-partition-table",
            "text": "sgdisk -l ~/sdz_partition_backup /dev/sdz",
            "title": "Restore a GUID partition table"
        },
        {
            "location": "/sgdisk/#create-a-new-partition_1",
            "text": "This creates a 4th partition that is 50G using the default starting point (0 is default)  sgdisk /dev/sdz --new=4:0:+50G",
            "title": "Create a new partition"
        },
        {
            "location": "/sgdisk/#delete-the-4th-partition",
            "text": "sgdisk /dev/sdz -d 4",
            "title": "Delete the 4th partition"
        },
        {
            "location": "/sgdisk/#create-a-new-partition-number-4-that-fills-the-biggest-available-section-of-the-disk",
            "text": "sgdisk /dev/sdz -N 4",
            "title": "Create a new partition number 4 that fills the biggest available section of the disk"
        },
        {
            "location": "/sgdisk/#grab-the-name-of-a-partition",
            "text": "# sloppy, doesn't handle spaces or single quotes\nsgdisk /dev/sdk -i 1 | grep '^Partition name' | awk '{print $NF}' | sed \"s/'//g\"",
            "title": "Grab the name of a partition"
        },
        {
            "location": "/shutdown/",
            "text": "a command to reboot a *nix server.\n\n\nExamples\n\n\nReboot a server in 5 minutes with a message\n\n\nshutdown -r +5 \"Please announce in #dev if you would like to cancel this reboot\"\n\n\n\n\nPower off a server in 5 minutes\n\n\nshutdown -P +5\n\n\n\n\nCancel a scheduled shutdown\n\n\nshutdown -c",
            "title": "Shutdown"
        },
        {
            "location": "/shutdown/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/shutdown/#reboot-a-server-in-5-minutes-with-a-message",
            "text": "shutdown -r +5 \"Please announce in #dev if you would like to cancel this reboot\"",
            "title": "Reboot a server in 5 minutes with a message"
        },
        {
            "location": "/shutdown/#power-off-a-server-in-5-minutes",
            "text": "shutdown -P +5",
            "title": "Power off a server in 5 minutes"
        },
        {
            "location": "/shutdown/#cancel-a-scheduled-shutdown",
            "text": "shutdown -c",
            "title": "Cancel a scheduled shutdown"
        },
        {
            "location": "/sips/",
            "text": "\"scriptable image processing system.\" - \nsip --help\n\n\nExamples\n\n\nResize a DNG and save the output as JPG\n\n\nsips --resampleHeightWidthMax 1024  --setProperty format jpeg foo.dng --out foo.jpg\n\n\n\n\nResize all images in the CWD that were taken by the D5100\n\n\nmdfind -onlyin \"$PWD\" 'kMDItemAcquisitionModel == \"NIKON D5100\"' |\nwhile read -r line ; do\n  sips --resampleHeightWidthMax 1600 --setProperty format jpeg \"${line}\" --out \"${line%.*}.jpg\"\ndone\n\n\n\n\nResize all images in a dir tree, convert them to jpg and output them to a different folder\n\n\nIn the following example it is important to leave off the trailing slash on the target dir:\n\n\nfind . -type f -exec sips --resampleHeightWidthMax 800 --setProperty format jpeg {} --out /Volumes/B-Tron/all-jpgs \\;\n\n\n\n\nSee Also\n\n\n\n\nexiftool\n\n\ngraphicsmagick\n\n\nimagemagick\n\n\njpeginfo",
            "title": "Sips"
        },
        {
            "location": "/sips/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/sips/#resize-a-dng-and-save-the-output-as-jpg",
            "text": "sips --resampleHeightWidthMax 1024  --setProperty format jpeg foo.dng --out foo.jpg",
            "title": "Resize a DNG and save the output as JPG"
        },
        {
            "location": "/sips/#resize-all-images-in-the-cwd-that-were-taken-by-the-d5100",
            "text": "mdfind -onlyin \"$PWD\" 'kMDItemAcquisitionModel == \"NIKON D5100\"' |\nwhile read -r line ; do\n  sips --resampleHeightWidthMax 1600 --setProperty format jpeg \"${line}\" --out \"${line%.*}.jpg\"\ndone",
            "title": "Resize all images in the CWD that were taken by the D5100"
        },
        {
            "location": "/sips/#resize-all-images-in-a-dir-tree-convert-them-to-jpg-and-output-them-to-a-different-folder",
            "text": "In the following example it is important to leave off the trailing slash on the target dir:  find . -type f -exec sips --resampleHeightWidthMax 800 --setProperty format jpeg {} --out /Volumes/B-Tron/all-jpgs \\;",
            "title": "Resize all images in a dir tree, convert them to jpg and output them to a different folder"
        },
        {
            "location": "/sips/#see-also",
            "text": "exiftool  graphicsmagick  imagemagick  jpeginfo",
            "title": "See Also"
        },
        {
            "location": "/smartctl/",
            "text": "Linux interface to SMART data for hard disks.\n\n\nExamples\n\n\nShow identifying information about a device\n\n\nsmartctl -i /dev/sda\n\n\n\n\nShow drive attributes\n\n\nThis shows a bunch of recorded information that is updated over the life of the drive.\n\n\nsmartctl -A /dev/sda\n\n\n\n\nShow the same information with better output showing vendor flags\n\n\nsmartctl -A -f brief /dev/sda\n\n\n\n\nShow all data\n\n\nsmartctl -x /dev/sda\n\n\n\n\nSee Also\n\n\n\n\nhttps://www.backblaze.com/blog/what-smart-stats-indicate-hard-drive-failures/",
            "title": "Smartctl"
        },
        {
            "location": "/smartctl/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/smartctl/#show-identifying-information-about-a-device",
            "text": "smartctl -i /dev/sda",
            "title": "Show identifying information about a device"
        },
        {
            "location": "/smartctl/#show-drive-attributes",
            "text": "This shows a bunch of recorded information that is updated over the life of the drive.  smartctl -A /dev/sda  Show the same information with better output showing vendor flags  smartctl -A -f brief /dev/sda",
            "title": "Show drive attributes"
        },
        {
            "location": "/smartctl/#show-all-data",
            "text": "smartctl -x /dev/sda",
            "title": "Show all data"
        },
        {
            "location": "/smartctl/#see-also",
            "text": "https://www.backblaze.com/blog/what-smart-stats-indicate-hard-drive-failures/",
            "title": "See Also"
        },
        {
            "location": "/smartstack/",
            "text": "SmartStack is an automated service discovery and registration framework\n.\n\n\nComponents\n\n\n\n\nSynapse: Announces state of local services\n\n\nNerve: Query zookeeper for healthy services to connect to, then configures HAProxy\n\n\nZookeper: Service registry\n\n\nHAProxy: Load balancing\n\n\n\n\nLinks\n\n\n\n\nDockerCon 14: Tomas Doran - Building a smarter application stack\n\n\nSmartstack ( HAProxy + Serf ) Automated service discovery without rewriting apps\n\n\nGetYourGuide's SmartStack handbook",
            "title": "Smartstack"
        },
        {
            "location": "/smartstack/#components",
            "text": "Synapse: Announces state of local services  Nerve: Query zookeeper for healthy services to connect to, then configures HAProxy  Zookeper: Service registry  HAProxy: Load balancing",
            "title": "Components"
        },
        {
            "location": "/smartstack/#links",
            "text": "DockerCon 14: Tomas Doran - Building a smarter application stack  Smartstack ( HAProxy + Serf ) Automated service discovery without rewriting apps  GetYourGuide's SmartStack handbook",
            "title": "Links"
        },
        {
            "location": "/snap/",
            "text": "\"Package any app for every Linux desktop, server, cloud or device, and deliver updates directly.\" - \nhttp://snapcraft.io/\n\n\n\n\nA snap is a fancy zip file containing an application together with its dependencies, and a description of how it should safely be run on your system, especially the different ways it should talk to other software.\n\n\nMost importantly snaps are designed to be secure, sandboxed, containerised applications isolated from the underlying system and from other applications. Snaps allow the safe installation of apps from any vendor on mission critical devices and desktops.\n\n\n\n\nLinks\n\n\n\n\nhttps://www.ubuntu.com/internet-of-things\n\n\nhttps://developer.ubuntu.com/en/snappy/\n\n\nhttp://snapcraft.io/",
            "title": "Snap"
        },
        {
            "location": "/snap/#links",
            "text": "https://www.ubuntu.com/internet-of-things  https://developer.ubuntu.com/en/snappy/  http://snapcraft.io/",
            "title": "Links"
        },
        {
            "location": "/snmp/",
            "text": "Simple Network Management Protocol\n\n\nLinks\n\n\n\n\nThird party MIBs: \nhttp://www.plixer.com/support/mib_resources.php\n\n\nHow-To: \nhttp://www.linuxhomenetworking.com/wiki/index.php/Quick_HOWTO_:_Ch22_:_Monitoring_Server_Performance\n\n\nAPC has some snmp tricks specific to those devices.\n\n\nhttp://support.ipmonitor.com/mibs_byname_A.aspx\n - Good MIB reference\n\n\n\n\nExamples\n\n\nInstall snmp utils on redhat / centos\n\n\nyum install net-snmp-utils\n\n\n\n\nShow the system description of a host\n\n\nsnmpwalk -v 1 -c public 192.168.9.1 SNMPv2-MIB::sysDescr.0\n\n\n\n\nWalk 172.28.111.10 with community string itgwrk\n\n\nsnmpwalk -v 1 -c \"public\" 172.28.111.10\n\n\n\n\nIPV6 is different...\n\n\nsnmpwalk -v 1 -c public udp6:fe80::a2e:5fff:feba:f586%en0 enterprises\n\n\n\n\nShow Network Info\n\n\nsnmpwalk -c public 192.168.9.1 1.3.6.1.2.1\n\n\n\n\nShow Airport Upload and Download bytes\n\n\nsnmpwalk -c public 192.168.9.1 IF-MIB::ifOutOctets\nsnmpwalk -c public 192.168.9.1 IF-MIB::ifInOctets\n\n\n\n\nShow configured IP addresses\n\n\nIPV4 by querying IPV6: snmpwalk -v 1 -c public udp6:fe80::a2e:5fff:feba:f586%en0 ipAdEntAddr",
            "title": "Snmp"
        },
        {
            "location": "/snmp/#links",
            "text": "Third party MIBs:  http://www.plixer.com/support/mib_resources.php  How-To:  http://www.linuxhomenetworking.com/wiki/index.php/Quick_HOWTO_:_Ch22_:_Monitoring_Server_Performance  APC has some snmp tricks specific to those devices.  http://support.ipmonitor.com/mibs_byname_A.aspx  - Good MIB reference",
            "title": "Links"
        },
        {
            "location": "/snmp/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/snmp/#install-snmp-utils-on-redhat-centos",
            "text": "yum install net-snmp-utils",
            "title": "Install snmp utils on redhat / centos"
        },
        {
            "location": "/snmp/#show-the-system-description-of-a-host",
            "text": "snmpwalk -v 1 -c public 192.168.9.1 SNMPv2-MIB::sysDescr.0",
            "title": "Show the system description of a host"
        },
        {
            "location": "/snmp/#walk-1722811110-with-community-string-itgwrk",
            "text": "snmpwalk -v 1 -c \"public\" 172.28.111.10  IPV6 is different...  snmpwalk -v 1 -c public udp6:fe80::a2e:5fff:feba:f586%en0 enterprises",
            "title": "Walk 172.28.111.10 with community string itgwrk"
        },
        {
            "location": "/snmp/#show-network-info",
            "text": "snmpwalk -c public 192.168.9.1 1.3.6.1.2.1",
            "title": "Show Network Info"
        },
        {
            "location": "/snmp/#show-airport-upload-and-download-bytes",
            "text": "snmpwalk -c public 192.168.9.1 IF-MIB::ifOutOctets\nsnmpwalk -c public 192.168.9.1 IF-MIB::ifInOctets",
            "title": "Show Airport Upload and Download bytes"
        },
        {
            "location": "/snmp/#show-configured-ip-addresses",
            "text": "IPV4 by querying IPV6: snmpwalk -v 1 -c public udp6:fe80::a2e:5fff:feba:f586%en0 ipAdEntAddr",
            "title": "Show configured IP addresses"
        },
        {
            "location": "/solo/",
            "text": "solo is a command that uses a per-user loopback IP# and a designated port to ensure that multiple copies of a command are not run. This takes the place of pid files and process tracking, and has the benefit of never leaving around a false positive. It also lets you skip building trap, pid file and process checking into every shell script you write.\n\n\nhttp://timkay.com/solo",
            "title": "Solo"
        },
        {
            "location": "/sort/",
            "text": "sort is a command to sort lines of data.\n\n\nGNU Syntax Examples\n\n\nIn OS X, this is \ngsort\n.\n\n\nRandomly sort a file\n\n\nBeware that this will put duplicate lines right next to each other. If you need better file shuffling use \nshuf\n.\n\n\nsort -R foo\n\n\n\n\nSort by two fields, first dictionary, second reverse numeric\n\n\n# -k defines the sort key as starting position, sort style, ending position\n# -r is included in the second key to reverse numeric sort\n\ngsort -k1d,1 -k2nr,2\n\n\n\n\nBSD Syntax Examples\n\n\nGNU sort and BSD sort behave differently, which is mostly lame.\n\n\nSort by the third column\n\n\nsort -k 3 filename\n\n\n\n\nSort dates by the day\n\n\nThis example shows how to sort dates in ISO Year format by date. (EG: 2017-01-19). Assumes use of \nbash\n 4 to generate the example dates.\n\n\n# -n for numeric sort\n# -k3 for column 3\n# -t- to use - as a column delimiter\n\nfor X in {2016..2017}-{01..12..03}-{01..19..06} ; do echo ${X} ; done |\n\nsort -n -k3 -t-\n\n\n\n\nSort the /etc/passwd by UID\n\n\nAlso works on /etc/group file and GID\n\n\nsort -n -t: -k 3 /etc/passwd\n\n\n\n\nScan for airport and sort by columns\n\n\nPrint out two rows signifying column numbers, which makes it easier to find which columns you want to sort by, then run a command and sort by column numbers. This assumes you're on macOS.\n\n\nperl -e '\nforeach ( 1 .. 9 ) {\n    foreach ( 1 .. 9 ) { print \" \"; }\n    print $_;\n}\nprint \"\\n\";\nforeach ( 1 .. 9 ) {\n    foreach ( 1 .. 9, 0 ) { print $_; }\n}\nprint \"\\n\";' ; \\\nairport --scan | sort -k 1.52,1.54",
            "title": "Sort"
        },
        {
            "location": "/sort/#gnu-syntax-examples",
            "text": "In OS X, this is  gsort .",
            "title": "GNU Syntax Examples"
        },
        {
            "location": "/sort/#randomly-sort-a-file",
            "text": "Beware that this will put duplicate lines right next to each other. If you need better file shuffling use  shuf .  sort -R foo",
            "title": "Randomly sort a file"
        },
        {
            "location": "/sort/#sort-by-two-fields-first-dictionary-second-reverse-numeric",
            "text": "# -k defines the sort key as starting position, sort style, ending position\n# -r is included in the second key to reverse numeric sort\n\ngsort -k1d,1 -k2nr,2",
            "title": "Sort by two fields, first dictionary, second reverse numeric"
        },
        {
            "location": "/sort/#bsd-syntax-examples",
            "text": "GNU sort and BSD sort behave differently, which is mostly lame.",
            "title": "BSD Syntax Examples"
        },
        {
            "location": "/sort/#sort-by-the-third-column",
            "text": "sort -k 3 filename",
            "title": "Sort by the third column"
        },
        {
            "location": "/sort/#sort-dates-by-the-day",
            "text": "This example shows how to sort dates in ISO Year format by date. (EG: 2017-01-19). Assumes use of  bash  4 to generate the example dates.  # -n for numeric sort\n# -k3 for column 3\n# -t- to use - as a column delimiter\n\nfor X in {2016..2017}-{01..12..03}-{01..19..06} ; do echo ${X} ; done |\n\nsort -n -k3 -t-",
            "title": "Sort dates by the day"
        },
        {
            "location": "/sort/#sort-the-etcpasswd-by-uid",
            "text": "Also works on /etc/group file and GID  sort -n -t: -k 3 /etc/passwd",
            "title": "Sort the /etc/passwd by UID"
        },
        {
            "location": "/sort/#scan-for-airport-and-sort-by-columns",
            "text": "Print out two rows signifying column numbers, which makes it easier to find which columns you want to sort by, then run a command and sort by column numbers. This assumes you're on macOS.  perl -e '\nforeach ( 1 .. 9 ) {\n    foreach ( 1 .. 9 ) { print \" \"; }\n    print $_;\n}\nprint \"\\n\";\nforeach ( 1 .. 9 ) {\n    foreach ( 1 .. 9, 0 ) { print $_; }\n}\nprint \"\\n\";' ; \\\nairport --scan | sort -k 1.52,1.54",
            "title": "Scan for airport and sort by columns"
        },
        {
            "location": "/sphinx/",
            "text": "Sphinx is how many opensource projects generate sites for their documentation.\n- \nhttp://sphinx-doc.org/contents.html",
            "title": "Sphinx"
        },
        {
            "location": "/split/",
            "text": "\"split - split a file into pieces\" - \nman split\n\n\nsplit\n is a common unix command.\n\n\nUsage Examples\n\n\nSplit into DVD sized chunks\n\n\nThis example isn't practical, the size needs to be smaller than specified because of DVD filesystem overhead, so you should use 4700000000 or similar if you want to actually burn the data.\n\n\nsplit -b 4707319808 source\n\n\n\n\nSplit a big file and compress it with gzip before writing to disk\n\n\nThis is useful for splitting up large uncompressed logs. This command is background safe.\n\n\nsplit -a4 --additional-suffix='-redis.log.1' -l500000 --filter='gzip -9 > $FILE.gz' redis.log.1\n\n\n\n\nAnd if you want to see read stats, throw \npv\n in the mix:\n\n\n$ split -a4 --additional-suffix='-redis.log.1' -l500000 --filter='pv | gzip -9 > $FILE.gz' redis.log.1\n1.94GB 0:00:58 [21.2MB/s] [                                         <=>                              ]",
            "title": "Split"
        },
        {
            "location": "/split/#usage-examples",
            "text": "",
            "title": "Usage Examples"
        },
        {
            "location": "/split/#split-into-dvd-sized-chunks",
            "text": "This example isn't practical, the size needs to be smaller than specified because of DVD filesystem overhead, so you should use 4700000000 or similar if you want to actually burn the data.  split -b 4707319808 source",
            "title": "Split into DVD sized chunks"
        },
        {
            "location": "/split/#split-a-big-file-and-compress-it-with-gzip-before-writing-to-disk",
            "text": "This is useful for splitting up large uncompressed logs. This command is background safe.  split -a4 --additional-suffix='-redis.log.1' -l500000 --filter='gzip -9 > $FILE.gz' redis.log.1  And if you want to see read stats, throw  pv  in the mix:  $ split -a4 --additional-suffix='-redis.log.1' -l500000 --filter='pv | gzip -9 > $FILE.gz' redis.log.1\n1.94GB 0:00:58 [21.2MB/s] [                                         <=>                              ]",
            "title": "Split a big file and compress it with gzip before writing to disk"
        },
        {
            "location": "/splunk/",
            "text": "Enterprise log consumption and analysis.\n\n\n\n\nhttp://www.splunk.com/\n\n\nhttp://docs.splunk.com/Documentation/Splunk/latest/SearchReference/Sort\n\n\n\n\nExamples\n\n\nGet a list of indexes\n\n\n| REST /services/data/indexes | dedup title | table title\n\n\n\n\nGet a list of sourcetypes\n\n\n| metadata type=sourcetypes index=* OR index=_*\n\n\n\n\nCFEngine runs per hour by version\n\n\nsource=\"/var/log/messages\" OR source=\"udp:514\" \"Starting CFEngine\" earliest=\"-1w\" | rex \"Starting CFEngine (?<version>3.[0-9]+.[0-9]+).*\" | timechart span=4h usenull=0 dc(host) by version\n\n\n\n\nStrip domain from hostname for consistent UQDNs\n\n\nrex mode=sed field=host \"s/\\.foo\\.example\\.com//\"\n\n\n\n\nCount of records per hour by host\n\n\nearliest=\"-7d\" | timechart span=1h count(_raw) by host\n\n\n\n\nCount of records per source by 5m with no limit on list\n\n\nearliest=\"-8h\" | timechart span=5m count(_raw) by source limit=0\n\n\n\n\nCount of records per source with a given list\n\n\nearliest=\"-1d\" source=\"/var/log/messages\" OR source=\"udp:10514\" OR source=\"udp:514\" | timechart count by source\n\n\n\n\nCount of records per splunk server for a given time period\n\n\nStupidly, splunk doesn't support ISO date format by default (in the version I'm using).\n\n\nearliest=\"06/19/2015:3:0:0\" latest=\"06/19/2015:3:3:0\" | timechart count(_raw) by splunk_server\n\n\n\n\nOrder number of hits for a given string by an extracted IP address\n\n\nearliest=\"7/6/2015:9:30:0\" \"verifying pingback from\" | rex \"verifying pingback from (?<pingback_source_ip>[0-9\\.]*)\\\"\" | stats count(_raw) as pingback_source_ip_total by pingback_source_ip | sort pingback_source_ip_total desc\n\n\n\n\nOrder an RPM report\n\n\nGiven a report where RPM fields are exported as field=\"value\", such as:\n\n\nrpm -qa --queryformat 'report=\"rpm\", name=\"%{NAME}\", release=\"%{RELEASE}\", version=\"%{VERSION}\", packager=\"%{PACKAGER}\", url=\"%{URL}\", installtime=\"%{INSTALLTIME}\"\\n'\n\n\n\n\nThis search in splunk will show a useful table:\n\n\nearliest=\"-1d\" report=\"rpm\" | dedup name | eval install_timestamp = strftime(installtime, \"%F %T.%3N\") | sort installtime desc | table host,name,version,release,install_timestamp\n\n\n\n\nSee also:\n\n\n\n\nhttp://docs.splunk.com/Documentation/Splunk/latest/Admin/Propsconf\n\n\nhttp://answers.splunk.com/answers/140493/timestamp-contain-t-between-date-and-time.html#answer-140495\n\n\n\n\nCount of kernel versions\n\n\nAssuming you have a report that sends \nkernel_version=$(uname -r)\n:\n\n\nkernel_version | stats count(kernel_version) by kernel_version, host",
            "title": "Splunk"
        },
        {
            "location": "/splunk/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/splunk/#get-a-list-of-indexes",
            "text": "| REST /services/data/indexes | dedup title | table title",
            "title": "Get a list of indexes"
        },
        {
            "location": "/splunk/#get-a-list-of-sourcetypes",
            "text": "| metadata type=sourcetypes index=* OR index=_*",
            "title": "Get a list of sourcetypes"
        },
        {
            "location": "/splunk/#cfengine-runs-per-hour-by-version",
            "text": "source=\"/var/log/messages\" OR source=\"udp:514\" \"Starting CFEngine\" earliest=\"-1w\" | rex \"Starting CFEngine (?<version>3.[0-9]+.[0-9]+).*\" | timechart span=4h usenull=0 dc(host) by version",
            "title": "CFEngine runs per hour by version"
        },
        {
            "location": "/splunk/#strip-domain-from-hostname-for-consistent-uqdns",
            "text": "rex mode=sed field=host \"s/\\.foo\\.example\\.com//\"",
            "title": "Strip domain from hostname for consistent UQDNs"
        },
        {
            "location": "/splunk/#count-of-records-per-hour-by-host",
            "text": "earliest=\"-7d\" | timechart span=1h count(_raw) by host",
            "title": "Count of records per hour by host"
        },
        {
            "location": "/splunk/#count-of-records-per-source-by-5m-with-no-limit-on-list",
            "text": "earliest=\"-8h\" | timechart span=5m count(_raw) by source limit=0",
            "title": "Count of records per source by 5m with no limit on list"
        },
        {
            "location": "/splunk/#count-of-records-per-source-with-a-given-list",
            "text": "earliest=\"-1d\" source=\"/var/log/messages\" OR source=\"udp:10514\" OR source=\"udp:514\" | timechart count by source",
            "title": "Count of records per source with a given list"
        },
        {
            "location": "/splunk/#count-of-records-per-splunk-server-for-a-given-time-period",
            "text": "Stupidly, splunk doesn't support ISO date format by default (in the version I'm using).  earliest=\"06/19/2015:3:0:0\" latest=\"06/19/2015:3:3:0\" | timechart count(_raw) by splunk_server",
            "title": "Count of records per splunk server for a given time period"
        },
        {
            "location": "/splunk/#order-number-of-hits-for-a-given-string-by-an-extracted-ip-address",
            "text": "earliest=\"7/6/2015:9:30:0\" \"verifying pingback from\" | rex \"verifying pingback from (?<pingback_source_ip>[0-9\\.]*)\\\"\" | stats count(_raw) as pingback_source_ip_total by pingback_source_ip | sort pingback_source_ip_total desc",
            "title": "Order number of hits for a given string by an extracted IP address"
        },
        {
            "location": "/splunk/#order-an-rpm-report",
            "text": "Given a report where RPM fields are exported as field=\"value\", such as:  rpm -qa --queryformat 'report=\"rpm\", name=\"%{NAME}\", release=\"%{RELEASE}\", version=\"%{VERSION}\", packager=\"%{PACKAGER}\", url=\"%{URL}\", installtime=\"%{INSTALLTIME}\"\\n'  This search in splunk will show a useful table:  earliest=\"-1d\" report=\"rpm\" | dedup name | eval install_timestamp = strftime(installtime, \"%F %T.%3N\") | sort installtime desc | table host,name,version,release,install_timestamp  See also:   http://docs.splunk.com/Documentation/Splunk/latest/Admin/Propsconf  http://answers.splunk.com/answers/140493/timestamp-contain-t-between-date-and-time.html#answer-140495",
            "title": "Order an RPM report"
        },
        {
            "location": "/splunk/#count-of-kernel-versions",
            "text": "Assuming you have a report that sends  kernel_version=$(uname -r) :  kernel_version | stats count(kernel_version) by kernel_version, host",
            "title": "Count of kernel versions"
        },
        {
            "location": "/sqlite/",
            "text": "CLI Shell info: \nhttp://www.sqlite.org/sqlite.html\n\n\nBetter CLI tutorial: \nhttp://souptonuts.sourceforge.net/readme_sqlite_tutorial.html\n\n\nFAQ - \nhttp://www.sqlite.org/faq.html\n\n\nWhen to use SQLite - https://www.sqlite.org/whentouse.html\n\n\n\n\nSyntax Examples\n\n\nExit the CLI\n\n\n.exit\n\n\n\n\nCreate a table\n\n\nCREATE TABLE servers (id INTEGER NOT NULL, hostname VARCHAR(255), ip_addr VARCHAR(32), PRIMARY KEY (id), UNIQUE (id,hostname));\n\n\n\n\nOr from a unix shell\n\n\nsqlite3 foo.db \"CREATE TABLE servers (id INTEGER NOT NULL, hostname VARCHAR(255), ip_addr VARCHAR(32), PRIMARY KEY (id), UNIQUE (id,hostname));\"\n\n\n\n\nAdd a column to the table\n\n\nALTER TABLE servers ADD os varchar(255);\n\n\n\n\nAdd rows to the table from unix shell\n\n\nsqlite3 foo.db \"insert into baz values ('50','some text');\"\n\n\n\n\nAdd rows or update if the row already exists\n\n\nThis syntax is different from other SQL implementations\n\n\ninsert or replace into tablename(filename, hash) values\n  ('/etc/hosts', 'somehash'),\n  ('/etc/resolv.conf', 'someotherhash');\n\n\n\n\nOutput rows via the unix shell\n\n\nThis outputs as columns, but csv, html line, and list exist too.\n\n\nsqlite3 -column foo.db \"select * from baz limit 5;\"\n\n\n\n\nIf -column is truncating your output, instead use \n-list -separator ' '\n\n\nDump the db from CLI\n\n\nsqlite3 foo.db \".dump\" > db.sql\n\n\n\n\nSearch Skype chat history\n\n\nsqlite3 ~/Library/Application\\ Support/Skype/daniel.austin/main.db  \"select author, timestamp, body_xml from messages where body_xml like '%veewee%' ;\"\n\n\n\n\nExpanded functionality skype history search\n\n\nfunction skypesearch(){\n  skypeusername=$1\n  searchstring=$2\n  /usr/bin/env sqlite3 ~/Library/Application\\ Support/Skype/${skypeusername}/main.db  \"select author, datetime(timestamp,'unixepoch','localtime'), body_xml from messages where body_xml like '%${searchstring}%' ;\"\n}\nalias ss=\"skypesearch username\"\n\n\n\n\nQuickly create an image database\n\n\n# Create the database\nsqlite3 images.db \"create table images (filename varchar(255), createdate timestamp, unique(filename))\"\n# Populate the database. This can be blindly re-run when new files are added.\nexiftool -d \"%s\" -p 'insert into images values (\"$filename\", \"$DateTimeOriginal\");' -q -f -r . | sqlite3 images.db 2> /dev/null\n# Query the database\nsqlite3 images.db \"select filename,datetime(createdate,'unixepoch','localtime') as date from images where date like '2014-08-02%';\"\n\n\n\n\nUse sqlite3 in PHP\n\n\n<?php\n$db = new SQLite3(\"images.db\");\nif (!is_object($db)) { echo \"Couldn't connect to DB.\" ; exit ; }\n$query = \"select filename,datetime(createdate,'unixepoch','localtime') as date from images where date like '2014-08-02%';\" ;\n$result = $db->query($query);\nwhile($row = $result->fetchArray(SQLITE3_ASSOC)){\n       $i++ ;\n       if(!isset($row['filename'])) continue;\n       echo \"$row[filename] : $row[date]&lt;br>\\n\";\n}\n?>",
            "title": "Sqlite"
        },
        {
            "location": "/sqlite/#syntax-examples",
            "text": "",
            "title": "Syntax Examples"
        },
        {
            "location": "/sqlite/#exit-the-cli",
            "text": ".exit",
            "title": "Exit the CLI"
        },
        {
            "location": "/sqlite/#create-a-table",
            "text": "CREATE TABLE servers (id INTEGER NOT NULL, hostname VARCHAR(255), ip_addr VARCHAR(32), PRIMARY KEY (id), UNIQUE (id,hostname));  Or from a unix shell  sqlite3 foo.db \"CREATE TABLE servers (id INTEGER NOT NULL, hostname VARCHAR(255), ip_addr VARCHAR(32), PRIMARY KEY (id), UNIQUE (id,hostname));\"",
            "title": "Create a table"
        },
        {
            "location": "/sqlite/#add-a-column-to-the-table",
            "text": "ALTER TABLE servers ADD os varchar(255);",
            "title": "Add a column to the table"
        },
        {
            "location": "/sqlite/#add-rows-to-the-table-from-unix-shell",
            "text": "sqlite3 foo.db \"insert into baz values ('50','some text');\"",
            "title": "Add rows to the table from unix shell"
        },
        {
            "location": "/sqlite/#add-rows-or-update-if-the-row-already-exists",
            "text": "This syntax is different from other SQL implementations  insert or replace into tablename(filename, hash) values\n  ('/etc/hosts', 'somehash'),\n  ('/etc/resolv.conf', 'someotherhash');",
            "title": "Add rows or update if the row already exists"
        },
        {
            "location": "/sqlite/#output-rows-via-the-unix-shell",
            "text": "This outputs as columns, but csv, html line, and list exist too.  sqlite3 -column foo.db \"select * from baz limit 5;\"  If -column is truncating your output, instead use  -list -separator ' '",
            "title": "Output rows via the unix shell"
        },
        {
            "location": "/sqlite/#dump-the-db-from-cli",
            "text": "sqlite3 foo.db \".dump\" > db.sql",
            "title": "Dump the db from CLI"
        },
        {
            "location": "/sqlite/#search-skype-chat-history",
            "text": "sqlite3 ~/Library/Application\\ Support/Skype/daniel.austin/main.db  \"select author, timestamp, body_xml from messages where body_xml like '%veewee%' ;\"",
            "title": "Search Skype chat history"
        },
        {
            "location": "/sqlite/#expanded-functionality-skype-history-search",
            "text": "function skypesearch(){\n  skypeusername=$1\n  searchstring=$2\n  /usr/bin/env sqlite3 ~/Library/Application\\ Support/Skype/${skypeusername}/main.db  \"select author, datetime(timestamp,'unixepoch','localtime'), body_xml from messages where body_xml like '%${searchstring}%' ;\"\n}\nalias ss=\"skypesearch username\"",
            "title": "Expanded functionality skype history search"
        },
        {
            "location": "/sqlite/#quickly-create-an-image-database",
            "text": "# Create the database\nsqlite3 images.db \"create table images (filename varchar(255), createdate timestamp, unique(filename))\"\n# Populate the database. This can be blindly re-run when new files are added.\nexiftool -d \"%s\" -p 'insert into images values (\"$filename\", \"$DateTimeOriginal\");' -q -f -r . | sqlite3 images.db 2> /dev/null\n# Query the database\nsqlite3 images.db \"select filename,datetime(createdate,'unixepoch','localtime') as date from images where date like '2014-08-02%';\"",
            "title": "Quickly create an image database"
        },
        {
            "location": "/sqlite/#use-sqlite3-in-php",
            "text": "<?php\n$db = new SQLite3(\"images.db\");\nif (!is_object($db)) { echo \"Couldn't connect to DB.\" ; exit ; }\n$query = \"select filename,datetime(createdate,'unixepoch','localtime') as date from images where date like '2014-08-02%';\" ;\n$result = $db->query($query);\nwhile($row = $result->fetchArray(SQLITE3_ASSOC)){\n       $i++ ;\n       if(!isset($row['filename'])) continue;\n       echo \"$row[filename] : $row[date]&lt;br>\\n\";\n}\n?>",
            "title": "Use sqlite3 in PHP"
        },
        {
            "location": "/ss/",
            "text": "\"ss - another utility to investigate sockets\" \u2013 man ss\n\n\nThis tool shows all sockets, not just networking sockets.\n\n\nExamples\n\n\nOptions can be concatenated, so \nss -t -n -l -p\n can be \nss -tnlp\n\n\nShow all established connections, don't resolve service names\n\n\nss -n\n\n\n\n\nShow all listening sockets\n\n\nss -l\n\n\n\n\nDisplay all TCP sockets\n\n\nss -t -a\n\n\n\n\nShow ipv4 listening sockets sorted by port\n\n\nss -4 -ltn | sort -k2 -t: -n\n\n\n\n\nShow ssh connections\n\n\nss -at '( sport = :ssh or dport = :ssh )'\n\n\n\n\nShow ipv4 sockets in a particular state\n\n\nss -t4 state time-wait\n\n\n\n\nShow the processes for listening ipv4 sockets\n\n\nss -lt4p",
            "title": "Ss"
        },
        {
            "location": "/ss/#examples",
            "text": "Options can be concatenated, so  ss -t -n -l -p  can be  ss -tnlp",
            "title": "Examples"
        },
        {
            "location": "/ss/#show-all-established-connections-dont-resolve-service-names",
            "text": "ss -n",
            "title": "Show all established connections, don't resolve service names"
        },
        {
            "location": "/ss/#show-all-listening-sockets",
            "text": "ss -l",
            "title": "Show all listening sockets"
        },
        {
            "location": "/ss/#display-all-tcp-sockets",
            "text": "ss -t -a",
            "title": "Display all TCP sockets"
        },
        {
            "location": "/ss/#show-ipv4-listening-sockets-sorted-by-port",
            "text": "ss -4 -ltn | sort -k2 -t: -n",
            "title": "Show ipv4 listening sockets sorted by port"
        },
        {
            "location": "/ss/#show-ssh-connections",
            "text": "ss -at '( sport = :ssh or dport = :ssh )'",
            "title": "Show ssh connections"
        },
        {
            "location": "/ss/#show-ipv4-sockets-in-a-particular-state",
            "text": "ss -t4 state time-wait",
            "title": "Show ipv4 sockets in a particular state"
        },
        {
            "location": "/ss/#show-the-processes-for-listening-ipv4-sockets",
            "text": "ss -lt4p",
            "title": "Show the processes for listening ipv4 sockets"
        },
        {
            "location": "/ssh/",
            "text": "ssh is the secure shell, an encrypted version of telnet and a whole lot more\n\n\nssh\n\n\nThe secure shell itself, very useful for administering remote systems, tunneling arbitrary ports, tunneling X sessions, and a whole lot more.\n\n\nscp\n\n\nscp is like cp, but it happens securely and allows host-to-host transfers over ssh. Very handy when used with \nssh_config\n and \nkey-based authentication\n.\n\n\nsftp\n\n\nA secure FTP client built into ssh. The native client sucks, try lftp or rsync if it's available.\n\n\nsshd\n\n\nOutput effective server configuration variables\n\n\nThis is useful for troubleshooting ssh_config matching.\n\n\nsshd -T # requires root\n\n\nssh\n\n\nOutput effective client configuration variables\n\n\nssh -G user@host\n\n\ntunnel local port to the destination through the SSH connection\n\n\nThis will only listen on localhost, not ethernet interfaces. Use -g to listen on all interfaces\n\n\nssh -L LocalPort:Destination:DestinationPort\n\n\n\n\nTunnel from remote port through the local machine to destination\n\n\nssh -R RemotePort:Destination:DestinationPort\n\n\n\n\nCreate a socks 5 proxy on a local port\n\n\nssh -D [PORT] user@host\n\n\n\n\nLoop through some ssh hosts and execute a command\n\n\n-n is required in order to proceed past the first host.\n\n\ncat hostnames.txt | while read -r host ; do\n  ssh -o ConnectTimeout=10 -o PasswordAuthentication=no -n \"$host\" 'some_command ; another_command'\ndone\n\n\n\n\nssh_config\n\n\nThe user ssh config file, \n~/.ssh/config\n, lets you override default options. This makes it handy for command line stuff where the syntax is funky such as using non-standard ports.\n\n\nNotably, global vriables need to come at the \nend\n of the file, not the beginning!\n\n\nSimple host aliasing\n\n\nThe following example will let you simply \nssh sugarbeast\n to log in on the non-standard port on the proper IP# with the specified user.\n\n\nHost sugarbeast\n  HostName 66.134.66.42\n  User daniel\n  Port 888\n\n\n\n\nMultiplexed connections\n\n\nAfter running \nmkdir -p -m 700 ~/.ssh/sockets\n add this to your ~/.ssh/config\n\n\nHost *\n  ControlPersist yes\n  ControlMaster auto\n  ControlPath ~/.ssh/sockets/%r@%h:%p\n\n\n\n\nTo kill a multiplexed connection, run \nssh -O exit user@host\n\n\nProxyCommand\n\n\nThis command lets you execute an arbitrary series of commands to connect with.\n\n\nSSH proxy through ssh host for openSSH v4 and earlier (Ubuntu 8):\n\n\nProxyCommand ssh -q bastion nc -q 0 %h %p\n\n\n\n\nSSH proxy through ssh host for openSSH v5 and later:\n\n\nProxyCommand ssh -W %h:%p bastion\n\n\n\n\nHTTP proxy (from \nman ssh_config\n):\n\n\nProxyCommand nc -X connect -x 192.0.2.0:8080 %h %p\n\n\n\n\nkey-based authentication\n\n\nKey-based authentication lets you log in without specifying a password. This is useful for \nrsync\n, \nscp\n and just plain old \nssh\n shell. Adding comments to the public key makes it easy to sort through the keys that authorized_keys file. The \n$HOME/.ssh/authorized_keys\n file is the default list of public keys which are allowed password-less login. See also \nman authorized_keys\n for more info.\n\n\nKey-based auth Permissions\n\n\nPermissions on this file need to be set like this:\n\n\n#!/bin/sh\n# This will repair permissions for the current user's ssh key-pair authentication.\nmkdir ~/.ssh/\ntouch ~/.ssh/authorized_keys\nchmod go-w ~          && \\\nchmod 700 ~/.ssh      && \\\nchmod 600 ~/.ssh/*    && \\\necho \"Successfully fixed ssh authentication files permissions.\"\n\n\n\n\nssh-keygen\n\n\nValidate each entry of authorized_keys\n\n\nssh-keygen -lvf ~/.ssh/authorized_keys\n\n\n\n\nGenerate Keys\n\n\nNot all systems support ed25519, but it is currently the most secure key type.\n\n\nssh-keygen -t ssh-ed25519 -c \"Daniel Hoherd <danielhoherd@xyzhost>\n\n\n\n\nIf you require backwards compatibility, use 4096 bit RSA keys.\n\n\nssh-keygen -b 4096 -t rsa -c \"Daniel Hoherd <danielhoherd@xyzhost>\"\n\n\n\n\nCreate or change a password for an ssh identity\n\n\nThis will update the password used to unlock an ssh identity.\n\n\nssh-keygen -p -f ~/.ssh/id_ed25519\n\n\n\n\nLimit root login to key based auth\n\n\nIn /etc/ssh/sshd_config: PermitRootLogin without-password\n\n\n\n\nSee Also\n\n\n\n\nsshuttle\n - IP network router over ssh\n\n\nsslh\n - lets one accept both HTTPS and SSH connections on the same port. It makes it possible to connect to an SSH server on port 443 (e.g. from inside a corporate firewall)\n\n\nCorkscrew\n - a tool for tunneling SSH through HTTP proxies\n\n\nPutty\n - An SSH (and telnet) client for windows.\n\n\nPasswordless SSH logins\n\n\nSSH server for Windows\n\n\nSSH jump hosts\n\n\nThe Secure Shell (SSH) Connection Protocol - \nhttps://www.ietf.org/rfc/rfc4254.txt\n\n\nThe Secure Shell (SSH) Authentication Protocol - \nhttps://www.ietf.org/rfc/rfc4252.txt\n\n\nThe Secure Shell (SSH) Transport Layer Protocol - https://www.ietf.org/rfc/rfc4253.txt",
            "title": "Ssh"
        },
        {
            "location": "/ssh/#ssh",
            "text": "The secure shell itself, very useful for administering remote systems, tunneling arbitrary ports, tunneling X sessions, and a whole lot more.",
            "title": "ssh"
        },
        {
            "location": "/ssh/#scp",
            "text": "scp is like cp, but it happens securely and allows host-to-host transfers over ssh. Very handy when used with  ssh_config  and  key-based authentication .",
            "title": "scp"
        },
        {
            "location": "/ssh/#sftp",
            "text": "A secure FTP client built into ssh. The native client sucks, try lftp or rsync if it's available.",
            "title": "sftp"
        },
        {
            "location": "/ssh/#sshd",
            "text": "",
            "title": "sshd"
        },
        {
            "location": "/ssh/#output-effective-server-configuration-variables",
            "text": "This is useful for troubleshooting ssh_config matching.  sshd -T # requires root",
            "title": "Output effective server configuration variables"
        },
        {
            "location": "/ssh/#ssh_1",
            "text": "",
            "title": "ssh"
        },
        {
            "location": "/ssh/#output-effective-client-configuration-variables",
            "text": "ssh -G user@host",
            "title": "Output effective client configuration variables"
        },
        {
            "location": "/ssh/#tunnel-local-port-to-the-destination-through-the-ssh-connection",
            "text": "This will only listen on localhost, not ethernet interfaces. Use -g to listen on all interfaces  ssh -L LocalPort:Destination:DestinationPort",
            "title": "tunnel local port to the destination through the SSH connection"
        },
        {
            "location": "/ssh/#tunnel-from-remote-port-through-the-local-machine-to-destination",
            "text": "ssh -R RemotePort:Destination:DestinationPort",
            "title": "Tunnel from remote port through the local machine to destination"
        },
        {
            "location": "/ssh/#create-a-socks-5-proxy-on-a-local-port",
            "text": "ssh -D [PORT] user@host",
            "title": "Create a socks 5 proxy on a local port"
        },
        {
            "location": "/ssh/#loop-through-some-ssh-hosts-and-execute-a-command",
            "text": "-n is required in order to proceed past the first host.  cat hostnames.txt | while read -r host ; do\n  ssh -o ConnectTimeout=10 -o PasswordAuthentication=no -n \"$host\" 'some_command ; another_command'\ndone",
            "title": "Loop through some ssh hosts and execute a command"
        },
        {
            "location": "/ssh/#ssh_config",
            "text": "The user ssh config file,  ~/.ssh/config , lets you override default options. This makes it handy for command line stuff where the syntax is funky such as using non-standard ports.  Notably, global vriables need to come at the  end  of the file, not the beginning!",
            "title": "ssh_config"
        },
        {
            "location": "/ssh/#simple-host-aliasing",
            "text": "The following example will let you simply  ssh sugarbeast  to log in on the non-standard port on the proper IP# with the specified user.  Host sugarbeast\n  HostName 66.134.66.42\n  User daniel\n  Port 888",
            "title": "Simple host aliasing"
        },
        {
            "location": "/ssh/#multiplexed-connections",
            "text": "After running  mkdir -p -m 700 ~/.ssh/sockets  add this to your ~/.ssh/config  Host *\n  ControlPersist yes\n  ControlMaster auto\n  ControlPath ~/.ssh/sockets/%r@%h:%p  To kill a multiplexed connection, run  ssh -O exit user@host",
            "title": "Multiplexed connections"
        },
        {
            "location": "/ssh/#proxycommand",
            "text": "This command lets you execute an arbitrary series of commands to connect with.  SSH proxy through ssh host for openSSH v4 and earlier (Ubuntu 8):  ProxyCommand ssh -q bastion nc -q 0 %h %p  SSH proxy through ssh host for openSSH v5 and later:  ProxyCommand ssh -W %h:%p bastion  HTTP proxy (from  man ssh_config ):  ProxyCommand nc -X connect -x 192.0.2.0:8080 %h %p",
            "title": "ProxyCommand"
        },
        {
            "location": "/ssh/#key-based-authentication",
            "text": "Key-based authentication lets you log in without specifying a password. This is useful for  rsync ,  scp  and just plain old  ssh  shell. Adding comments to the public key makes it easy to sort through the keys that authorized_keys file. The  $HOME/.ssh/authorized_keys  file is the default list of public keys which are allowed password-less login. See also  man authorized_keys  for more info.",
            "title": "key-based authentication"
        },
        {
            "location": "/ssh/#key-based-auth-permissions",
            "text": "Permissions on this file need to be set like this:  #!/bin/sh\n# This will repair permissions for the current user's ssh key-pair authentication.\nmkdir ~/.ssh/\ntouch ~/.ssh/authorized_keys\nchmod go-w ~          && \\\nchmod 700 ~/.ssh      && \\\nchmod 600 ~/.ssh/*    && \\\necho \"Successfully fixed ssh authentication files permissions.\"",
            "title": "Key-based auth Permissions"
        },
        {
            "location": "/ssh/#ssh-keygen",
            "text": "",
            "title": "ssh-keygen"
        },
        {
            "location": "/ssh/#validate-each-entry-of-authorized_keys",
            "text": "ssh-keygen -lvf ~/.ssh/authorized_keys",
            "title": "Validate each entry of authorized_keys"
        },
        {
            "location": "/ssh/#generate-keys",
            "text": "Not all systems support ed25519, but it is currently the most secure key type.  ssh-keygen -t ssh-ed25519 -c \"Daniel Hoherd <danielhoherd@xyzhost>  If you require backwards compatibility, use 4096 bit RSA keys.  ssh-keygen -b 4096 -t rsa -c \"Daniel Hoherd <danielhoherd@xyzhost>\"",
            "title": "Generate Keys"
        },
        {
            "location": "/ssh/#create-or-change-a-password-for-an-ssh-identity",
            "text": "This will update the password used to unlock an ssh identity.  ssh-keygen -p -f ~/.ssh/id_ed25519",
            "title": "Create or change a password for an ssh identity"
        },
        {
            "location": "/ssh/#limit-root-login-to-key-based-auth",
            "text": "In /etc/ssh/sshd_config: PermitRootLogin without-password",
            "title": "Limit root login to key based auth"
        },
        {
            "location": "/ssh/#see-also",
            "text": "sshuttle  - IP network router over ssh  sslh  - lets one accept both HTTPS and SSH connections on the same port. It makes it possible to connect to an SSH server on port 443 (e.g. from inside a corporate firewall)  Corkscrew  - a tool for tunneling SSH through HTTP proxies  Putty  - An SSH (and telnet) client for windows.  Passwordless SSH logins  SSH server for Windows  SSH jump hosts  The Secure Shell (SSH) Connection Protocol -  https://www.ietf.org/rfc/rfc4254.txt  The Secure Shell (SSH) Authentication Protocol -  https://www.ietf.org/rfc/rfc4252.txt  The Secure Shell (SSH) Transport Layer Protocol - https://www.ietf.org/rfc/rfc4253.txt",
            "title": "See Also"
        },
        {
            "location": "/sshuttle/",
            "text": "sshuttle is an SSH powered ipv4 routed VPN that doesn't require admin rights on the target host.\n- \nhttps://github.com/apenwarr/sshuttle\n\n\nUsage\n\n\nTunnel DNS queries and create a route through the given host to the given subnet, and be verbose about it.\n\n\nsshuttle --dns -vr user@host:port 192.168.1.0/24",
            "title": "Sshuttle"
        },
        {
            "location": "/sshuttle/#usage",
            "text": "Tunnel DNS queries and create a route through the given host to the given subnet, and be verbose about it.  sshuttle --dns -vr user@host:port 192.168.1.0/24",
            "title": "Usage"
        },
        {
            "location": "/stat/",
            "text": "show filesystem metadata about a file\n\n\nGNU stat examples\n\n\nShow permissions, modify date, ownership and long filename\n\n\nstat -c \"%a/%A  %y %G(%g):%U(%u) %N\" /srv/log/apache2/\n\n\n\n\nSum file sizes\n\n\nstat -c '%s' *2016* | awk '{sum += $1} END {print sum}'\n\n\n\n\nGNU stat -c variables\n\n\nThe valid format sequences for files (without --filesystem):\n\n\n\n\n%a - Access rights in octal\n\n\n%A - Access rights in human readable form\n\n\n%b - Number of blocks allocated (see %B)\n\n\n%B - The size in bytes of each block reported by %b\n\n\n%C - SELinux security context string\n\n\n%d - Device number in decimal\n\n\n%D - Device number in hex\n\n\n%f - Raw mode in hex\n\n\n%F - File type\n\n\n%g - Group ID of owner\n\n\n%G - Group name of owner\n\n\n%h - Number of hard links\n\n\n%i - Inode number\n\n\n%n - File name\n\n\n%N - Quoted file name with dereference if symbolic link\n\n\n%o - I/O block size\n\n\n%s - Total size, in bytes\n\n\n%t - Major device type in hex\n\n\n%T - Minor device type in hex\n\n\n%u - User ID of owner\n\n\n%U - User name of owner\n\n\n%x - Time of last access\n\n\n%X - Time of last access as seconds since Epoch\n\n\n%y - Time of last modification\n\n\n%Y - Time of last modification as seconds since Epoch\n\n\n%z - Time of last change\n\n\n%Z - Time of last change as seconds since Epoch Valid format sequences for file systems:\n\n\n%a - Free blocks available to non-superuser\n\n\n%b - Total data blocks in file system\n\n\n%c - Total file nodes in file system\n\n\n%d - Free file nodes in file system\n\n\n%f - Free blocks in file system\n\n\n%C - SELinux security context string\n\n\n%i - File System ID in hex\n\n\n%l - Maximum length of filenames\n\n\n%n - File name\n\n\n%s - Block size (for faster transfers)\n\n\n%S - Fundamental block size (for block counts)\n\n\n%t - Type in hex\n\n\n%T - Type in human readable form",
            "title": "Stat"
        },
        {
            "location": "/stat/#gnu-stat-examples",
            "text": "",
            "title": "GNU stat examples"
        },
        {
            "location": "/stat/#show-permissions-modify-date-ownership-and-long-filename",
            "text": "stat -c \"%a/%A  %y %G(%g):%U(%u) %N\" /srv/log/apache2/",
            "title": "Show permissions, modify date, ownership and long filename"
        },
        {
            "location": "/stat/#sum-file-sizes",
            "text": "stat -c '%s' *2016* | awk '{sum += $1} END {print sum}'",
            "title": "Sum file sizes"
        },
        {
            "location": "/stat/#gnu-stat-c-variables",
            "text": "The valid format sequences for files (without --filesystem):   %a - Access rights in octal  %A - Access rights in human readable form  %b - Number of blocks allocated (see %B)  %B - The size in bytes of each block reported by %b  %C - SELinux security context string  %d - Device number in decimal  %D - Device number in hex  %f - Raw mode in hex  %F - File type  %g - Group ID of owner  %G - Group name of owner  %h - Number of hard links  %i - Inode number  %n - File name  %N - Quoted file name with dereference if symbolic link  %o - I/O block size  %s - Total size, in bytes  %t - Major device type in hex  %T - Minor device type in hex  %u - User ID of owner  %U - User name of owner  %x - Time of last access  %X - Time of last access as seconds since Epoch  %y - Time of last modification  %Y - Time of last modification as seconds since Epoch  %z - Time of last change  %Z - Time of last change as seconds since Epoch Valid format sequences for file systems:  %a - Free blocks available to non-superuser  %b - Total data blocks in file system  %c - Total file nodes in file system  %d - Free file nodes in file system  %f - Free blocks in file system  %C - SELinux security context string  %i - File System ID in hex  %l - Maximum length of filenames  %n - File name  %s - Block size (for faster transfers)  %S - Fundamental block size (for block counts)  %t - Type in hex  %T - Type in human readable form",
            "title": "GNU stat -c variables"
        },
        {
            "location": "/sudo/",
            "text": "super user do\n\n\nExamples\n\n\n#includedir /etc/sudoers.d\n\n\n#includedir /etc/sudoers.d\n\n\n\n\nThis line is in some sudoers files, and is not a comment. #includedir is a configuration directive. This directory does not like to have .conf files, so they should be flatly named. eg: 00_default\n\n\nCheck sudoers for errors\n\n\nvisudo -c\n\n\n\n\nShow sudo rules that match for the given user\n\n\nsudo -l -U username\n\n\n\n\nThe order shown is important. sudo picks the last matching rule. Rules are parsed in order from /etc/sudoers and all included files. Because of this, \n#includedir /etc/sudoers.d\n should be the last line in the /etc/sudoers file, and the order of the /etc/sudoers.d/ files will be important when fine tuning rules.\n\n\nAllow admins to run mtr without a password\n\n\nAdd the following line to /etc/sudoers\n\n\n%admin ALL=(ALL)NOPASSWD:/usr/local/sbin/mtr\n\n\n\n\nAllow several groups and users to execute upstart commands\n\n\nUser_Alias UPSTART_USERS = %wheel, %sysadmin, %adm\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/start\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/stop\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/initctl\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/restart\n\n\n\n\nRun several commands with one sudo command\n\n\nsudo -s -- <<EOF\nwhoami\nwhoami\nEOF\n\n\n\n\nor\n\n\nsudo bash -c \"whoami ; whoami ;\"\n\n\n\n\nLinks\n\n\n\n\nsudoers config - \nhttp://ubuntuforums.org/showthread.php?t=1132821",
            "title": "Sudo"
        },
        {
            "location": "/sudo/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/sudo/#includedir-etcsudoersd",
            "text": "#includedir /etc/sudoers.d  This line is in some sudoers files, and is not a comment. #includedir is a configuration directive. This directory does not like to have .conf files, so they should be flatly named. eg: 00_default",
            "title": "#includedir /etc/sudoers.d"
        },
        {
            "location": "/sudo/#check-sudoers-for-errors",
            "text": "visudo -c",
            "title": "Check sudoers for errors"
        },
        {
            "location": "/sudo/#show-sudo-rules-that-match-for-the-given-user",
            "text": "sudo -l -U username  The order shown is important. sudo picks the last matching rule. Rules are parsed in order from /etc/sudoers and all included files. Because of this,  #includedir /etc/sudoers.d  should be the last line in the /etc/sudoers file, and the order of the /etc/sudoers.d/ files will be important when fine tuning rules.",
            "title": "Show sudo rules that match for the given user"
        },
        {
            "location": "/sudo/#allow-admins-to-run-mtr-without-a-password",
            "text": "Add the following line to /etc/sudoers  %admin ALL=(ALL)NOPASSWD:/usr/local/sbin/mtr",
            "title": "Allow admins to run mtr without a password"
        },
        {
            "location": "/sudo/#allow-several-groups-and-users-to-execute-upstart-commands",
            "text": "User_Alias UPSTART_USERS = %wheel, %sysadmin, %adm\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/start\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/stop\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/initctl\nUPSTART_USERS  ALL=(ALL)     NOPASSWD: /sbin/restart",
            "title": "Allow several groups and users to execute upstart commands"
        },
        {
            "location": "/sudo/#run-several-commands-with-one-sudo-command",
            "text": "sudo -s -- <<EOF\nwhoami\nwhoami\nEOF  or  sudo bash -c \"whoami ; whoami ;\"",
            "title": "Run several commands with one sudo command"
        },
        {
            "location": "/sudo/#links",
            "text": "sudoers config -  http://ubuntuforums.org/showthread.php?t=1132821",
            "title": "Links"
        },
        {
            "location": "/swagger/",
            "text": "\"Swagger is the world\u2019s largest framework of API developer tools for the OpenAPI Specification(OAS), enabling development across the entire API lifecycle, from design and documentation, to test and deployment.\" - \nhttps://swagger.io/\n\n\nLinks\n\n\n\n\nHello World with Swagger - \nhttps://swagger.io/blog/getting-started-with-swagger-i-what-is-swagger/\n\n\nSwagger 101 - \nhttps://app.swaggerhub.com/help/tutorials/writing-swagger-definitions\n\n\nOnline editor with example app definition \nhttps://editor.swagger.io/\n\n\nhttps://swagger.io/tools/",
            "title": "Swagger"
        },
        {
            "location": "/swagger/#links",
            "text": "Hello World with Swagger -  https://swagger.io/blog/getting-started-with-swagger-i-what-is-swagger/  Swagger 101 -  https://app.swaggerhub.com/help/tutorials/writing-swagger-definitions  Online editor with example app definition  https://editor.swagger.io/  https://swagger.io/tools/",
            "title": "Links"
        },
        {
            "location": "/sysctl/",
            "text": "\"sysctl - configure kernel parameters at runtime\" - man sysctl\n\n\n/etc/sysctl.conf\n is for storing permanent changes, \nsysctl\n is used for making changes to the running system.\n\n\nsysctl command examples\n\n\nShow all kernel variables for the in-memory kernel\n\n\nsysctl -a\n\n\n\n\nAssign a new variable for the running kernel to use\n\n\nsysctl -w variable=value\n\n\n\n\nLoad values from /etc/sysctl.conf\n\n\nsysctl -p\n\n\n\n\nsysctl.conf examples\n\n\nReboot after 10 seconds if kernel panics\n\n\nkernel.panic = 10\n\n\n\n\nTreat all oopses as panics\n\n\nkernel.panic_on_oops = 1",
            "title": "Sysctl"
        },
        {
            "location": "/sysctl/#sysctl-command-examples",
            "text": "",
            "title": "sysctl command examples"
        },
        {
            "location": "/sysctl/#show-all-kernel-variables-for-the-in-memory-kernel",
            "text": "sysctl -a",
            "title": "Show all kernel variables for the in-memory kernel"
        },
        {
            "location": "/sysctl/#assign-a-new-variable-for-the-running-kernel-to-use",
            "text": "sysctl -w variable=value",
            "title": "Assign a new variable for the running kernel to use"
        },
        {
            "location": "/sysctl/#load-values-from-etcsysctlconf",
            "text": "sysctl -p",
            "title": "Load values from /etc/sysctl.conf"
        },
        {
            "location": "/sysctl/#sysctlconf-examples",
            "text": "",
            "title": "sysctl.conf examples"
        },
        {
            "location": "/sysctl/#reboot-after-10-seconds-if-kernel-panics",
            "text": "kernel.panic = 10",
            "title": "Reboot after 10 seconds if kernel panics"
        },
        {
            "location": "/sysctl/#treat-all-oopses-as-panics",
            "text": "kernel.panic_on_oops = 1",
            "title": "Treat all oopses as panics"
        },
        {
            "location": "/sysdig/",
            "text": "An awesome host inspection tool, with tcpdump like tool and an interface similar to [[top]] et al. - \nhttp://www.sysdig.org/\n\n\nInstallation - CentOS\n\n\n\n\nhttps://github.com/draios/sysdig/wiki/How-to-Install-Sysdig-for-Linux\n\n\n\n\nTheir shell script installs epel from a 3rd party source, so it's best to use this method instead:\n\n\nrpm --import https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public && \\\ncurl -s -o /etc/yum.repos.d/draios.repo http://download.draios.com/stable/rpm/draios.repo && \\\nyum -y install kernel-devel-$(uname -r) && \\\nyum -y install sysdig\n\n\n\n\nExamples\n\n\nSimple usage\n\n\nsysdig\n\n\n\n\nWrite a system trace file\n\n\nsysdig -w tracefile.scap\n\n\n\n\nReplay a tracefile\n\n\nsysdig -r tracefile.scap\n\n\n\n\nShow filters\n\n\nsysdig -l\n\n\n\n\nShow activity for access to a given file\n\n\nsysdig -l fd.name=/etc/hosts\n\n\n\n\nShow shell commands for all users\n\n\nsysdig -pc -c spy_users\n\n\n\n\nSpy on a user and exclude a process\n\n\nsysdig -pc -c spy_users proc.name!=gmetric\n\n\n\n\nOr exclude multiple processes\n\n\nsysdig -pc -c spy_users \"not proc.name in ( gmetric, awk, sed, grep )\"\n\n\n\n\nShow a top like interface\n\n\ncsysdig\n\n\n\n\nLinks\n\n\n\n\nhttps://github.com/draios/sysdig/wiki\n\n\nhttps://github.com/draios/sysdig/wiki/Sysdig%20Examples\n\n\nhttp://man7.org/linux/man-pages/man8/sysdig.8.html\n\n\nGetting Started With Sysdig\n\n\nGetting Started With Csysdig",
            "title": "Sysdig"
        },
        {
            "location": "/sysdig/#installation-centos",
            "text": "https://github.com/draios/sysdig/wiki/How-to-Install-Sysdig-for-Linux   Their shell script installs epel from a 3rd party source, so it's best to use this method instead:  rpm --import https://s3.amazonaws.com/download.draios.com/DRAIOS-GPG-KEY.public && \\\ncurl -s -o /etc/yum.repos.d/draios.repo http://download.draios.com/stable/rpm/draios.repo && \\\nyum -y install kernel-devel-$(uname -r) && \\\nyum -y install sysdig",
            "title": "Installation - CentOS"
        },
        {
            "location": "/sysdig/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/sysdig/#simple-usage",
            "text": "sysdig",
            "title": "Simple usage"
        },
        {
            "location": "/sysdig/#write-a-system-trace-file",
            "text": "sysdig -w tracefile.scap",
            "title": "Write a system trace file"
        },
        {
            "location": "/sysdig/#replay-a-tracefile",
            "text": "sysdig -r tracefile.scap",
            "title": "Replay a tracefile"
        },
        {
            "location": "/sysdig/#show-filters",
            "text": "sysdig -l",
            "title": "Show filters"
        },
        {
            "location": "/sysdig/#show-activity-for-access-to-a-given-file",
            "text": "sysdig -l fd.name=/etc/hosts",
            "title": "Show activity for access to a given file"
        },
        {
            "location": "/sysdig/#show-shell-commands-for-all-users",
            "text": "sysdig -pc -c spy_users",
            "title": "Show shell commands for all users"
        },
        {
            "location": "/sysdig/#spy-on-a-user-and-exclude-a-process",
            "text": "sysdig -pc -c spy_users proc.name!=gmetric  Or exclude multiple processes  sysdig -pc -c spy_users \"not proc.name in ( gmetric, awk, sed, grep )\"",
            "title": "Spy on a user and exclude a process"
        },
        {
            "location": "/sysdig/#show-a-top-like-interface",
            "text": "csysdig",
            "title": "Show a top like interface"
        },
        {
            "location": "/sysdig/#links",
            "text": "https://github.com/draios/sysdig/wiki  https://github.com/draios/sysdig/wiki/Sysdig%20Examples  http://man7.org/linux/man-pages/man8/sysdig.8.html  Getting Started With Sysdig  Getting Started With Csysdig",
            "title": "Links"
        },
        {
            "location": "/systemd/",
            "text": "\"systemd is a system and service manager for Linux, compatible with SysV and LSB init scripts. systemd provides aggressive parallelization capabilities, uses socket and D-Bus activation for starting services, offers on-demand starting of daemons, keeps track of processes using Linux control groups, supports snapshotting and restoring of the system state, maintains mount and automount points and implements an elaborate transactional dependency-based service control logic. It can work as a drop-in replacement for sysvinit.\" - \nhttp://www.freedesktop.org/wiki/Software/systemd/\n\n\n\n\nTips and tricks - \nhttp://www.freedesktop.org/wiki/Software/systemd/TipsAndTricks/\n\n\nMan page for control groups - \nhttp://man7.org/linux/man-pages/man5/systemd.cgroup.5.html\n\n\nFAQ - \nhttp://www.freedesktop.org/wiki/Software/systemd/FrequentlyAskedQuestions/\n\n\nsysvinit to chkconfig - \nhttps://fedoraproject.org/wiki/SysVinit_to_Systemd_Cheatsheet\n\n\nsystemd for upstart users - \nhttps://wiki.ubuntu.com/SystemdForUpstartUsers\n\n\n\n\nTips\n\n\nInit file locations\n\n\n/usr/lib/systemd/system\n/etc/systemd/system # has precedence\n\n\n\n\nShow the full systemd journal\n\n\nThe systemd journal is syslog and more.\n\n\njournalctl --full\n\n\n\n\nShow the nginx journal for today\n\n\njournalctl -u nginx.service --since today\n\n\n\n\nShow units\n\n\nUnits are things that are handled by systemd, including services.     systemctl list-units\n\n\nShow dependencies\n\n\nThis works on any .target or .service\n\n\nsystemctl list-dependencies network.service\n\n\n\n\nEnable a service\n\n\nThis behavior replaces chkconfig\n\n\nsystemctl enable docker.service\n\n\n\n\nCheck the status of a service and show 20 lines\n\n\nsystemctl -n 20 status nodejs\n\n\n\n\nPer-user services\n\n\nhttps://wiki.archlinux.org/index.php/Systemd/User\n\n\n/usr/lib/systemd/user/ - where services provided by installed packages go.\n/etc/systemd/user/ - where system-wide user services are placed by the system administrator.\n~/.config/systemd/user/ - where the user puts its own services.\n\n\n\n\nAlter power / sleep / hibernate button behaviors\n\n\n/etc/systemd/logind.conf",
            "title": "Systemd"
        },
        {
            "location": "/systemd/#tips",
            "text": "",
            "title": "Tips"
        },
        {
            "location": "/systemd/#init-file-locations",
            "text": "/usr/lib/systemd/system\n/etc/systemd/system # has precedence",
            "title": "Init file locations"
        },
        {
            "location": "/systemd/#show-the-full-systemd-journal",
            "text": "The systemd journal is syslog and more.  journalctl --full",
            "title": "Show the full systemd journal"
        },
        {
            "location": "/systemd/#show-the-nginx-journal-for-today",
            "text": "journalctl -u nginx.service --since today",
            "title": "Show the nginx journal for today"
        },
        {
            "location": "/systemd/#show-units",
            "text": "Units are things that are handled by systemd, including services.     systemctl list-units",
            "title": "Show units"
        },
        {
            "location": "/systemd/#show-dependencies",
            "text": "This works on any .target or .service  systemctl list-dependencies network.service",
            "title": "Show dependencies"
        },
        {
            "location": "/systemd/#enable-a-service",
            "text": "This behavior replaces chkconfig  systemctl enable docker.service",
            "title": "Enable a service"
        },
        {
            "location": "/systemd/#check-the-status-of-a-service-and-show-20-lines",
            "text": "systemctl -n 20 status nodejs",
            "title": "Check the status of a service and show 20 lines"
        },
        {
            "location": "/systemd/#per-user-services",
            "text": "https://wiki.archlinux.org/index.php/Systemd/User  /usr/lib/systemd/user/ - where services provided by installed packages go.\n/etc/systemd/user/ - where system-wide user services are placed by the system administrator.\n~/.config/systemd/user/ - where the user puts its own services.",
            "title": "Per-user services"
        },
        {
            "location": "/systemd/#alter-power-sleep-hibernate-button-behaviors",
            "text": "/etc/systemd/logind.conf",
            "title": "Alter power / sleep / hibernate button behaviors"
        },
        {
            "location": "/tcpdump/",
            "text": "Network sniffing tool.\n\n\nSyntax Examples\n\n\nCapture packets to and from an IP address\n\n\nOnly captures data that includes 1.2.3.4 as source or destination address\n\n\ntcpdump host 1.2.3.4\n\n\n\n\nCapture traffic that contains a given mac address\n\n\nwrites capfile.cap containing all traffic to or from the specified mac address on the network attached to eth1\n\n\ntcpdump -w capfile.cap -i eth1 ether host 00:03:fa:46:2c:08\n\n\n\n\nFilter packets from an existing capture\n\n\nFilters port 53 packets out of the old capfile into the new\n\n\ntcpdump -r oldcapfile.cap -w newcapfile.cap port 53\n\n\n\n\nCapture all pop3 traffic and all traffic from a particular host\n\n\nCaptures all pop3 traffic and all traffic to or from the specified host on the first interface of a Mac OS X computer\n\n\ntcpdump -w foo.cap -i en0 ether host 00:03:9a:28:44:01 or port 110\n\n\n\n\nCapture all traffic not a mac address\n\n\nCaptures all traffic not from the host 00:1b:63:ce:83:2e, useful for filtering out your own traffic.\n\n\ntcpdump -i en1 not ether src 00:1b:63:ce:83:2e\n\n\n\n\nCapture LLDP traffic\n\n\nThis matches 2 bytes starting at the 12th byte against 88cc\n\n\ntcpdump -v -s 1500 -c 1  '(ether[12:2]=0x88cc)'\n\n\n\n\nCapture SYN packets\n\n\ntcpdump -n 'tcp[13] & 2!=0'\n\n\n\n\nCapture SYN/ACK packets\n\n\ntcpdump -n 'tcp[13]=18'\n\n\n\n\nOr another way\n\n\ntcpdump 'tcp[tcpflags] && tcp-syn != 0'\n\n\n\n\nOr capture all SYN packets going only to two ethernet destinations:\n\n\ntcpdump 'tcp[13] & 2!=0 && (ether dst 00:22:64:f4:d0:70 or ether dst 00:22:64:f4:d0:6e)'\n\n\n\n\nWrite capture to file and replay it at the same time\n\n\nsudo tcpdump -n 'host 216.200.102.84' -s 1500 -l -w - | tee logcopy.pcap | tcpdump -r -\n\n\n\n\nWrite a circular buffer of traffic\n\n\nThis will write 5 files 1 mb each and loop through them as the destination for writing traffic. That is, the filenames do not indicate chronology. The files will be named foo.cap[0-4]\n\n\nsudo tcpdump -C 1 -W 5 -w foo.cap\n\n\n\n\nYou can reassemble these files chronologically with \nmergecap -w merged.cap foo.cap*\n\n\nLinks\n\n\n\n\nhttp://www.danielmiessler.com/study/tcpdump/",
            "title": "Tcpdump"
        },
        {
            "location": "/tcpdump/#syntax-examples",
            "text": "",
            "title": "Syntax Examples"
        },
        {
            "location": "/tcpdump/#capture-packets-to-and-from-an-ip-address",
            "text": "Only captures data that includes 1.2.3.4 as source or destination address  tcpdump host 1.2.3.4",
            "title": "Capture packets to and from an IP address"
        },
        {
            "location": "/tcpdump/#capture-traffic-that-contains-a-given-mac-address",
            "text": "writes capfile.cap containing all traffic to or from the specified mac address on the network attached to eth1  tcpdump -w capfile.cap -i eth1 ether host 00:03:fa:46:2c:08",
            "title": "Capture traffic that contains a given mac address"
        },
        {
            "location": "/tcpdump/#filter-packets-from-an-existing-capture",
            "text": "Filters port 53 packets out of the old capfile into the new  tcpdump -r oldcapfile.cap -w newcapfile.cap port 53",
            "title": "Filter packets from an existing capture"
        },
        {
            "location": "/tcpdump/#capture-all-pop3-traffic-and-all-traffic-from-a-particular-host",
            "text": "Captures all pop3 traffic and all traffic to or from the specified host on the first interface of a Mac OS X computer  tcpdump -w foo.cap -i en0 ether host 00:03:9a:28:44:01 or port 110",
            "title": "Capture all pop3 traffic and all traffic from a particular host"
        },
        {
            "location": "/tcpdump/#capture-all-traffic-not-a-mac-address",
            "text": "Captures all traffic not from the host 00:1b:63:ce:83:2e, useful for filtering out your own traffic.  tcpdump -i en1 not ether src 00:1b:63:ce:83:2e",
            "title": "Capture all traffic not a mac address"
        },
        {
            "location": "/tcpdump/#capture-lldp-traffic",
            "text": "This matches 2 bytes starting at the 12th byte against 88cc  tcpdump -v -s 1500 -c 1  '(ether[12:2]=0x88cc)'",
            "title": "Capture LLDP traffic"
        },
        {
            "location": "/tcpdump/#capture-syn-packets",
            "text": "tcpdump -n 'tcp[13] & 2!=0'",
            "title": "Capture SYN packets"
        },
        {
            "location": "/tcpdump/#capture-synack-packets",
            "text": "tcpdump -n 'tcp[13]=18'  Or another way  tcpdump 'tcp[tcpflags] && tcp-syn != 0'  Or capture all SYN packets going only to two ethernet destinations:  tcpdump 'tcp[13] & 2!=0 && (ether dst 00:22:64:f4:d0:70 or ether dst 00:22:64:f4:d0:6e)'",
            "title": "Capture SYN/ACK packets"
        },
        {
            "location": "/tcpdump/#write-capture-to-file-and-replay-it-at-the-same-time",
            "text": "sudo tcpdump -n 'host 216.200.102.84' -s 1500 -l -w - | tee logcopy.pcap | tcpdump -r -",
            "title": "Write capture to file and replay it at the same time"
        },
        {
            "location": "/tcpdump/#write-a-circular-buffer-of-traffic",
            "text": "This will write 5 files 1 mb each and loop through them as the destination for writing traffic. That is, the filenames do not indicate chronology. The files will be named foo.cap[0-4]  sudo tcpdump -C 1 -W 5 -w foo.cap  You can reassemble these files chronologically with  mergecap -w merged.cap foo.cap*",
            "title": "Write a circular buffer of traffic"
        },
        {
            "location": "/tcpdump/#links",
            "text": "http://www.danielmiessler.com/study/tcpdump/",
            "title": "Links"
        },
        {
            "location": "/time/",
            "text": "Notes about time technologies.\n\n\nISO 8601\n\n\nISO 8601 Data elements and interchange formats \u2013 Information interchange \u2013 Representation of dates and times is an international standard covering the exchange of date and time-related data.\n\n\nISO 8601 format examples\n\n\nSee the \nISO 8601 wikipedia page\n for many examples. Much of the content in this section was taken from that article.\n\n\nOne notable syntax is that the letter T should always precede times. This aids in parsing, and distinguishes between month and minute, which are both shortened to M.\n\n\nAnother notable syntax is the use of Z to mean a timezone offset of 0 hours, or GMT.\n\n\nSingle points in time\n\n\n$ for fmt in {date,hours,minutes,seconds,ns} ; do\n    bash -x -c \"\n      TZ=$(\n        awk '$1 !~ /^#/ {print $3}' /usr/share/zoneinfo/zone.tab |\n        sort -R |\n        head -n 1\n      ) \\\n      date --iso-8601=${fmt}\n    \" ;\n  done ;\n+ TZ=America/Paramaribo\n+ date --iso-8601=date\n2016-08-09\n+ TZ=Africa/Dakar\n+ date --iso-8601=hours\n2016-08-09T21+00:00\n+ TZ=Indian/Kerguelen\n+ date --iso-8601=minutes\n2016-08-10T02:58+05:00\n+ TZ=Pacific/Saipan\n+ date --iso-8601=seconds\n2016-08-10T07:58:48+10:00\n+ TZ=Pacific/Midway\n+ date --iso-8601=ns\n2016-08-09T10:58:48,503878101-11:00\n\n\n\n\n\n\nWeek: 2016-W32\n\n\nDate with week number: 2016-W32-2\n\n\nMonth and day without year: -12-31\n\n\n\n\nDurations, or ranges of time\n\n\nDurations are a component of time intervals and define the amount of intervening time in a time interval.\n\n\nExamples:\n\n\n\n\nP10Y - a duration of ten years.\n\n\nP5DT12H - a duration of five days and twelve hours.\n\n\nP3Y6M4DT12H30M5S - a duration of three years, six months, four days, twelve hours, thirty minutes, and five seconds.\n\n\nP1M - one month.\n\n\nPT1M - one minute.\n\n\n\n\nTime intervals\n\n\nA time interval is the intervening time between two time points. There are four ways to express a time interval:\n\n\n\n\nStart and end, such as \n2007-03-01T13:00:00Z/2008-05-11T15:30:00Z\n\n\nStart and duration, such as \n2007-03-01T13:00:00Z/P1Y2M10DT2H30M\n\n\nDuration and end, such as \nP1Y2M10DT2H30M/2008-05-11T15:30:00Z\n\n\nDuration only, such as \nP1Y2M10DT2H30M\n, with additional context information\n\n\n\n\nRepeating intervals\n\n\nRepeating intervals are formed by adding \nR[n]/\n to the beginning of an interval expression. Such as \nR5/2007-03-01T13:00:00Z/2008-05-11T15:30:00Z\n. The \nn\n can be omitted if the interval should repeat forever.\n\n\nRFC 3339\n\n\nRFC 3339 is considered a profile of ISO 8601. It defines a profile of ISO 8601 for use in Internet protocols and standards. It explicitly excludes durations and dates before the common era. The more complex formats such as week numbers and ordinal days are not permitted.\n\n\n\n\nhttps://tools.ietf.org/html/rfc3339\n\n\n\n\nLeap Seconds\n\n\n\"A leap second is a one-second adjustment that is occasionally applied to \nCoordinated Universal Time (UTC)\n in order to keep its time of day close to the mean solar time, or \nUT1\n.\" - \nhttps://en.wikipedia.org/wiki/Leap_second\n\n\nLeap seconds are scheduled by the \ninternational earth rotation and reference systems service\n (See also: \nhttps://en.wikipedia.org/wiki/International_Earth_Rotation_and_Reference_Systems_Service\n) Leap seconds cause a variety of problems in computer systems, and complicate time tracking in general.\n\n\nPublic time server handling of leap seconds\n\n\n\n\nGoogle time servers do leap second smearing - \nhttps://developers.google.com/time/\n\n\nAWS time servers do leap second smearing - \nhttps://aws.amazon.com/about-aws/whats-new/2017/11/introducing-the-amazon-time-sync-service\n\n\nntp.org servers do not leap smear: \"Leap Second Smearing MUST NOT be used for public servers, e.g. servers provided by metrology institutes, or servers participating in the NTP pool project.\" - \nhttps://docs.ntpsec.org/latest/leapsmear.html\n\n\n\n\nLeap Second Links\n\n\n\n\nWhen is the next leap second?\n\n\nResolve Leap Second Issues in Red Hat Enterprise Linux\n\n\nGoogle Public NTP: Leap Smear\n\n\nFive different ways to handle leap seconds with NTP\n\n\nThe Unix leap second mess\n\n\nntp.org FAQ: What happens during a Leap Second?\n\n\n\n\nCode snips and examples\n\n\nQuick and dirty time sync in Linux for when NTP is blocked.\n\n\ndate -s $(curl -s -D - google.com | sed '/Date:/s/.*Date: //p ; d')\n\n\n\n\nLinks\n\n\nReading\n\n\n\n\nUnderstanding and mitigating NTP-based DDoS attacks\n\n\nISO 8601\n\n\nDate and Time on the Internet: Timestamps - RFC 3339\n\n\nExamples of date (GNU)\n\n\nman date (linux)\n\n\nman date (freebsd)\n\n\nFalsehoods programmers believe about time\n\n\nMore falsehoods programmers believe about time; \"wisdom of the crowd\" edition\n\n\nInternational Earth Rotation and Reference Systems Service\n\n\n\n\nVideos\n\n\n\n\nThe Problem with Time & Timezones - Computerphile",
            "title": "Time"
        },
        {
            "location": "/time/#iso-8601",
            "text": "ISO 8601 Data elements and interchange formats \u2013 Information interchange \u2013 Representation of dates and times is an international standard covering the exchange of date and time-related data.",
            "title": "ISO 8601"
        },
        {
            "location": "/time/#iso-8601-format-examples",
            "text": "See the  ISO 8601 wikipedia page  for many examples. Much of the content in this section was taken from that article.  One notable syntax is that the letter T should always precede times. This aids in parsing, and distinguishes between month and minute, which are both shortened to M.  Another notable syntax is the use of Z to mean a timezone offset of 0 hours, or GMT.",
            "title": "ISO 8601 format examples"
        },
        {
            "location": "/time/#single-points-in-time",
            "text": "$ for fmt in {date,hours,minutes,seconds,ns} ; do\n    bash -x -c \"\n      TZ=$(\n        awk '$1 !~ /^#/ {print $3}' /usr/share/zoneinfo/zone.tab |\n        sort -R |\n        head -n 1\n      ) \\\n      date --iso-8601=${fmt}\n    \" ;\n  done ;\n+ TZ=America/Paramaribo\n+ date --iso-8601=date\n2016-08-09\n+ TZ=Africa/Dakar\n+ date --iso-8601=hours\n2016-08-09T21+00:00\n+ TZ=Indian/Kerguelen\n+ date --iso-8601=minutes\n2016-08-10T02:58+05:00\n+ TZ=Pacific/Saipan\n+ date --iso-8601=seconds\n2016-08-10T07:58:48+10:00\n+ TZ=Pacific/Midway\n+ date --iso-8601=ns\n2016-08-09T10:58:48,503878101-11:00   Week: 2016-W32  Date with week number: 2016-W32-2  Month and day without year: -12-31",
            "title": "Single points in time"
        },
        {
            "location": "/time/#durations-or-ranges-of-time",
            "text": "Durations are a component of time intervals and define the amount of intervening time in a time interval.",
            "title": "Durations, or ranges of time"
        },
        {
            "location": "/time/#examples",
            "text": "P10Y - a duration of ten years.  P5DT12H - a duration of five days and twelve hours.  P3Y6M4DT12H30M5S - a duration of three years, six months, four days, twelve hours, thirty minutes, and five seconds.  P1M - one month.  PT1M - one minute.",
            "title": "Examples:"
        },
        {
            "location": "/time/#time-intervals",
            "text": "A time interval is the intervening time between two time points. There are four ways to express a time interval:   Start and end, such as  2007-03-01T13:00:00Z/2008-05-11T15:30:00Z  Start and duration, such as  2007-03-01T13:00:00Z/P1Y2M10DT2H30M  Duration and end, such as  P1Y2M10DT2H30M/2008-05-11T15:30:00Z  Duration only, such as  P1Y2M10DT2H30M , with additional context information",
            "title": "Time intervals"
        },
        {
            "location": "/time/#repeating-intervals",
            "text": "Repeating intervals are formed by adding  R[n]/  to the beginning of an interval expression. Such as  R5/2007-03-01T13:00:00Z/2008-05-11T15:30:00Z . The  n  can be omitted if the interval should repeat forever.",
            "title": "Repeating intervals"
        },
        {
            "location": "/time/#rfc-3339",
            "text": "RFC 3339 is considered a profile of ISO 8601. It defines a profile of ISO 8601 for use in Internet protocols and standards. It explicitly excludes durations and dates before the common era. The more complex formats such as week numbers and ordinal days are not permitted.   https://tools.ietf.org/html/rfc3339",
            "title": "RFC 3339"
        },
        {
            "location": "/time/#leap-seconds",
            "text": "\"A leap second is a one-second adjustment that is occasionally applied to  Coordinated Universal Time (UTC)  in order to keep its time of day close to the mean solar time, or  UT1 .\" -  https://en.wikipedia.org/wiki/Leap_second  Leap seconds are scheduled by the  international earth rotation and reference systems service  (See also:  https://en.wikipedia.org/wiki/International_Earth_Rotation_and_Reference_Systems_Service ) Leap seconds cause a variety of problems in computer systems, and complicate time tracking in general.",
            "title": "Leap Seconds"
        },
        {
            "location": "/time/#public-time-server-handling-of-leap-seconds",
            "text": "Google time servers do leap second smearing -  https://developers.google.com/time/  AWS time servers do leap second smearing -  https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-the-amazon-time-sync-service  ntp.org servers do not leap smear: \"Leap Second Smearing MUST NOT be used for public servers, e.g. servers provided by metrology institutes, or servers participating in the NTP pool project.\" -  https://docs.ntpsec.org/latest/leapsmear.html",
            "title": "Public time server handling of leap seconds"
        },
        {
            "location": "/time/#leap-second-links",
            "text": "When is the next leap second?  Resolve Leap Second Issues in Red Hat Enterprise Linux  Google Public NTP: Leap Smear  Five different ways to handle leap seconds with NTP  The Unix leap second mess  ntp.org FAQ: What happens during a Leap Second?",
            "title": "Leap Second Links"
        },
        {
            "location": "/time/#code-snips-and-examples",
            "text": "",
            "title": "Code snips and examples"
        },
        {
            "location": "/time/#quick-and-dirty-time-sync-in-linux-for-when-ntp-is-blocked",
            "text": "date -s $(curl -s -D - google.com | sed '/Date:/s/.*Date: //p ; d')",
            "title": "Quick and dirty time sync in Linux for when NTP is blocked."
        },
        {
            "location": "/time/#links",
            "text": "",
            "title": "Links"
        },
        {
            "location": "/time/#reading",
            "text": "Understanding and mitigating NTP-based DDoS attacks  ISO 8601  Date and Time on the Internet: Timestamps - RFC 3339  Examples of date (GNU)  man date (linux)  man date (freebsd)  Falsehoods programmers believe about time  More falsehoods programmers believe about time; \"wisdom of the crowd\" edition  International Earth Rotation and Reference Systems Service",
            "title": "Reading"
        },
        {
            "location": "/time/#videos",
            "text": "The Problem with Time & Timezones - Computerphile",
            "title": "Videos"
        },
        {
            "location": "/tls/",
            "text": "TLS is Transport Layer Security. It used to be called SSL: the Secure Sockets Layer. It has to do with encrypted IP traffic and stuff stuff.\n\n\nApache SSL steps\n\n\n\n\nGenerate a host key: \nopenssl genrsa -out foo.com.key 2048\n\n\nGenerate a CSR from that key: \nopenssl req -new -key foo.com.key -out foo.com.csr\n\n\n\n\nTo set up VirtualHosts, follow this template: \nhttp://wiki.apache.org/httpd/NameBasedSSLVHosts\n\n\nExamples\n\n\nShow info about a pem file\n\n\nopenssl\u00a0x509\u00a0-noout\u00a0-text\u00a0-in\u00a0foo.pem\n\n\n\n\nShow certificate options\n\n\nopenssl x509 -text -in foo.crt\n\n\n\n\nValidate a keys / cert pair\n\n\nTo validate that a particular key was used to generate a certificate, useful for testing https key/crt files, do the following and make sure the modulus sections match:\n\n\nopenssl\u00a0rsa\u00a0\u00a0-noout\u00a0-text\u00a0-in\u00a0server.key\u00a0|\u00a0grep\u00a0-i\u00a0-A9\u00a0modulus\nopenssl\u00a0x509\u00a0-noout\u00a0-text\u00a0-in\u00a0server.crt\u00a0|\u00a0grep\u00a0-i\u00a0-A9\u00a0modulus\n\n\n\n\nOr\n\n\ndiff <(openssl rsa -in my.key -modulus | grep Modulus) <(openssl x509 -in my.crt -modulus | grep Modulus)\n\n\n\n\nOr as a function:\n\n\nfunction cert-key-compare {\n    if [[ \"$1\" != *key* ]] || [[ \"$2\" != *cert* ]] ; then\n        echo \"usage: cert-key-compare key certificate\" ;\n    else\n        diff \\\n      <(openssl rsa  -in $1 -modulus 2>/dev/null | grep Modulus) \\\n      <(openssl x509 -in $2 -modulus 2>/dev/null | grep Modulus) \\\n      > /dev/null && echo \"key and crt match.\" || echo \"key and crt do not match\"\n    fi\n}\n\n\n\n\nSee some information about a server's certificate\n\n\nopenssl\u00a0s_client\u00a0-connect\u00a0linuxforums.org:443\n\n\n\n\nEncrypt a file\n\n\nopenssl\u00a0enc\u00a0-aes-256-cbc\u00a0-salt\u00a0-in\u00a0yourfile\u00a0-out\u00a0yourfile.enc\n\n\n\n\nDecrypt a file\n\n\nopenssl\u00a0enc\u00a0-aes-256-cbc\u00a0-d\u00a0-in\u00a0encryptedfile.enc\u00a0-out\u00a0decryptedfile\n\n\n\n\nEncrypt / Decrypt bash functions\n\n\nfunction encrypt_file() { openssl enc -aes-256-cbc -salt -in \"${1}\" -out \"${1}.enc\" ; }\nfunction decrypt_file() { openssl enc -aes-256-cbc -d -in \"${1}\" -out \"${1}.dec\" ; }\n\n\n\n\nLinks\n\n\n\n\nAn overview of the SSL or TLS handshake\n\n\nThe Transport Layer Security (TLS) Protocol Version 1.2 - \nhttps://tools.ietf.org/html/rfc5246",
            "title": "Tls"
        },
        {
            "location": "/tls/#apache-ssl-steps",
            "text": "Generate a host key:  openssl genrsa -out foo.com.key 2048  Generate a CSR from that key:  openssl req -new -key foo.com.key -out foo.com.csr   To set up VirtualHosts, follow this template:  http://wiki.apache.org/httpd/NameBasedSSLVHosts",
            "title": "Apache SSL steps"
        },
        {
            "location": "/tls/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/tls/#show-info-about-a-pem-file",
            "text": "openssl\u00a0x509\u00a0-noout\u00a0-text\u00a0-in\u00a0foo.pem",
            "title": "Show info about a pem file"
        },
        {
            "location": "/tls/#show-certificate-options",
            "text": "openssl x509 -text -in foo.crt",
            "title": "Show certificate options"
        },
        {
            "location": "/tls/#validate-a-keys-cert-pair",
            "text": "To validate that a particular key was used to generate a certificate, useful for testing https key/crt files, do the following and make sure the modulus sections match:  openssl\u00a0rsa\u00a0\u00a0-noout\u00a0-text\u00a0-in\u00a0server.key\u00a0|\u00a0grep\u00a0-i\u00a0-A9\u00a0modulus\nopenssl\u00a0x509\u00a0-noout\u00a0-text\u00a0-in\u00a0server.crt\u00a0|\u00a0grep\u00a0-i\u00a0-A9\u00a0modulus  Or  diff <(openssl rsa -in my.key -modulus | grep Modulus) <(openssl x509 -in my.crt -modulus | grep Modulus)  Or as a function:  function cert-key-compare {\n    if [[ \"$1\" != *key* ]] || [[ \"$2\" != *cert* ]] ; then\n        echo \"usage: cert-key-compare key certificate\" ;\n    else\n        diff \\\n      <(openssl rsa  -in $1 -modulus 2>/dev/null | grep Modulus) \\\n      <(openssl x509 -in $2 -modulus 2>/dev/null | grep Modulus) \\\n      > /dev/null && echo \"key and crt match.\" || echo \"key and crt do not match\"\n    fi\n}",
            "title": "Validate a keys / cert pair"
        },
        {
            "location": "/tls/#see-some-information-about-a-servers-certificate",
            "text": "openssl\u00a0s_client\u00a0-connect\u00a0linuxforums.org:443",
            "title": "See some information about a server's certificate"
        },
        {
            "location": "/tls/#encrypt-a-file",
            "text": "openssl\u00a0enc\u00a0-aes-256-cbc\u00a0-salt\u00a0-in\u00a0yourfile\u00a0-out\u00a0yourfile.enc",
            "title": "Encrypt a file"
        },
        {
            "location": "/tls/#decrypt-a-file",
            "text": "openssl\u00a0enc\u00a0-aes-256-cbc\u00a0-d\u00a0-in\u00a0encryptedfile.enc\u00a0-out\u00a0decryptedfile",
            "title": "Decrypt a file"
        },
        {
            "location": "/tls/#encrypt-decrypt-bash-functions",
            "text": "function encrypt_file() { openssl enc -aes-256-cbc -salt -in \"${1}\" -out \"${1}.enc\" ; }\nfunction decrypt_file() { openssl enc -aes-256-cbc -d -in \"${1}\" -out \"${1}.dec\" ; }",
            "title": "Encrypt / Decrypt bash functions"
        },
        {
            "location": "/tls/#links",
            "text": "An overview of the SSL or TLS handshake  The Transport Layer Security (TLS) Protocol Version 1.2 -  https://tools.ietf.org/html/rfc5246",
            "title": "Links"
        },
        {
            "location": "/top-variant-list/",
            "text": "The \ntop\n interface is a common pattern in the CLI tool world. Here are some top style tools.\n\n\ntop style tools\n\n\n\n\natop\n - Linux top tool that catches short-lived processes.\n\n\nglances\n - A better \ntop\n which shows more aspects of the system.\n\n\nhtop\n - Top, but different.  Perhaps better.\n\n\niftop\n - Top for network interfaces.\n\n\ninnotop\n - Top for database connections.\n\n\niotop\n - Top for IO.\n\n\nnethogs\n - Network top that shows usage by pid.\n\n\nntop\n - Top for networking.\n\n\npowertop\n - Top for power usage.\n\n\ntop\n - The original.",
            "title": "Top variant list"
        },
        {
            "location": "/top-variant-list/#top-style-tools",
            "text": "atop  - Linux top tool that catches short-lived processes.  glances  - A better  top  which shows more aspects of the system.  htop  - Top, but different.  Perhaps better.  iftop  - Top for network interfaces.  innotop  - Top for database connections.  iotop  - Top for IO.  nethogs  - Network top that shows usage by pid.  ntop  - Top for networking.  powertop  - Top for power usage.  top  - The original.",
            "title": "top style tools"
        },
        {
            "location": "/top/",
            "text": "top is a CLI tool to show running processes.\n\n\nGNU top Usage\n\n\n\n\nChange the number of displayed processes with \nn\n\n\nDisplay all CPUs with \n1\n\n\nKill a process with \nk\n\n\nRenice a process with \nr\n\n\nSave current display as default in \n~/.toprc\n with \nW\n\n\nShow or hide idle processes with \ni\n\n\nSort output with \nO\n\n\n\n\nBSD top Usage\n\n\nStart top sorted by cpu\n\n\ntop\u00a0-u\n\n\n\n\nSee also\n\n\n\n\nTop variant list",
            "title": "Top"
        },
        {
            "location": "/top/#gnu-top-usage",
            "text": "Change the number of displayed processes with  n  Display all CPUs with  1  Kill a process with  k  Renice a process with  r  Save current display as default in  ~/.toprc  with  W  Show or hide idle processes with  i  Sort output with  O",
            "title": "GNU top Usage"
        },
        {
            "location": "/top/#bsd-top-usage",
            "text": "",
            "title": "BSD top Usage"
        },
        {
            "location": "/top/#start-top-sorted-by-cpu",
            "text": "top\u00a0-u",
            "title": "Start top sorted by cpu"
        },
        {
            "location": "/top/#see-also",
            "text": "Top variant list",
            "title": "See also"
        },
        {
            "location": "/touch/",
            "text": "touch\n is a command to modify the date of filesystem metadata for a given file.\n\n\nExamples\n\n\nCreate an empty file\n\n\ntouch somefile\n\n\nRandomize the mtime for a given file\n\n\nbash's random only goes up to 32767, which is about 9 hours. With RANDOM * 32767 + RANDOM we can get this up to just over 34 years.\n\n\nrandomize-mtime() {\n  seconds=\"$(( $(date +%s) - $(( RANDOM * 32767 )) - RANDOM))\"\n  new_mtime=\"$(gdate -d @\"${seconds}\" \"+%Y%m%d%H%M.%S\")\"\n  echo \"${new_mtime} $*\" 1>&2\n  touch -m -t \"${new_mtime}\" \"$@\"\n}\n\n# change mtime of all files to the same random mtime\nrandomize-mtime test-foo{1..3} ;\n\n# change mtime of each file to a different random mtime\nfor F in test-bar{1..3} ; do\n  randomize-mtime \"$F\"\ndone",
            "title": "Touch"
        },
        {
            "location": "/touch/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/touch/#create-an-empty-file",
            "text": "touch somefile",
            "title": "Create an empty file"
        },
        {
            "location": "/touch/#randomize-the-mtime-for-a-given-file",
            "text": "bash's random only goes up to 32767, which is about 9 hours. With RANDOM * 32767 + RANDOM we can get this up to just over 34 years.  randomize-mtime() {\n  seconds=\"$(( $(date +%s) - $(( RANDOM * 32767 )) - RANDOM))\"\n  new_mtime=\"$(gdate -d @\"${seconds}\" \"+%Y%m%d%H%M.%S\")\"\n  echo \"${new_mtime} $*\" 1>&2\n  touch -m -t \"${new_mtime}\" \"$@\"\n}\n\n# change mtime of all files to the same random mtime\nrandomize-mtime test-foo{1..3} ;\n\n# change mtime of each file to a different random mtime\nfor F in test-bar{1..3} ; do\n  randomize-mtime \"$F\"\ndone",
            "title": "Randomize the mtime for a given file"
        },
        {
            "location": "/ubuntu/",
            "text": "Versions overview\n\n\n\n\n\n\n\n\nCodename\n\n\nUbuntu Version\n\n\nEOL\n\n\nInit\n\n\nRuby\n\n\nPython\n\n\nbash\n\n\n\n\n\n\n\n\n\n\nZesty\n\n\n17.04\n\n\n2018-01\n\n\nsystemd\n\n\n\n\n\n\n\n\n\n\n\n\nYakkety\n\n\n16.10\n\n\n2017-07\n\n\nsystemd\n\n\n\n\n\n\n\n\n\n\n\n\nXenial\n\n\n16.04 LTS\n\n\n2021-04\n\n\nsystemd\n\n\n\n\n2.7.12 / 3.5\n\n\n4.3.46\n\n\n\n\n\n\nTrusty\n\n\n14.04 LTS\n\n\n2019-04\n\n\nUpstart\n\n\n1.9.3\n\n\n2.7.6\n\n\n4.3.11\n\n\n\n\n\n\nPrecise\n\n\n12.04 LTS\n\n\n2017-04\n\n\nUpstart\n\n\n1.8.7\n\n\n\n\n\n\n\n\n\n\nLucid\n\n\n10.04 LTS\n\n\n2015-04\n\n\nUpstart\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\nUbuntu Kernel Support and Schedules\n\n\nList of releases",
            "title": "Versions overview"
        },
        {
            "location": "/ubuntu/#versions-overview",
            "text": "Codename  Ubuntu Version  EOL  Init  Ruby  Python  bash      Zesty  17.04  2018-01  systemd       Yakkety  16.10  2017-07  systemd       Xenial  16.04 LTS  2021-04  systemd   2.7.12 / 3.5  4.3.46    Trusty  14.04 LTS  2019-04  Upstart  1.9.3  2.7.6  4.3.11    Precise  12.04 LTS  2017-04  Upstart  1.8.7      Lucid  10.04 LTS  2015-04  Upstart",
            "title": "Versions overview"
        },
        {
            "location": "/ubuntu/#links",
            "text": "Ubuntu Kernel Support and Schedules  List of releases",
            "title": "Links"
        },
        {
            "location": "/upstart/",
            "text": "\"Upstart is an event-based replacement for the \n/sbin/init\n daemon which handles starting of tasks and services during boot, stopping them during shutdown and supervising them while the system is running.\" - \nhttp://upstart.ubuntu.com\n\n\nExamples\n\n\nStart multiple instances of the same services\n\n\nhttp://upstart.ubuntu.com/cookbook/#instance\n\n\nMaster\n\n\nstart on runlevel [2345]\nstop on runlevel [^2345]\nrespawn\n\nenv job_count=6\n\npre-start script\n  for i in $(seq -w 1 ${job_count}) ; do\n    start photoworker N=${i}\n  done\nend script\n\npost-stop script\n  for i in $(seq -w 1 ${job_count}) ; do\n    stop photoworker N=${i}\n  done\nend script\n\n\n\n\n\nChild\n\n\nrespawn\nrespawn limit 10 5\ninstance $N\nenv logfile=\"/var/log/worker_photoworker.log\"\nchdir /srv/photoworkers/current/web/services/jobworkers\n\npre-start exec bash -c \"echo $(date --rfc-3339=seconds) beginning worker run >> ${logfile}\"\nexec su -s /bin/sh -c 'exec \"$0\" \"$@\"' php-worker -- php photoworker.php >> ${logfile} 2>&1\npost-stop exec bash -c \"echo $(date --rfc-3339=seconds) ended worker run >> ${logfile}\"\n\n\n\n\nRedirect all output of an upstart script to syslog\n\n\nFound at \nhttp://serverfault.com/questions/114052/logging-a-daemons-output-with-upstart\n\n\nscript\n  FIFO=fifo.temp\n  mkfifo $FIFO\n\n  ( logger -t myservice <$FIFO & )\n\n  exec > $FIFO\n  rm $FIFO\n\n  exec /usr/local/bin/myservice 2>&1\nend script\n\n\n\n\nLinks\n\n\n\n\nhttp://upstart.ubuntu.com/cookbook",
            "title": "Upstart"
        },
        {
            "location": "/upstart/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/upstart/#start-multiple-instances-of-the-same-services",
            "text": "http://upstart.ubuntu.com/cookbook/#instance",
            "title": "Start multiple instances of the same services"
        },
        {
            "location": "/upstart/#master",
            "text": "start on runlevel [2345]\nstop on runlevel [^2345]\nrespawn\n\nenv job_count=6\n\npre-start script\n  for i in $(seq -w 1 ${job_count}) ; do\n    start photoworker N=${i}\n  done\nend script\n\npost-stop script\n  for i in $(seq -w 1 ${job_count}) ; do\n    stop photoworker N=${i}\n  done\nend script",
            "title": "Master"
        },
        {
            "location": "/upstart/#child",
            "text": "respawn\nrespawn limit 10 5\ninstance $N\nenv logfile=\"/var/log/worker_photoworker.log\"\nchdir /srv/photoworkers/current/web/services/jobworkers\n\npre-start exec bash -c \"echo $(date --rfc-3339=seconds) beginning worker run >> ${logfile}\"\nexec su -s /bin/sh -c 'exec \"$0\" \"$@\"' php-worker -- php photoworker.php >> ${logfile} 2>&1\npost-stop exec bash -c \"echo $(date --rfc-3339=seconds) ended worker run >> ${logfile}\"",
            "title": "Child"
        },
        {
            "location": "/upstart/#redirect-all-output-of-an-upstart-script-to-syslog",
            "text": "Found at  http://serverfault.com/questions/114052/logging-a-daemons-output-with-upstart  script\n  FIFO=fifo.temp\n  mkfifo $FIFO\n\n  ( logger -t myservice <$FIFO & )\n\n  exec > $FIFO\n  rm $FIFO\n\n  exec /usr/local/bin/myservice 2>&1\nend script",
            "title": "Redirect all output of an upstart script to syslog"
        },
        {
            "location": "/upstart/#links",
            "text": "http://upstart.ubuntu.com/cookbook",
            "title": "Links"
        },
        {
            "location": "/vagrant/",
            "text": "Vagrantfile syntax is ruby\n\n\nhttps://www.vagrantup.com\n\n\nhttps://docs.vagrantup.com/v2\n\n\nhttps://atlas.hashicorp.com\n\n\nExamples: \nhttps://github.com/patrickdlee/vagrant-examples\n\n\n\n\nOS X Shell tweaks\n\n\nbrew tap homebrew/completions\nbrew install vagrant-completion\n\n\n\n\nThen in .bash_profile:\n\n\nif [ -f $(brew --prefix)/etc/bash_completion ]; then\n  . $(brew --prefix)/etc/bash_completion\nfi\n\n\n\n\nPlugins\n\n\nvagrant plugin install vagrant-vbguest\nvagrant plugin install vagrant-hosts\n\n\n\n\nUsage Examples\n\n\nList which boxes you have stored locally\n\n\nvagrant box List\n\n\n\n\nRemove an old version of a vagrant box\n\n\nvagrant box remove ubuntu/trusty64 --box-version 20151201.0.0\n\n\n\n\nScript box updates\n\n\nThis may fail in some circumstances, I haven't tested it exhaustively.\n\n\nvagrant box outdated --machine-readable --global |\n  awk -F, '$4 == \"warn\" {print $5; exit 1}' |\n  awk -F\"'\" '{print $2}' |\n  xargs -n1 vagrant box update --box\n\n\n\n\nShow status of all running Vagrant boxes, not just the one in the CWD\n\n\nvagrant global-status",
            "title": "Vagrant"
        },
        {
            "location": "/vagrant/#os-x-shell-tweaks",
            "text": "brew tap homebrew/completions\nbrew install vagrant-completion  Then in .bash_profile:  if [ -f $(brew --prefix)/etc/bash_completion ]; then\n  . $(brew --prefix)/etc/bash_completion\nfi",
            "title": "OS X Shell tweaks"
        },
        {
            "location": "/vagrant/#plugins",
            "text": "vagrant plugin install vagrant-vbguest\nvagrant plugin install vagrant-hosts",
            "title": "Plugins"
        },
        {
            "location": "/vagrant/#usage-examples",
            "text": "",
            "title": "Usage Examples"
        },
        {
            "location": "/vagrant/#list-which-boxes-you-have-stored-locally",
            "text": "vagrant box List",
            "title": "List which boxes you have stored locally"
        },
        {
            "location": "/vagrant/#remove-an-old-version-of-a-vagrant-box",
            "text": "vagrant box remove ubuntu/trusty64 --box-version 20151201.0.0",
            "title": "Remove an old version of a vagrant box"
        },
        {
            "location": "/vagrant/#script-box-updates",
            "text": "This may fail in some circumstances, I haven't tested it exhaustively.  vagrant box outdated --machine-readable --global |\n  awk -F, '$4 == \"warn\" {print $5; exit 1}' |\n  awk -F\"'\" '{print $2}' |\n  xargs -n1 vagrant box update --box",
            "title": "Script box updates"
        },
        {
            "location": "/vagrant/#show-status-of-all-running-vagrant-boxes-not-just-the-one-in-the-cwd",
            "text": "vagrant global-status",
            "title": "Show status of all running Vagrant boxes, not just the one in the CWD"
        },
        {
            "location": "/videos/",
            "text": "Tech videos\n\n\n\n\nCorey Quinn Scale 14x - Docker Must Die\n\n\nSensu @ Yelp part 1\n\n\nSensu @ Yelp part 2\n\n\nSurge 2015 - Bryan Cantrill - Docker in Production: Tales From the Engine Room\n\n\nTerrible ideas in Git\n\n\nThe Well Tempered API\n - Why can we play 400 year old music but our software only lasts a few months or years?\n\n\nUsing Swagger to tame HTTP/JSON interfaces\n\n\nWorking Theory of Monitoring\n\n\nYelp's Theory of PaaSes talk from Box SRE Hour",
            "title": "Tech videos"
        },
        {
            "location": "/videos/#tech-videos",
            "text": "Corey Quinn Scale 14x - Docker Must Die  Sensu @ Yelp part 1  Sensu @ Yelp part 2  Surge 2015 - Bryan Cantrill - Docker in Production: Tales From the Engine Room  Terrible ideas in Git  The Well Tempered API  - Why can we play 400 year old music but our software only lasts a few months or years?  Using Swagger to tame HTTP/JSON interfaces  Working Theory of Monitoring  Yelp's Theory of PaaSes talk from Box SRE Hour",
            "title": "Tech videos"
        },
        {
            "location": "/vim/",
            "text": "modelines\n\n\nmodelines are commented lines in files that set vim settings to use when editing that file.\n\n\nhttp://vim.wikia.com/wiki/Modeline_magic\n\n\nmodeline example:\n\n\n# vim: set expandtab ts=2",
            "title": "modelines"
        },
        {
            "location": "/vim/#modelines",
            "text": "modelines are commented lines in files that set vim settings to use when editing that file.  http://vim.wikia.com/wiki/Modeline_magic",
            "title": "modelines"
        },
        {
            "location": "/vim/#modeline-example",
            "text": "# vim: set expandtab ts=2",
            "title": "modeline example:"
        },
        {
            "location": "/wget/",
            "text": "\"GNU Wget is a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive commandline tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc.\" - \nhttps://www.gnu.org/software/wget\n\n\nExamples\n\n\nMirror site for local viewing\n\n\nFrom the man page: to download a single page and all its requisites (even if they exist on separate websites), and make sure the lot displays properly locally, this author likes to use a few options in addition to -p:\n\n\nwget -E -H -k -K -p http://<site>/<document>\n\n\n\n\nDownload all images from a site\n\n\nTo politely download all images from within a current remote directory:\n\n\nwget --wait=2 --random-wait --tries=0 --waitretry=30 -np -N -r -A.jpg http://www.site.com/directory/\n\n\n\n\nSimple use of cookies\n\n\nSome servers that need referrers and cookies can be accessed by doing:\n\n\nwget --save-cookies=\"cookies.txt\" \u201cfoo.html\nwget --load-cookies=\"cookies.txt\" --referer=\"foo.html\" \"foo.mp3\"\n\n\n\n\nSet default behavior\n\n\n~/.wgetrc\n sets default parameter values\n\n\ntries=0\ncontinue=1",
            "title": "Wget"
        },
        {
            "location": "/wget/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/wget/#mirror-site-for-local-viewing",
            "text": "From the man page: to download a single page and all its requisites (even if they exist on separate websites), and make sure the lot displays properly locally, this author likes to use a few options in addition to -p:  wget -E -H -k -K -p http://<site>/<document>",
            "title": "Mirror site for local viewing"
        },
        {
            "location": "/wget/#download-all-images-from-a-site",
            "text": "To politely download all images from within a current remote directory:  wget --wait=2 --random-wait --tries=0 --waitretry=30 -np -N -r -A.jpg http://www.site.com/directory/",
            "title": "Download all images from a site"
        },
        {
            "location": "/wget/#simple-use-of-cookies",
            "text": "Some servers that need referrers and cookies can be accessed by doing:  wget --save-cookies=\"cookies.txt\" \u201cfoo.html\nwget --load-cookies=\"cookies.txt\" --referer=\"foo.html\" \"foo.mp3\"",
            "title": "Simple use of cookies"
        },
        {
            "location": "/wget/#set-default-behavior",
            "text": "~/.wgetrc  sets default parameter values  tries=0\ncontinue=1",
            "title": "Set default behavior"
        },
        {
            "location": "/winbind/",
            "text": "These examples may only work on Samba 3. See info about Winbindd here: \nhttps://wiki.samba.org/index.php/Configuring_Winbindd_on_a_Samba_AD_DC\n\n\nExamples\n\n\nPing the winbind servers\n\n\nwbinfo -p\n\n\nlist the domain users\n\n\nwbinfo -u\n\n\ntry authenticating the user against winbind\n\n\nwbinfo -a dhoherd",
            "title": "Winbind"
        },
        {
            "location": "/winbind/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/winbind/#ping-the-winbind-servers",
            "text": "wbinfo -p",
            "title": "Ping the winbind servers"
        },
        {
            "location": "/winbind/#list-the-domain-users",
            "text": "wbinfo -u",
            "title": "list the domain users"
        },
        {
            "location": "/winbind/#try-authenticating-the-user-against-winbind",
            "text": "wbinfo -a dhoherd",
            "title": "try authenticating the user against winbind"
        },
        {
            "location": "/wuzz/",
            "text": "\"Interactive cli tool for HTTP inspection\" - \nhttps://github.com/asciimoo/wuzz",
            "title": "Wuzz"
        },
        {
            "location": "/yaml/",
            "text": "YAML Ain't Markup Language\n\n\n\n\nhttp://www.yaml.org/\n\n\nhttp://www.yaml.org/refcard.html\n\n\nhttps://en.wikipedia.org/wiki/YAML",
            "title": "Yaml"
        },
        {
            "location": "/youtube-dl/",
            "text": "\"Command-line program to download videos from YouTube.com and other video sites\" - \nhttps://github.com/rg3/youtube-dl/\n\n\nExamples\n\n\nShow available media formats\n\n\nyoutube-dl -F 'https://youtu.be/LdCq6y1Uu5Y'\n\n\n\n\nDownload the best quality within resolution bounds\n\n\nyoutube-dl -f 'bestvideo[height<=480]+bestaudio' 'https://youtu.be/-kgTCpv_W64'",
            "title": "Youtube dl"
        },
        {
            "location": "/youtube-dl/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/youtube-dl/#show-available-media-formats",
            "text": "youtube-dl -F 'https://youtu.be/LdCq6y1Uu5Y'",
            "title": "Show available media formats"
        },
        {
            "location": "/youtube-dl/#download-the-best-quality-within-resolution-bounds",
            "text": "youtube-dl -f 'bestvideo[height<=480]+bestaudio' 'https://youtu.be/-kgTCpv_W64'",
            "title": "Download the best quality within resolution bounds"
        },
        {
            "location": "/yum/",
            "text": "Redhat Package Manager is a format for software distribution.\n\n\nTricks\n\n\nShow a list of enabled repositories\n\n\nyum repolist\n\n\n\n\nShow a list of available repositories\n\n\nyum repolist all\n\n\n\n\nShow all installed packages, their versions and their source repo\n\n\nyum list installed\n\n\n\n\nList available packages and the repo they come from\n\n\nyum list available | grep jre\n\n\n\n\nShow all duplicates in a search\n\n\nThis is a good way to get a complete list of packages that are available that match a certain string\n\n\nyum --showduplicates search thrift\n\n\n\n\nQuery available packages in a given repository\n\n\nyum --disablerepo=\"*\" --enablerepo=\"epel\" list available\n\n\n\n\nUpgrade and skip broken dependencies\n\n\nyum upgrade -y --skip-broken\n\n\n\n\nUpgrade and skip certain packages\n\n\nyum upgrade --exclude=*rabbitmq*\n\n\n\n\nCheck for package conflicts\n\n\ninstall yum-utils, then run package-cleanup\n\n\nFind a package that includes a specific command or file\n\n\nyum whatprovides \"*/filename\"\n\n\n\n\nCheck for groups of packages\n\n\nyum grouplist\n\n\nEnable optional installs in groups\n\n\nAdd \ngroup_package_types=mandatory,default,optional\n in /etc/yum.conf\n\n\nDownload but do not install packages for update\n\n\nyum upgrade --downloadonly --skip-broken\n\n\n\n\nInstall a local file using yum\n\n\nyum localinstall whatever.rpm\n\n\n\n\nAuto-updates for Centos5\n\n\nyum install yum-updatesd\n\n\n\n\nAuto-updates for Centos6\n\n\nyum install yum-cron\n\n\n\n\nSee Also\n\n\n\n\nrpm - interact with rpms directly\n\n\nhttps://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/sec-Managing_Yum_Repositories.html",
            "title": "Yum"
        },
        {
            "location": "/yum/#tricks",
            "text": "",
            "title": "Tricks"
        },
        {
            "location": "/yum/#show-a-list-of-enabled-repositories",
            "text": "yum repolist",
            "title": "Show a list of enabled repositories"
        },
        {
            "location": "/yum/#show-a-list-of-available-repositories",
            "text": "yum repolist all",
            "title": "Show a list of available repositories"
        },
        {
            "location": "/yum/#show-all-installed-packages-their-versions-and-their-source-repo",
            "text": "yum list installed",
            "title": "Show all installed packages, their versions and their source repo"
        },
        {
            "location": "/yum/#list-available-packages-and-the-repo-they-come-from",
            "text": "yum list available | grep jre",
            "title": "List available packages and the repo they come from"
        },
        {
            "location": "/yum/#show-all-duplicates-in-a-search",
            "text": "This is a good way to get a complete list of packages that are available that match a certain string  yum --showduplicates search thrift",
            "title": "Show all duplicates in a search"
        },
        {
            "location": "/yum/#query-available-packages-in-a-given-repository",
            "text": "yum --disablerepo=\"*\" --enablerepo=\"epel\" list available",
            "title": "Query available packages in a given repository"
        },
        {
            "location": "/yum/#upgrade-and-skip-broken-dependencies",
            "text": "yum upgrade -y --skip-broken",
            "title": "Upgrade and skip broken dependencies"
        },
        {
            "location": "/yum/#upgrade-and-skip-certain-packages",
            "text": "yum upgrade --exclude=*rabbitmq*",
            "title": "Upgrade and skip certain packages"
        },
        {
            "location": "/yum/#check-for-package-conflicts",
            "text": "install yum-utils, then run package-cleanup",
            "title": "Check for package conflicts"
        },
        {
            "location": "/yum/#find-a-package-that-includes-a-specific-command-or-file",
            "text": "yum whatprovides \"*/filename\"",
            "title": "Find a package that includes a specific command or file"
        },
        {
            "location": "/yum/#check-for-groups-of-packages",
            "text": "yum grouplist",
            "title": "Check for groups of packages"
        },
        {
            "location": "/yum/#enable-optional-installs-in-groups",
            "text": "Add  group_package_types=mandatory,default,optional  in /etc/yum.conf",
            "title": "Enable optional installs in groups"
        },
        {
            "location": "/yum/#download-but-do-not-install-packages-for-update",
            "text": "yum upgrade --downloadonly --skip-broken",
            "title": "Download but do not install packages for update"
        },
        {
            "location": "/yum/#install-a-local-file-using-yum",
            "text": "yum localinstall whatever.rpm",
            "title": "Install a local file using yum"
        },
        {
            "location": "/yum/#auto-updates-for-centos5",
            "text": "yum install yum-updatesd",
            "title": "Auto-updates for Centos5"
        },
        {
            "location": "/yum/#auto-updates-for-centos6",
            "text": "yum install yum-cron",
            "title": "Auto-updates for Centos6"
        },
        {
            "location": "/yum/#see-also",
            "text": "rpm - interact with rpms directly  https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/sec-Managing_Yum_Repositories.html",
            "title": "See Also"
        },
        {
            "location": "/zerotier/",
            "text": "\"ZeroTier delivers the capabilities of VPNs, SDN, and SD-WAN with a single system. Manage all your connected resources across both local and wide area networks as if the whole world is a single data center.\" - \nhttps://www.zerotier.com/",
            "title": "Zerotier"
        },
        {
            "location": "/zfs/",
            "text": "ZFS is the Zetabyte File System.\n\n\nLinks\n\n\n\n\nOpenZFS - \nhttp://open-zfs.org\n\n\nTuning Guide - \nhttp://www.solarisinternals.com/wiki/index.php/ZFS_Evil_Tuning_Guide\n\n\nHardware recommendations - \nhttp://blog.zorinaq.com/?e=10\n\n\nMac ZFS - \nhttp://code.google.com/p/maczfs/\n\n\nShadow migration feature - \nhttp://docs.oracle.com/cd/E23824_01/html/821-1448/gkkud.html\n\n\nSpeed tuning - \nhttp://icesquare.com/wordpress/how-to-improve-zfs-performance/\n\n\nZFS RAID levels - \nhttp://www.zfsbuild.com/2010/05/26/zfs-raid-levels/\n\n\nhttp://en.wikipedia.org/wiki/ZFS\n\n\nhttp://wiki.freebsd.org/ZFSQuickStartGuide\n\n\nhttp://www.solarisinternals.com/wiki/index.php/ZFS_Best_Practices_Guide\n\n\nhttp://zfsguru.com\n\n\nhttp://zfsonlinux.org/faq.html\n\n\nhttp://www.oracle.com/technetwork/articles/servers-storage-admin/o11-113-size-zfs-dedup-1354231.html\n\n\nhttp://wiki.freebsd.org/ZFSTuningGuide#Deduplication\n\n\nCorruption / failure to import - \nhttps://github.com/zfsonlinux/zfs/issues/2457\n\n\n\n\nTips\n\n\nMemory\n\n\n\n\nFor normal operation, 1gb of memory per tb of disk space is suitable.\n\n\nFor dedup operation, 5gb of memory per tb of addressable disk space is suitable.\n\n\n\n\nLog devices\n\n\n\n\nUse a log device if you have lots of writes.\n\n\nMirror it, because if you lose it you lose the whole volume.\n\n\nSpeed and latency are most important, not size.  Log flushes every 5 seconds.\n\n\nGet SLC if possible, otherwise MLC\n\n\n\n\nCache devices\n\n\n\n\nUse if you have lots of reads\n\n\nSize does matter, with big devices more data can be cached for faster reads of more data.\n\n\nSpeed and latency matter\n\n\nMirror does not matter because if it fails, reads come from the spinning disks\n\n\n\n\nGood explanation: \nhttps://blogs.oracle.com/brendan/entry/test\n\n\nzdb\n\n\nShow the potential savings of turning on dedupe on zpool tank\n\n\nhttp://hub.opensolaris.org/bin/view/Community+Group+zfs/dedup\n\n\nzdb -S tank\n\n\n\n\nShow transactions and human readable dates in the zdb history\n\n\nUse \nzdb -e\n for pools that are not mounted.\n\n\nzdb -hh tank \\\n| egrep 'txg|time' \\\n| while read -r _ a b ; do\n  if [ \"$a\" == \"time:\" ] ; then\n    date -d @$b \"+$a %F %T\" ;\n  else\n    echo \"$a  $b\" ;\n  fi ;\ndone\n\n\n\n\nzpool\n\n\nCreate a zpool and its base filesystem\n\n\nzpool create -f -o cachefile=/tmp/zpool.cache zpoolname /dev/ada1 #create a zpool\n\n\n\n\nAdd a cache device to a pool\n\n\n# add ada0p3 as a cache device to the tank zpool\nzpool add tank cache ada0p3\n\n\n\n\nShow all configured zpool options for a given zpool\n\n\nzpool get all tank\n\n\n\n\nShow history of all operations on a given pool\n\n\n# show history of operations on the pool, eg: snapshots, attribute changes\nzpool history\n\n\n\n\nShow real time statistics on a given zpool\n\n\n# show per-device statistics every 1 second\nzpool iostat -v 1\n\n\n\n\nShow basic information about all imported zpools\n\n\n# show zpool space info, deduplication ratio and health\nzpool list\n\n\n\n\nShow deduplication tables\n\n\n# show deduplication table entries. Take entries * size / 1024 / 1024 to calculate DDT consumption\nzpool status -D z2\n\n\n\n\nReplace a disk in a zpool\n\n\n# Replace the first disk with the second in the tank pool\nzpool replace -f tank /dev/disk/by-id/ata-ST3000DM001-9YN166_W1F09CW9 /dev/disk/by-id/ata-ST3000DM001-9YN166_Z1F0N9S7 \n\n\n\n\nReal example\n\n\n$ zpool replace -f tank /dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1334PCJY9ASS /dev/disk/by-id/ata-HGST_HUH728080ALE600_VKHA6YDX\n$ zpool status\n  pool: home\n state: ONLINE\n  scan: scrub repaired 0 in 0h0m with 0 errors on Sun Dec 10 00:24:07 2017\nconfig:\n\n        NAME                                             STATE     READ WRITE CKSUM\n        home                                             ONLINE       0     0     0\n          ata-M4-CT064M4SSD2_0000000012170908F759-part4  ONLINE       0     0     0\n\nerrors: No known data errors\n\n  pool: tank\n state: DEGRADED\nstatus: One or more devices is currently being resilvered.  The pool will\n        continue to function, possibly in a degraded state.\naction: Wait for the resilver to complete.\n  scan: resilver in progress since Mon Jan  8 19:57:45 2018\n    47.1M scanned out of 13.7T at 6.72M/s, 592h39m to go\n    11.5M resilvered, 0.00% done\nconfig:\n\n        NAME                                           STATE     READ WRITE CKSUM\n        tank                                           DEGRADED     0     0     0\n          raidz1-0                                     DEGRADED     0     0     0\n            replacing-0                                UNAVAIL      0     0     0\n              ata-HGST_HDN724040ALE640_PK1334PCJY9ASS  UNAVAIL      0     1     0  corrupted data\n              ata-HGST_HUH728080ALE600_VKHA6YDX        ONLINE       0     0     0  (resilvering)\n            ata-HGST_HDN724040ALE640_PK2334PEHG8LAT    ONLINE       0     0     0\n            ata-HGST_HDN724040ALE640_PK2334PEHGD37T    ONLINE       0     0     0\n            ata-HGST_HDN724040ALE640_PK2338P4H3TJPC    ONLINE       0     0     0\n\nerrors: No known data errors\n\n\n\n\nzfs\n\n\nshow differences between current filesystem state and snapshot state\n\n\nzfs diff tank tank@snap\n\n\n\n\nShow configured properties for a filesystem\n\n\nzfs get all\n\n\n\n\nShow custom filesystem attributes\n\n\n# show custom attributes that override inherited attributes\nzfs get all -s local tank\n\n\n\n\nShow an overview of all mounted zfs filesystems\n\n\n# show disk space including free physical disk space and mount info\nzfs list\n\n\n\n\nShow specified fields of each filesystem\n\n\n# show the listed fields of all filesystems\nzfs list -t all -o name,referenced,used,written,creation,userused@root\n\n\n\n\nShow only snapshots\n\n\nzfs list -t snapshot\n\n\n\n\nShow space consumed by file owner\n\n\nzfs userspace tank\n\n\n\n\nDisable atime updates for a filesystem\n\n\nzfs set atime=off tank\n\n\n\n\nSet compression to lz4 for a filesystem\n\n\nzfs set compression=lz4 tank\n\n\n\n\nSet deduplication to enabled for a filesystem\n\n\nzfs set dedup=on tank\n\n\n\n\nSet a filesystem to readonly\n\n\nzfs set readonly=on zpoolname/dataset\n\n\n\n\nSet a filesystem to allow NFS sharing\n\n\nzfs set sharenfs=on tank\n\n\n\n\nCreate a dataset\n\n\n# create a dataset 'sole' on zpool 'tank'\nzfs create tank/sole\n\n\n\n\nDestroy multiple snapshots\n\n\nzfs destroy tank@20130413-weekly,20130420-weekly,20130428-weekly,20130505-weekly\n\n\n\n\nzfs send / receive\n\n\nReplicate a zpool (use the latest snapshot name as the source) to a blank zpool:\n\n\nzfs send -v -D -R tank@20120907-oldest | zfs receive -F -v z2\n\n\n\n\n\n\n-D enables a deduplicated stream.\n\n\n-R enables a recursive send of all snapshots and filesystems up to that point.\n\n\n-F enables deletion of any snapshots on the target that don't exist on the sender\n\n\n-v enables verbose mode\n\n\n\n\nrecursively zfs send a filesystem to a remote host and recieve it as a new dataset\n\n\nzfs send -v -D -R z1@20120907-oldest | ssh otherhost zfs receive -v z2/z1\n\n\n\n\nShow summary of what would be sent\n\n\nThis shows an entire dataset up to the given snapshot\n\n\nzfs send -n -v -D -R tank@20140531-monthly\n\n\n\n\nShow the space differences between two snapshots\n\n\nzfs send -n -v -D -i tank@20140531-monthly tank@20141031-monthly\n\n\n\n\nShow the amount of new space consumed by each monthly\n\n\nzfs list -o name | grep 'tank@.*monthly' | while read -r X ; do [[ ! $a =~ .*monthly ]] && a=$X || zfs send -n -v -D -i $a $X && a=$X ; done 2>&1 | grep send\n\n\n\n\nComplex examples\n\n\nCreate a raidz called tank\n\n\nCreate a raidz pool from 4 disks and set some properties:\n\n\npool=tank\nzpool create -f \"${pool}\" raidz /dev/disk/by-id/scsi-SATA_HGST_HDN724040A_PK2338P4H*-part1 -o ashift=12\nzfs set dedup=on \"${pool}\"\nzpool set listsnapshots=on \"${pool}\"\nzfs set atime=off \"${pool}\"\nzfs set compression=lz4 \"${pool}\"\n\n\n\n\nCreate a case insensitive raidz3 out of 50 files\n\n\npool=tank\nfor X in {1..50} ; do mkfile -n 2g ${pool}.$X ; done ;\nsudo zpool create -O casesensitivity=insensitive ${pool} raidz3 /Users/danielh/Desktop/Stuff/${pool}/${pool}.{1..50}\n\n\n\n\nTroubleshooting\n\n\nMount a pool that is giving you Trouble\n\n\nzpool import -o failmode=continue -o readonly=on zpool_name\n\n\n\n\nThis helped me get read access to a pool that was kernel panicking with the following error when I tried to import it normally:\n\n\nDec  7 14:48:40 localhost kernel: PANIC: blkptr at ffff8803fddb4200 DVA 0 has invalid OFFSET 294940902907904\n\n\n\n\nZFS on Mac OS X\n\n\n\n\nhttp://openzfsonosx.org\n\n\n\n\nCreate a ZFS partition on /dev/disk3\n\n\n# Must eject device in Disk Utility first\ndiskutil partitiondisk /dev/disk3 GPTFormat ZFS %noformat% 100% # strange syntax, but works\nzpool create backups1 /dev/disk3s2 # create the zpool\nmdutil -i off /Volumes/backups1 # required on MacZFS since spotlight does not function\n\n\n\n\nZFS on Linux\n\n\n\n\nIf you get module errors: \nmodprobe zfs ; ldconfig\n\n\nIf you get permission denied, check selinux settings\n\n\n\n\nCentOS 6 Repository\n\n\nsudo yum install -y epel-release # assumes later CentOS 6 where epel is provided upstream\nsudo yum localinstall --nogpgcheck http://archive.zfsonlinux.org/epel/zfs-release.el6.noarch.rpm\nsudo yum install zfs -y\n\n\n\n\nReinstalling when things fail\n\n\n#!/bin/bash -x\nyum install -y kernel-devel-$(uname -r)\nzfs_version=0.6.5.4\ndkms remove  -m zfs -v \"${zfs_version}\" --all\ndkms remove  -m spl -v \"${zfs_version}\" --all\ndkms add     -m spl -v \"${zfs_version}\" --force\ndkms add     -m zfs -v \"${zfs_version}\" --force\ndkms install -m spl -v \"${zfs_version}\" --force\ndkms install -m zfs -v \"${zfs_version}\" --force\n\n\n\n\nInspect the rpm for what scripts it runs\n\n\nThis is useful for debugging failures after kernel upgrade.\n\n\nrpm -q --scripts zfs-dkms\n\n\n\n\nBuilding on CentOS 6\n\n\nyum groupinstall \"Development tools\" && yum install -y libuuid-devel zlib-devel bc lsscsi mdadm parted kernel-debug\n# For spl, then again for zfs:\n./configure && make && make rpm && rpm -i *64.rpm",
            "title": "Zfs"
        },
        {
            "location": "/zfs/#links",
            "text": "OpenZFS -  http://open-zfs.org  Tuning Guide -  http://www.solarisinternals.com/wiki/index.php/ZFS_Evil_Tuning_Guide  Hardware recommendations -  http://blog.zorinaq.com/?e=10  Mac ZFS -  http://code.google.com/p/maczfs/  Shadow migration feature -  http://docs.oracle.com/cd/E23824_01/html/821-1448/gkkud.html  Speed tuning -  http://icesquare.com/wordpress/how-to-improve-zfs-performance/  ZFS RAID levels -  http://www.zfsbuild.com/2010/05/26/zfs-raid-levels/  http://en.wikipedia.org/wiki/ZFS  http://wiki.freebsd.org/ZFSQuickStartGuide  http://www.solarisinternals.com/wiki/index.php/ZFS_Best_Practices_Guide  http://zfsguru.com  http://zfsonlinux.org/faq.html  http://www.oracle.com/technetwork/articles/servers-storage-admin/o11-113-size-zfs-dedup-1354231.html  http://wiki.freebsd.org/ZFSTuningGuide#Deduplication  Corruption / failure to import -  https://github.com/zfsonlinux/zfs/issues/2457",
            "title": "Links"
        },
        {
            "location": "/zfs/#tips",
            "text": "",
            "title": "Tips"
        },
        {
            "location": "/zfs/#memory",
            "text": "For normal operation, 1gb of memory per tb of disk space is suitable.  For dedup operation, 5gb of memory per tb of addressable disk space is suitable.",
            "title": "Memory"
        },
        {
            "location": "/zfs/#log-devices",
            "text": "Use a log device if you have lots of writes.  Mirror it, because if you lose it you lose the whole volume.  Speed and latency are most important, not size.  Log flushes every 5 seconds.  Get SLC if possible, otherwise MLC",
            "title": "Log devices"
        },
        {
            "location": "/zfs/#cache-devices",
            "text": "Use if you have lots of reads  Size does matter, with big devices more data can be cached for faster reads of more data.  Speed and latency matter  Mirror does not matter because if it fails, reads come from the spinning disks   Good explanation:  https://blogs.oracle.com/brendan/entry/test",
            "title": "Cache devices"
        },
        {
            "location": "/zfs/#zdb",
            "text": "",
            "title": "zdb"
        },
        {
            "location": "/zfs/#show-the-potential-savings-of-turning-on-dedupe-on-zpool-tank",
            "text": "http://hub.opensolaris.org/bin/view/Community+Group+zfs/dedup  zdb -S tank",
            "title": "Show the potential savings of turning on dedupe on zpool tank"
        },
        {
            "location": "/zfs/#show-transactions-and-human-readable-dates-in-the-zdb-history",
            "text": "Use  zdb -e  for pools that are not mounted.  zdb -hh tank \\\n| egrep 'txg|time' \\\n| while read -r _ a b ; do\n  if [ \"$a\" == \"time:\" ] ; then\n    date -d @$b \"+$a %F %T\" ;\n  else\n    echo \"$a  $b\" ;\n  fi ;\ndone",
            "title": "Show transactions and human readable dates in the zdb history"
        },
        {
            "location": "/zfs/#zpool",
            "text": "",
            "title": "zpool"
        },
        {
            "location": "/zfs/#create-a-zpool-and-its-base-filesystem",
            "text": "zpool create -f -o cachefile=/tmp/zpool.cache zpoolname /dev/ada1 #create a zpool",
            "title": "Create a zpool and its base filesystem"
        },
        {
            "location": "/zfs/#add-a-cache-device-to-a-pool",
            "text": "# add ada0p3 as a cache device to the tank zpool\nzpool add tank cache ada0p3",
            "title": "Add a cache device to a pool"
        },
        {
            "location": "/zfs/#show-all-configured-zpool-options-for-a-given-zpool",
            "text": "zpool get all tank",
            "title": "Show all configured zpool options for a given zpool"
        },
        {
            "location": "/zfs/#show-history-of-all-operations-on-a-given-pool",
            "text": "# show history of operations on the pool, eg: snapshots, attribute changes\nzpool history",
            "title": "Show history of all operations on a given pool"
        },
        {
            "location": "/zfs/#show-real-time-statistics-on-a-given-zpool",
            "text": "# show per-device statistics every 1 second\nzpool iostat -v 1",
            "title": "Show real time statistics on a given zpool"
        },
        {
            "location": "/zfs/#show-basic-information-about-all-imported-zpools",
            "text": "# show zpool space info, deduplication ratio and health\nzpool list",
            "title": "Show basic information about all imported zpools"
        },
        {
            "location": "/zfs/#show-deduplication-tables",
            "text": "# show deduplication table entries. Take entries * size / 1024 / 1024 to calculate DDT consumption\nzpool status -D z2",
            "title": "Show deduplication tables"
        },
        {
            "location": "/zfs/#replace-a-disk-in-a-zpool",
            "text": "# Replace the first disk with the second in the tank pool\nzpool replace -f tank /dev/disk/by-id/ata-ST3000DM001-9YN166_W1F09CW9 /dev/disk/by-id/ata-ST3000DM001-9YN166_Z1F0N9S7",
            "title": "Replace a disk in a zpool"
        },
        {
            "location": "/zfs/#real-example",
            "text": "$ zpool replace -f tank /dev/disk/by-id/ata-HGST_HDN724040ALE640_PK1334PCJY9ASS /dev/disk/by-id/ata-HGST_HUH728080ALE600_VKHA6YDX\n$ zpool status\n  pool: home\n state: ONLINE\n  scan: scrub repaired 0 in 0h0m with 0 errors on Sun Dec 10 00:24:07 2017\nconfig:\n\n        NAME                                             STATE     READ WRITE CKSUM\n        home                                             ONLINE       0     0     0\n          ata-M4-CT064M4SSD2_0000000012170908F759-part4  ONLINE       0     0     0\n\nerrors: No known data errors\n\n  pool: tank\n state: DEGRADED\nstatus: One or more devices is currently being resilvered.  The pool will\n        continue to function, possibly in a degraded state.\naction: Wait for the resilver to complete.\n  scan: resilver in progress since Mon Jan  8 19:57:45 2018\n    47.1M scanned out of 13.7T at 6.72M/s, 592h39m to go\n    11.5M resilvered, 0.00% done\nconfig:\n\n        NAME                                           STATE     READ WRITE CKSUM\n        tank                                           DEGRADED     0     0     0\n          raidz1-0                                     DEGRADED     0     0     0\n            replacing-0                                UNAVAIL      0     0     0\n              ata-HGST_HDN724040ALE640_PK1334PCJY9ASS  UNAVAIL      0     1     0  corrupted data\n              ata-HGST_HUH728080ALE600_VKHA6YDX        ONLINE       0     0     0  (resilvering)\n            ata-HGST_HDN724040ALE640_PK2334PEHG8LAT    ONLINE       0     0     0\n            ata-HGST_HDN724040ALE640_PK2334PEHGD37T    ONLINE       0     0     0\n            ata-HGST_HDN724040ALE640_PK2338P4H3TJPC    ONLINE       0     0     0\n\nerrors: No known data errors",
            "title": "Real example"
        },
        {
            "location": "/zfs/#zfs",
            "text": "",
            "title": "zfs"
        },
        {
            "location": "/zfs/#show-differences-between-current-filesystem-state-and-snapshot-state",
            "text": "zfs diff tank tank@snap",
            "title": "show differences between current filesystem state and snapshot state"
        },
        {
            "location": "/zfs/#show-configured-properties-for-a-filesystem",
            "text": "zfs get all",
            "title": "Show configured properties for a filesystem"
        },
        {
            "location": "/zfs/#show-custom-filesystem-attributes",
            "text": "# show custom attributes that override inherited attributes\nzfs get all -s local tank",
            "title": "Show custom filesystem attributes"
        },
        {
            "location": "/zfs/#show-an-overview-of-all-mounted-zfs-filesystems",
            "text": "# show disk space including free physical disk space and mount info\nzfs list",
            "title": "Show an overview of all mounted zfs filesystems"
        },
        {
            "location": "/zfs/#show-specified-fields-of-each-filesystem",
            "text": "# show the listed fields of all filesystems\nzfs list -t all -o name,referenced,used,written,creation,userused@root",
            "title": "Show specified fields of each filesystem"
        },
        {
            "location": "/zfs/#show-only-snapshots",
            "text": "zfs list -t snapshot",
            "title": "Show only snapshots"
        },
        {
            "location": "/zfs/#show-space-consumed-by-file-owner",
            "text": "zfs userspace tank",
            "title": "Show space consumed by file owner"
        },
        {
            "location": "/zfs/#disable-atime-updates-for-a-filesystem",
            "text": "zfs set atime=off tank",
            "title": "Disable atime updates for a filesystem"
        },
        {
            "location": "/zfs/#set-compression-to-lz4-for-a-filesystem",
            "text": "zfs set compression=lz4 tank",
            "title": "Set compression to lz4 for a filesystem"
        },
        {
            "location": "/zfs/#set-deduplication-to-enabled-for-a-filesystem",
            "text": "zfs set dedup=on tank",
            "title": "Set deduplication to enabled for a filesystem"
        },
        {
            "location": "/zfs/#set-a-filesystem-to-readonly",
            "text": "zfs set readonly=on zpoolname/dataset",
            "title": "Set a filesystem to readonly"
        },
        {
            "location": "/zfs/#set-a-filesystem-to-allow-nfs-sharing",
            "text": "zfs set sharenfs=on tank",
            "title": "Set a filesystem to allow NFS sharing"
        },
        {
            "location": "/zfs/#create-a-dataset",
            "text": "# create a dataset 'sole' on zpool 'tank'\nzfs create tank/sole",
            "title": "Create a dataset"
        },
        {
            "location": "/zfs/#destroy-multiple-snapshots",
            "text": "zfs destroy tank@20130413-weekly,20130420-weekly,20130428-weekly,20130505-weekly",
            "title": "Destroy multiple snapshots"
        },
        {
            "location": "/zfs/#zfs-send-receive",
            "text": "Replicate a zpool (use the latest snapshot name as the source) to a blank zpool:  zfs send -v -D -R tank@20120907-oldest | zfs receive -F -v z2   -D enables a deduplicated stream.  -R enables a recursive send of all snapshots and filesystems up to that point.  -F enables deletion of any snapshots on the target that don't exist on the sender  -v enables verbose mode",
            "title": "zfs send / receive"
        },
        {
            "location": "/zfs/#recursively-zfs-send-a-filesystem-to-a-remote-host-and-recieve-it-as-a-new-dataset",
            "text": "zfs send -v -D -R z1@20120907-oldest | ssh otherhost zfs receive -v z2/z1",
            "title": "recursively zfs send a filesystem to a remote host and recieve it as a new dataset"
        },
        {
            "location": "/zfs/#show-summary-of-what-would-be-sent",
            "text": "This shows an entire dataset up to the given snapshot  zfs send -n -v -D -R tank@20140531-monthly",
            "title": "Show summary of what would be sent"
        },
        {
            "location": "/zfs/#show-the-space-differences-between-two-snapshots",
            "text": "zfs send -n -v -D -i tank@20140531-monthly tank@20141031-monthly",
            "title": "Show the space differences between two snapshots"
        },
        {
            "location": "/zfs/#show-the-amount-of-new-space-consumed-by-each-monthly",
            "text": "zfs list -o name | grep 'tank@.*monthly' | while read -r X ; do [[ ! $a =~ .*monthly ]] && a=$X || zfs send -n -v -D -i $a $X && a=$X ; done 2>&1 | grep send",
            "title": "Show the amount of new space consumed by each monthly"
        },
        {
            "location": "/zfs/#complex-examples",
            "text": "",
            "title": "Complex examples"
        },
        {
            "location": "/zfs/#create-a-raidz-called-tank",
            "text": "Create a raidz pool from 4 disks and set some properties:  pool=tank\nzpool create -f \"${pool}\" raidz /dev/disk/by-id/scsi-SATA_HGST_HDN724040A_PK2338P4H*-part1 -o ashift=12\nzfs set dedup=on \"${pool}\"\nzpool set listsnapshots=on \"${pool}\"\nzfs set atime=off \"${pool}\"\nzfs set compression=lz4 \"${pool}\"",
            "title": "Create a raidz called tank"
        },
        {
            "location": "/zfs/#create-a-case-insensitive-raidz3-out-of-50-files",
            "text": "pool=tank\nfor X in {1..50} ; do mkfile -n 2g ${pool}.$X ; done ;\nsudo zpool create -O casesensitivity=insensitive ${pool} raidz3 /Users/danielh/Desktop/Stuff/${pool}/${pool}.{1..50}",
            "title": "Create a case insensitive raidz3 out of 50 files"
        },
        {
            "location": "/zfs/#troubleshooting",
            "text": "",
            "title": "Troubleshooting"
        },
        {
            "location": "/zfs/#mount-a-pool-that-is-giving-you-trouble",
            "text": "zpool import -o failmode=continue -o readonly=on zpool_name  This helped me get read access to a pool that was kernel panicking with the following error when I tried to import it normally:  Dec  7 14:48:40 localhost kernel: PANIC: blkptr at ffff8803fddb4200 DVA 0 has invalid OFFSET 294940902907904",
            "title": "Mount a pool that is giving you Trouble"
        },
        {
            "location": "/zfs/#zfs-on-mac-os-x",
            "text": "http://openzfsonosx.org",
            "title": "ZFS on Mac OS X"
        },
        {
            "location": "/zfs/#create-a-zfs-partition-on-devdisk3",
            "text": "# Must eject device in Disk Utility first\ndiskutil partitiondisk /dev/disk3 GPTFormat ZFS %noformat% 100% # strange syntax, but works\nzpool create backups1 /dev/disk3s2 # create the zpool\nmdutil -i off /Volumes/backups1 # required on MacZFS since spotlight does not function",
            "title": "Create a ZFS partition on /dev/disk3"
        },
        {
            "location": "/zfs/#zfs-on-linux",
            "text": "If you get module errors:  modprobe zfs ; ldconfig  If you get permission denied, check selinux settings",
            "title": "ZFS on Linux"
        },
        {
            "location": "/zfs/#centos-6-repository",
            "text": "sudo yum install -y epel-release # assumes later CentOS 6 where epel is provided upstream\nsudo yum localinstall --nogpgcheck http://archive.zfsonlinux.org/epel/zfs-release.el6.noarch.rpm\nsudo yum install zfs -y",
            "title": "CentOS 6 Repository"
        },
        {
            "location": "/zfs/#reinstalling-when-things-fail",
            "text": "#!/bin/bash -x\nyum install -y kernel-devel-$(uname -r)\nzfs_version=0.6.5.4\ndkms remove  -m zfs -v \"${zfs_version}\" --all\ndkms remove  -m spl -v \"${zfs_version}\" --all\ndkms add     -m spl -v \"${zfs_version}\" --force\ndkms add     -m zfs -v \"${zfs_version}\" --force\ndkms install -m spl -v \"${zfs_version}\" --force\ndkms install -m zfs -v \"${zfs_version}\" --force",
            "title": "Reinstalling when things fail"
        },
        {
            "location": "/zfs/#inspect-the-rpm-for-what-scripts-it-runs",
            "text": "This is useful for debugging failures after kernel upgrade.  rpm -q --scripts zfs-dkms",
            "title": "Inspect the rpm for what scripts it runs"
        },
        {
            "location": "/zfs/#building-on-centos-6",
            "text": "yum groupinstall \"Development tools\" && yum install -y libuuid-devel zlib-devel bc lsscsi mdadm parted kernel-debug\n# For spl, then again for zfs:\n./configure && make && make rpm && rpm -i *64.rpm",
            "title": "Building on CentOS 6"
        },
        {
            "location": "/zookeeper/",
            "text": "ZooKeeper is a high-performance coordination service for distributed applications. - \nhttps://zookeeper.apache.org/doc/trunk/\n\n\nExamples\n\n\nThe four letter words\n\n\n\"ZooKeeper responds to a small set of commands. Each command is composed of four letters. You issue the commands to ZooKeeper via telnet or nc, at the client port.\" - \nhttps://zookeeper.apache.org/doc/r3.4.8/zookeeperAdmin.html#sc_zkCommands\n\n\nLists brief details for the server and connected clients\n\n\necho 'stat' | nc localhost 2181\n\n\nView a list of variables that could be used for monitoring the health of the cluster\n\n\necho 'mntr' | nc localhost 2181\n\n\nList full details for the server\n\n\necho 'srvr' | nc localhost 2181\n\n\nLinks\n\n\n\n\nhttps://zookeeper.apache.org/doc/r3.4.8/zookeeperAdmin.html",
            "title": "Zookeeper"
        },
        {
            "location": "/zookeeper/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/zookeeper/#the-four-letter-words",
            "text": "\"ZooKeeper responds to a small set of commands. Each command is composed of four letters. You issue the commands to ZooKeeper via telnet or nc, at the client port.\" -  https://zookeeper.apache.org/doc/r3.4.8/zookeeperAdmin.html#sc_zkCommands",
            "title": "The four letter words"
        },
        {
            "location": "/zookeeper/#lists-brief-details-for-the-server-and-connected-clients",
            "text": "echo 'stat' | nc localhost 2181",
            "title": "Lists brief details for the server and connected clients"
        },
        {
            "location": "/zookeeper/#view-a-list-of-variables-that-could-be-used-for-monitoring-the-health-of-the-cluster",
            "text": "echo 'mntr' | nc localhost 2181",
            "title": "View a list of variables that could be used for monitoring the health of the cluster"
        },
        {
            "location": "/zookeeper/#list-full-details-for-the-server",
            "text": "echo 'srvr' | nc localhost 2181",
            "title": "List full details for the server"
        },
        {
            "location": "/zookeeper/#links",
            "text": "https://zookeeper.apache.org/doc/r3.4.8/zookeeperAdmin.html",
            "title": "Links"
        }
    ]
}